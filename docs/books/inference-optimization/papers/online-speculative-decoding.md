# Online Speculative Decoding：在线投机解码

原文链接： [Online Speculative Decoding](https://arxiv.org/abs/2310.07177) [4]

## 论文信息
- 年份：2023 [4]
- 作者：Xiaoxuan Liu, Lanxiang Hu, Peter Bailis, Alvin Cheung, Zhijie Deng, Ion Stoica, Hao Zhang [4]
- 作者背景（研究领域）：在线学习/蒸馏/推理系统 [4]
- 前后血缘关系（同主题）：前序：[Speculative Sampling](speculative-sampling.md)；后续：无 [4]

## 主旨
在线投机解码的核心思想是把草稿模型持续在线更新，使其适配真实请求分布，从而提高接受率与时延收益。[4]

## 背景与问题定义
传统投机解码依赖静态草稿模型，当请求分布与训练数据分布不一致时，草稿准确率下降，接受率低导致加速失效。[4]
论文将问题定义为：如何让草稿模型持续贴近线上请求，以保证投机解码在真实服务场景稳定获益。[4]

## 方法与机制
论文提出在线蒸馏框架，通过实时收集用户请求与目标模型输出，持续训练一个或多个草稿模型。[4]
该机制在保持目标分布一致性的前提下，提升草稿模型预测匹配度，使验证阶段可接受更多 token。[4]

## 实验与结果
在合成与真实查询数据上，在线更新显著提升草稿接受率，并带来稳定的时延降低。[4]
作者强调接受率是可通过在线训练持续抬高的关键指标。[4]

## 关键数据结果
- 接受率提升 0.1–0.65。[4]
- 时延降低 1.42×–2.17×。[4]

## 工程启示（优化点）
- 建立在线蒸馏流水线，把草稿模型视为可持续优化的服务组件。[4]
- 以接受率为核心 KPI，动态调整草稿更新频率。[4]
- 支持多草稿模型以适配不同请求分布。[4]
- 评估线上收益时同时衡量延迟与吞吐。[4]

## 局限与延伸
在线训练带来系统复杂度与成本，同时也引入隐私与数据治理约束。[4]
未来可结合更强的蒸馏策略与分布漂移检测，提升在线适配的稳定性。[4]
