# Staged Speculative Decoding：分阶段投机解码

原文链接： [Accelerating LLM Inference with Staged Speculative Decoding](https://arxiv.org/abs/2308.04623) [5]

## 论文信息
- 年份：2023 [5]
- 作者：Benjamin Spector, Chris Re [5]
- 作者背景（研究领域）：推理系统/小批量加速/解码优化 [5]
- 前后血缘关系（同主题）：前序：[Speculative Sampling](speculative-sampling.md)；后续：无 [5]

## 主旨
Staged Speculative Decoding 通过树形草稿批次与两阶段验证，解决小批量/端侧推理的低算力密度问题。[5]

## 背景与问题定义
小批量场景下算术强度低，GPU 难以充分利用，导致投机解码的并行优势被削弱。[5]
论文的问题是：如何在小 batch 和 on-device 场景中，仍然让投机解码形成实质性的延迟收益。[5]

## 方法与机制
作者把草稿批次重构为树形结构，提高每轮验证可接受的 token 数。[5]
在此基础上增加第二阶段投机解码，进一步放大每次目标模型调用的收益。[5]

## 实验与结果
在 GPT-2-L (762M) 上验证，该方法在单批场景下显著降低推理延迟且保持输出质量。[5]
结果表明投机解码不仅适合大批量 server 场景，也可适用于 on-device 推理。[5]

## 关键数据结果
- 在 762M GPT-2-L 上，单批量解码时延降低 3.16×。[5]

## 工程启示（优化点）
- 通过树形草稿批次提高单次验证收益。[5]
- 两阶段投机显著提升小批量场景效率。[5]
- 端侧推理优先以 latency 作为主要指标调参。[5]

## 局限与延伸
树形批次与两阶段验证增加实现复杂度，且收益与模型规模、硬件结构密切相关。[5]
未来可与更强草稿模型或并行预测结合，进一步降低小 batch 的推理成本。[5]
