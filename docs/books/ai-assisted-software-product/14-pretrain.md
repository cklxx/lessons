# 第 14 章：预训练：目标、边界与成本核算

> 在应用层语境里，预训练更像领域适配：让通用基座模型更贴合你的业务语言与分布，而不是追求参数规模。对个人与小团队而言，预训练的第一原则是：先证明值得做，再为它付出算力与风险成本。[44][37]

本章将避免宏大叙事，聚焦预训练在 0→1 阶段的适用边界与决策方法。对许多 0→1 产品而言，预训练通常并非最短路径，因为它验证周期长、成本高、风险大；更好的数据边界、更好的 RAG、更好的评测回归往往更快闭环。只有当这些路径都不足以解决问题时，预训练才值得进入你的成本表。[6][44]

## 你将收获什么
通过本章，你将能够：
- 用一条可裁决的决策路径判断是否需要预训练（先便宜方案，后训练）。
- 填好一张预训练决策卡，把目标、基线、数据、预算、风险、评测、门槛与回滚写成可执行条款。
- 用一次小跑外推训练与上线成本，并把守门指标与止损线写进门禁。[44]

!!! note
    术语约定：本章所说的预训练主要指基于现有通用基座模型做持续预训练或领域适配预训练（continued pretraining / domain-adaptive pretraining），而非从零训练一个基础模型。

本章默认把止损线与回滚当作前置条件：没有止损，投入将缺乏证据约束，且更容易把退化模型引入生产环境。

## 三层思考：预训练的本质是投资决策
### 第 1 层：决策目标
你要交付一张能开会拍板的决策卡：目标任务与指标、可复现基线、预算上限与止损线、守门指标与回滚动作。任何一个写不出来，就说明你还不该做预训练。

极简结构可以先写成一行：

```text
目标 | 基线 | 数据 | 预算 | 风险 | 评测 | 门槛 | 回滚
```

### 第 2 层：论证链条
预训练决策链条是：

问题定义 → 便宜替代方案 → 数据可用性 → 成本与风险 → 评测基线 → 训练计划 → 对比报告 → 发布与回滚

把链条写成可执行的问题清单，更容易对齐判断标准：

| 环节 | 你必须回答的问题 | 产出物 |
| --- | --- | --- |
| 前置边界 | 止损线、回滚动作与守门指标是否已定义？ | 边界声明（写进决策卡） |
| 问题定义 | 预训练要补的是哪类能力缺口，如何量化？ | 任务清单 + 指标 |
| 便宜替代方案 | RAG、提示、流程能否先解决 80%？ | 基线方案 |
| 数据可用性 | 数据是否可用于训练与商业部署，覆盖与偏差如何？ | 数据卡 + 风险说明 |
| 成本与风险 | 最坏情况你扛得住吗，失败如何止损？ | 预算上限 + 止损线 |
| 评测基线 | 不训练时的指标是多少，能否稳定复现？ | 回归集 + 基线报告 |
| 训练计划 | 训练做什么改动，跑多久，怎么采样？ | 训练配置 + 日志规范 |
| 对比报告 | 提升与退化分别在哪里，原因是什么？ | 对比报告 |
| 发布与回滚 | 如何灰度，如何一键回退？ | 上线与回滚方案 |

数据卡：一张解释数据来源、许可协议、字段口径、覆盖范围、潜在偏差、脱敏方案、可回溯性与版本信息（含存储地与跨境）的说明书（见第 13 章）。

缺乏可复现的评测基线，预训练投入将难以量化产出，导致资源浪费。[6]

### 第 3 层：落地与验收
验收必须是对比式的：
- 与基线（不训练）相比，关键任务质量提升达到门槛；
- 守门指标不劣于基线且不超阈值（安全、隐私、延迟、成本、稳定性）；
- 可回滚到旧模型（或旧策略），不把自己锁死。[6][44]

## 先问：你真的需要预训练吗
预训练决策路径概览（用于形成可裁决的决策）

| 步骤 | 问题 | 通过条件 | 下一步 |
| --- | --- | --- | --- |
| 0. 预设边界 | 是否已写清止损线、回滚动作与守门指标？ | 可执行且可审计 | 进入 1 |
| 1. 明确缺口 | 缺的是证据、流程、稳定性还是领域能力？ | 能写成可评测任务 | 进入 2 |
| 2. 先跑便宜方案 | RAG/提示/流程/评测回归能否达标？ | 达标或接近达标 | 不做预训练 |
| 3. 评估数据 | 数据是否可用（许可、脱敏、偏差、覆盖）？ | 合规可用且覆盖足够 | 进入 4 |
| 4. 建立基线 | 不训练时的基线指标是多少？ | 基线可复现 | 进入 5 |
| 5. 小跑试验 | 小规模训练是否有趋势收益？ | 趋势明确且守门不越界 | 进入 6 |
| 6. 全量训练 | 达到门槛了吗？ | 达标 | 进入上线 |
| 7. 上线与回滚 | 灰度后是否稳定？ | 稳定 | 固化版本 |
| 8. 止损 | 不达标或守门越界 | 触发止损线 | 回滚到基线 |

把问题按缺什么分类，会更清醒：
- **缺证据**：回答编造、知识过期（业务后果：信任受损与投诉）→ 先做 RAG 与语料边界：用检索把权威事实接进来，让更新不依赖训练（见第 10 章）。[24]
- **缺流程**：任务太长、输入太乱（业务后果：转化差、人工兜底）→ 先做产品与交互：把任务拆成分步输入、模板与校验，把自由生成变成受控填写（第 4–8 章）。
- **缺稳定性**：改动后波动难解释（业务后果：回归事故与返工）→ 先做评测回归：把回归集、守门指标与发布门禁固化，指标不过线不允许发版（第 18 章）。[6]
- **缺领域能力**：模型始终理解不了你的术语、格式、风格（业务后果：专业度不够、效率低）→ 才考虑领域适配或增量预训练（例如在合同抽取里混淆赔偿与罚款）。[37]

### 案例：合同条款抽取助手是否做增量预训练
场景：你做一个合同条款抽取助手，把合同文本抽成结构化字段（例如违约条款、赔偿上限、管辖地）。用户最在意的是准确与可追溯，错一次就会流失。

按上面的决策路径走一遍，可以得到可裁决的结论，而不是依赖直觉：

| 决策卡字段 | 填写示例（示意） |
| --- | --- |
| 目标 | 条款抽取准确率从 0.84 提升到 0.90；格式一致性显著提升 |
| 基线方案 | RAG + 模板提示；回归集 2000 份合同可复现 |
| 数据 | 12 万份历史合同，授权允许内部训练；先做去标识化与字段排除；覆盖主要行业但存在行业偏差 |
| 预算 | 先小跑 50 GPU 小时；若趋势不明显则停；上线后推理成本不得上升超过 10% |
| 风险 | 遗忘：通用回归下降 > 1 个点即止损；泄露：PII 命中率 > 0.1% 即回滚；越权：注入或越权成功率 > 0.1% 即阻断 |
| 评测 | 回归集（2000 份合同）+ 注入集（诱导生成虚假条款）+ PII 探测集（姓名/身份证/银行卡正则与扫描）+ 成本/延迟基准 |
| 成功门槛 | 主指标 ≥ 0.90；守门：注入/越权 ≤ 0.1%，PII ≤ 0.1%，成本 ≤ +10%，延迟 p95 ≤ +10% |
| 回滚 | 模型注册表版本化；灰度异常一键切回基线方案 |

## 预训练能解决什么（以及不能解决什么）
预训练/领域适配更擅长解决：
- 领域语言与术语（格式、缩写、写作风格）
- 领域知识表达方式（常见结构与模板）
- 领域内深层语义关联与模式（难以用显式规则编码，且输出不保证可解释性）

它不擅长解决：
- 权威事实的实时更新（更适合 RAG）
- 复杂动作链路与权限边界（更适合 Agent + 工具合同）
- 缺乏评测基线的感觉更好

## 模板：预训练决策卡（先写再动手）
| 字段 | 说明 |
| --- | --- |
| 目标 | 想提升什么能力（必须可评测）；对应哪些真实任务 |
| 基线方案 | 不训练时怎么做（RAG/提示/流程）；基线指标是多少 |
| 数据 | 许可是否允许训练与商业部署；数据存储地与跨境传输合规；覆盖与偏差；脱敏与排除清单 |
| 预算 | 训练 GPU 小时上限、周期上限、推理成本上限；止损线 |
| 风险 | 写清风险场景 + 检测指标 + 阈值 + 处置动作（停训/回滚/下线）；包含隐私泄露、越权、遗忘与不可控输出 |
| 评测 | 关键任务回归集 + 安全集 + 成本/延迟集（全部可复现） |
| 成功门槛 | 主指标提升达到阈值；守门指标不劣于基线并且不超阈值（对比式） |
| 回滚 | 模型与策略版本化；灰度失败可一键回到基线 |

## 成本核算：把可能性变成账本
对个人来说，成本核算的意义是优先确定三件事：
- 你能否承受最坏情况（预算止损）；
- 你能否得到可解释的收益（对比门槛）；
- 你能否在失败后安全撤退（回滚与资产留存）。[44]

建议你至少估算三类成本：
- **直接成本**：训练算力、存储、带宽、工程时间。
- **机会成本**：本可以用于产品验证与增长的时间。
- **风险成本**：合规审查、质量波动、回归维护。 [44]

### 最小估算方法：先测一次，再外推
避免凭直觉写预算。最务实的做法是做一次小跑，测出吞吐与单价。

如果你暂时没有训练环境：先用云服务托管训练平台（例如 AWS SageMaker、Google Cloud Vertex AI、Azure ML）或 notebook 环境跑一个小模型的概念验证，获取 tokens_per_sec 与单价等关键估算值；若仍无法获取，建议预留 0.5–2 个工程人日与 2–10 GPU 小时，完成一次最小可运行试验（单卡、小模型、1% 数据、1 epoch），再进入预算讨论。
如果你完全从零开始：先用云平台免费试用或社区 notebook 做概念验证，或者先用训练成本计算器做粗估，至少把数量级算对。

- 取 1%–5% 的核心数据，跑 30–60 分钟的训练试验，记录 tokens_per_sec、显存占用、checkpoint 体积。
- 用外推估算训练开销：(数据集 token 总量 × epoch 数) ÷ tokens_per_sec ≈ 训练秒数，再换算成 GPU 小时与费用。
- 注意：上述是下界粗估，实际还会受到分布式通信、数据加载、周期评测、checkpoint 保存、I/O、平台服务费等影响；建议保守乘以 1.2–2.0 的系数，并在小跑中用日志与 profiling 校准。
- 把推理成本也算进去：上线后每请求 token、平均 tool_calls、峰值并发，决定你会不会训练完反而更亏。

你至少应该能写出一张简化账本：

| 成本项 | 最小估算方法 | 止损线示例 |
| --- | --- | --- |
| 训练算力 | GPU 小时 × 单价（实例类型、区域、抢占式差异） | 不超过预算上限 |
| 存储与网络 | 数据存储、上传下载、I/O、托管平台服务费 | 单次训练存储或网络费用超预算 15% 则暂停优化 |
| 数据处理 | 清洗/脱敏/标注人天 | 超过就缩范围 |
| 评测回归 | 回归集维护人天 | 回归维护成本超周预算 20% 则简化策略或收缩范围 |
| 推理增量 | 每请求成本 × 预计量 | 越界则降级或不做 |
| 合规与风险 | 法务审查、应急预案 | 无法覆盖就停止 |
| 平台锁定 | 托管训练依赖评估（数据格式、训练脚本、部署） | 迁移成本超过预算 30% 或超过 1 个月工程投入就止损 |

### 给新手的降门槛做法
- 不要从大模型开始：先用更小的基座做小跑，看趋势再决定是否值得升级规模。
- 不要从全量数据开始：先用最有价值的子域数据（失败样本与高价值样本）验证方向，再扩量。
- 不要从自建训练栈开始：优先用托管训练平台或成熟框架把试验跑通（例如 AWS SageMaker、Google Cloud Vertex AI、Azure ML，或 Hugging Face Transformers 生态），把工程风险降到最低。

## 评测先行：训练不是终点，对比报告才是
预训练的交付物不是模型文件，而是对比报告：
- 哪些任务变好了（达到门槛）；
- 哪些任务变差了（守门指标是否越界）；
- 为什么会变（数据与策略解释）；
- 是否值得上线（以及如何灰度与回滚）。[6]

### 对比报告建议结构（写清就能裁决）
1. 执行摘要：是否达标，是否建议上线，止损结论。
2. 方法与范围：训练配置、数据快照、评测集版本、对比基线。
3. 关键任务对比：主指标基线 vs 训练后，分桶到关键子场景。
4. 守门指标：安全、隐私、成本、延迟、稳定性逐项对比与阈值判定。
5. 退化与根因：退化任务列表，疑似原因与证据（样本与日志）。
6. 风险与缓解：风险场景、处置动作、灰度策略与回滚条件。
7. 成本账本：训练与推理成本估算、与预算差异、平台锁定评估。

### 最小工具链建议（把评测与回滚变成默认动作）
- 实验追踪：MLflow 或同类系统，记录 config、code_revision、数据快照、指标与产物。
- 数据版本：DVC 或对象存储快照 + manifest，确保训练与评测可回放。
- 自动化回归：在 CI 中跑回归脚本，按 checkpoint 产出对比报告并触发门禁。

落地方式建议：在预训练项目启动阶段由工程负责人或 MLOps 先把工具链搭好，并把评测与门禁接入 CI；任何训练迭代与灰度发布都必须自动产出对比报告，未达门槛或守门越界则自动阻断与回滚。

### 守门指标示例（缺失则不建议上线）

阈值必须是量化数值，来源应明确：业务 SLA、法规与合同要求、历史基线分位数与风险评估。建议同时设置告警阈值与阻断阈值，并将阈值写入决策卡与回归门禁。

| 类别 | 指标例子 | 成功标准 | 越界动作 |
| --- | --- | --- | --- |
| 安全 | 注入成功率、越权成功率 | 不劣于基线且不超阈值（示例：≤ 0.1%） | 立刻回滚 |
| 隐私 | PII 泄露命中率 | 不劣于基线且不超阈值（示例：≤ 0.1%） | 下线并排查数据 |
| 成本 | 每请求 token、单位任务成本 | 不劣于预算且不超阈值 | 降级或停止推广 |
| 延迟 | p95 推理延迟 | 不劣于 SLA 且不超阈值 | 限流或切回基线 |
| 稳定 | 回归集方差、漂移告警 | 不劣于基线且不超阈值 | 暂停灰度 |

## 复现检查清单（本章最低门槛）
- 预训练决策卡已写：目标、预算、风险、成功门槛、回滚齐全。[44]
- 已有评测基线：不训练的方案可运行、可对比。[6]
- 有止损线：达不到门槛或守门越界时，停止训练或灰度并回滚到基线；同时启动复盘与原因排查，决定下一步动作。[44]

## 常见陷阱（失败样本）
1. **现象**：花了大量预算，效果说不清。  
   **根因**：没有评测基线与门槛；训练成了许愿。  
   **修复**：先按本章建立可复现回归集与基线报告；训练过程每个 checkpoint 都跑对比评测并产出对比报告；达不到门槛立刻止损并回滚到基线方案。[6]

2. **现象**：某些能力变好了，但通用能力退化或变危险。  
   **根因**：数据偏差、遗忘与缺乏守门指标。  
   **修复**：把注入、越权、PII 泄露与关键通用任务纳入守门集；任何守门退化就停训或回滚；同时把触发样本写回数据排除清单与清洗规则。[6]

3. **现象**：训练做完却无法上线，运维与成本压垮团队。  
   **根因**：只算训练成本，不算推理与维护成本。  
   **修复**：在决策卡里写清推理成本上限与 SLA；灰度阶段用真实流量测算成本与延迟；若长期成本越界，优先做路由、量化、蒸馏或策略回退，而不是硬上预训练。[44]

## 交付物清单与验收标准
- 预训练决策卡与止损线。[44]
- 评测基线与对比报告（含守门指标）。[6]
- 上线与回滚计划（模型/策略版本化）。[6]

## 下一章
预训练讨论让模型更像你的领域。下一章进入后训练：如何用 SFT/DPO/RLHF 等方法把行为调成可控，并把安全与回归纳入门禁。见：[15-posttrain-rl.md](15-posttrain-rl.md)。

## 参考
详见本书统一参考文献列表：[references.md](references.md)。本章正文中的引用编号 [n] 对应该列表中的同号条目。
