# 第 17 章：部署与运维：灰度、监控与回滚
![Chapter 17 Header](../../assets/chapter_17_header_1766035971472.png)

> 上线不是把版本推上去，而是把不确定性纳入治理：你知道如何灰度、如何观测、如何回滚、如何复盘。没有回滚的发布，等价于赌博。[5][6]

AI 产品的运维挑战更尖锐：模型/提示/检索/工具任何一处变化都可能改变行为分布；你不只要监控错误率，还要监控质量、成本与风险面。把这些纳入发布门禁，你才能持续迭代而不被线上事故拖垮。[6]

## 章节定位
本章承接推理优化与评测门禁，讲如何安全地发布与长期运行：版本管理、灰度策略、监控口径、回滚与复盘。它的目标是让你在低资源条件下仍能建立可控上线的操作系统。[5]

## 你将收获什么
- 一套发布策略：从小流量灰度到全量，何时推进、何时暂停、何时回滚。[5]
- 一份运维观测口径：质量/延迟/成本/风险四线同看。[6]
- 一份 Runbook 模板：事故发生时你按表执行，而不是凭情绪决策。[5]

## 三层思考：运维是让系统长期不坏
### 第 1 层：读者目标
你要获得持续迭代的能力：上线不怕、退化可控、事故可复盘。

### 第 2 层：论证链条
可控发布链条是：

版本化（代码/配置/提示/模型）→ 灰度策略 → 观测口径 → 告警与处置 → 回滚与复盘 → 回归集更新

缺版本化，你无法解释变化；缺回归集，你无法防止复发。[6]

### 第 3 层：落地与验收
验收看三件事：
- 你能明确说明这次发布改了什么（可追溯）；
- 你能在 10 分钟内完成回滚或降级（可执行）；
- 你能产出一份复盘并把失败样本回写进回归集（可复利）。[6]

## 版本化：把变化变成可追溯对象
AI 系统的版本不止代码，还包括：
- 提示与输出合同
- 检索配置与索引版本（RAG）
- 工具清单与权限边界（Agent）
- 模型版本与后训练策略

最低要求：任何一次线上行为都能指向一组明确版本（用于复盘与回放）。[6]

## 灰度发布：把风险拆小
灰度的本质是：在真实分布下验证，但把影响面控制在可承受范围内。[5]

![图 17-1：可控发布流程（版本化→灰度→观测→回滚→复盘）示意（占位）](../../assets/figure_17_1_1765971453223.png)

**模板：灰度策略卡**

| 维度 | 说明 |
| --- | --- |
| 灰度对象 | 内测用户/小比例租户/特定场景 |
| 观察窗口 | 例如：24 小时/一周（与使用周期一致） |
| 通过门槛 | 质量/延迟/成本/风险阈值 |
| 暂停条件 | 任一守门指标越界 |
| 回滚方式 | 版本回退/功能开关/降级路径 |

### 灰度推进的操作手册：推进/暂停/回滚三件事
灰度最折磨人的瞬间通常发生在看起来没大问题，但数据开始抖：上线后 30 分钟，告警没响，核心转化也没明显掉，但你看到 P95 轻微上扬、少量用户反馈有点慢，团队开始争论这算不算退化。这种时候，最容易发生两种失误：要么硬着头皮继续放量，把不确定性放大；要么过度恐慌立刻回滚，把真正的收益也扼杀掉。

更稳的做法是把灰度决策压缩成三件事，并且为每件事配套必须留的证据和复盘要补的样本。你不需要现场辩论，你只需要按表执行：先判断信号，再执行动作，再固化证据与回归资产。[5][6]

灰度期间的默认心态是：**不确定就先暂停**；**守门指标越界就回滚**；**推进必须有证据**。推进不是胆量，是对口径与证据的信任。[6]

| 信号（以基线为准） | 动作 | 你必须记录的证据（用来复盘/回放） | 复盘要补的回归样本（让问题不复发） |
| --- | --- | --- | --- |
| 守门指标稳定；关键体验（质量线）与关键业务指标同向或基本不变 | 推进（扩大灰度或延长观察窗口） | 当前版本集合（代码/配置/prompt/模型/索引）；关键面板截图；抽样请求的 `trace_id` 与响应对比；用户反馈摘要 | 新增收益样本：体现改动带来的真实价值闭环；补齐不同用户段/不同输入长度的代表性样本 |
| 指标波动但仍在历史波动范围；存在噪音或样本量不足，无法裁决 | 暂停（维持流量不变，进入排查） | 分桶对比（新/旧版本、不同租户/地区/入口）；失败请求样本与日志；排队/缓存命中等解释变量 | 新增分布样本：把造成波动的特定分桶（某类输入、某入口、某租户）沉淀进回归集 |
| 守门指标明显恶化（错误率/超时率/成本越界）；或出现可复现的用户关键失败 | 回滚（立即切回上一稳定版本/稳定模式） | 回滚触发时刻与条件；告警与指标变化曲线；最小复现请求；回滚后指标恢复证明 | 新增事故复发样本：把最小复现样本写入阻断级回归；补充相邻边界（更长/更短输入、弱网、工具失败） |
| 高风险事件：越权/泄露/注入突破边界；或成本失控影响现金流 | 立即止损（强回滚 + 关闭入口/开关） | 审计记录（谁/何时/对什么）；触发链路与攻击样本；影响面评估；对外说明草稿 | 新增红线样本：攻击样本进入固定红队集；把触发条件固化为门禁（命中即阻断） |

## 监控口径：四条线同看
AI 产品上线后至少要同看四条线：[6]
- **质量线**：用户是否解决问题（反馈、采纳率、失败样本）。
- **延迟线**：P50/P95、超时率、重试率。
- **成本线**：单次成本、日消耗、尖峰消耗。
- **风险线**：越权尝试、注入命中、敏感内容与拒答质量。

## 观测性：把看见发生了什么变成默认能力
AI 系统的事故往往不是单点故障：模型变了、索引变了、工具权限变了、prompt 变了，最后表现为某类用户体验变差。如果你缺少可追溯的观测链路，复盘就会变成讲故事。最低要求是把日志、指标、链路追踪三件套打通，并且让每一次请求都能在三者之间对齐。[61]

![图 17-2：观测性三件套如何服务灰度与回滚](../../assets/figure_17_2_observability_stack.svg)

### OpenTelemetry：统一日志/指标/链路的语义
OpenTelemetry 的价值不是又一个 SDK，而是让你能用统一的字段把一次请求串起来：从 API 网关 → 推理服务 → 检索/工具调用 → 结果返回。这样你才能回答慢在哪里、贵在哪里、错在哪里。[61]

**模板：最小可观测字段合同（建议写进输出/日志规范）**
- `request_id` / `trace_id`：一次请求的全链路标识。[61]
- `user_id` / `tenant_id`：用于限流、成本归因与安全审计（注意脱敏/合规）。
- `model_version` / `prompt_version` / `rag_index_version`：把行为变化绑定到版本。[6]
- `tool_calls`：工具名、次数、耗时、失败原因（能定位工具导致的慢/贵/错）。
- `tokens_in/tokens_out`、`latency_ms`、`cache_hit`：成本与延迟的最小闭环。[6]

## 指标与面板：Prometheus + Grafana 的组合拳
指标体系的核心不是收集很多数据，而是让守门指标可以被持续观察、被告警、被用于回滚决策。Prometheus 适合做时序指标采集与告警规则，Grafana 负责把它们变成可读的面板与值班入口。[62][64]

**模板：发布守门指标（建议至少覆盖以下 6 类）**
- 质量：成功率/失败率、用户反馈（或离线抽样分数）。[6]
- 延迟：P50/P95、超时率、排队时间。[6]
- 成本：单次成本、Token 预算越界率、缓存命中率。[6]
- 稳定性：5xx、重试、OOM/过载保护触发次数。[6]
- RAG/工具：检索命中率、工具调用失败率/耗时。[6]
- 风险：越权尝试、注入命中、敏感内容触发率。[6]

**最小告警原则**
- 告警必须绑定动作：降级/限流/回滚三选一；没有动作的告警等于噪音。[6]
- 告警必须绑定版本：能回答从哪个版本开始变坏。[6]

## 一个能跑的最小观测闭环（Python）：trace_id + /metrics
观测性最容易变成买工具。但对个人与小团队来说，你更需要的是先建立可追溯闭环，再决定是否上更重的栈。

这里直接复用上一章的可运行示例（标准库实现）：`docs/examples/inference/budgeted_gateway.py`。

启动命令（mock 模式）：

```bash
python3 docs/examples/inference/budgeted_gateway.py --provider mock --port 8787
```

1) 发起请求时带上 `x-trace-id`：

```bash
curl -sS -X POST http://127.0.0.1:8787/chat \
  -H 'content-type: application/json' \
  -H 'x-trace-id: canary-0001' \
  -d '{"user_id":"u1","prompt":"写一份 10 分钟止损 runbook","budget_ms":1200}'
```

2) 你会在响应与日志里拿到同一个 `trace_id`，这就是可追溯的最小单位（后续你可以把它对齐到 OTel trace）。[61]

3) 访问指标端点：

```bash
curl -sS http://127.0.0.1:8787/metrics | head
```

你会看到 Prometheus 文本格式的指标（请求总量、成功/失败、缓存命中、inflight、延迟总和）。这份最小闭环足够你把灰度推进/暂停/回滚的决策从情绪变成口径：例如当 `gateway_requests_error` 或 `gateway_inflight` 异常上升时，Runbook 触发降级或回滚。[6]

## 推理服务形态：从能跑到可运维
当你把推理放进产品体系，服务形态会直接影响可控性：并发、伸缩、发布、监控、权限隔离都需要一套可运维的承载方式。

### KServe：把推理当作工作负载管理
KServe 更像是推理的运维壳：围绕部署、滚动更新、伸缩与流量治理提供标准化入口，适合把推理服务纳入统一的发布与运维系统里。[63]

### TGI：把推理服务的关键能力做成标准件
TGI 的定位更偏向推理服务产品化：让你以更低的工程成本获得并发、流式输出与基础运维能力，适合在早期把服务先跑稳，再逐步引入更深的性能优化。[49]

## 告警与处置：先保底，再优化
当告警触发，你的第一目标不是修得漂亮，而是止损。建议优先级：
1) 降级高成本/高风险路径（减少工具、缩短上下文、关闭某入口）
2) 限流（按用户/租户预算）
3) 回滚到上一版本
4) 进入复盘与补回归

## 模板：事故 Runbook（10 分钟版）
| 步骤 | 你要做什么 | 产出 |
| --- | --- | --- |
| 1 | 确认影响面（谁/多少/哪些功能） | 影响范围说明 |
| 2 | 触发止损（降级/限流/回滚） | 止损动作记录 |
| 3 | 保留证据（日志/请求样本/版本） | 证据包 |
| 4 | 定位根因（最小复现） | 失败样本 |
| 5 | 补门禁与回归（防复发） | 回归集更新 |
| 6 | 写复盘（结论与行动项） | 复盘文档 |

### 一次 10 分钟止损该怎么走（让你在压力下也能执行）
事故发生时，人最容易犯的错是急着解释。你会下意识地把注意力放在到底哪里错了，而不是如何先把损失停住。Runbook 的价值是把决策顺序反过来：先止损，再定位；先保留证据，再复盘叙事。[5]

一个更可执行的心智模型是：把 10 分钟切成 3 段，每段只做一件事。

1) **第 1–3 分钟：确认影响面**
你要回答的不是发生了什么，而是谁正在受影响。只要影响面不清楚，你后续所有动作都容易过度或不足。

2) **第 3–7 分钟：触发止损**
优先级永远是：能降级就先降级，能限流就先限流，能回滚就回滚。止损动作越早，后续定位越从容；越晚，你就越容易被线上噪音带偏。[5][6]

3) **第 7–10 分钟：保留证据并固定版本**
在你开始修复之前，先把证据包固定下来：请求样本、关键日志、指标截图、当前版本号与配置快照。否则你很可能会遇到最痛苦的一种事故：你已经改了一堆东西，但无法复现，也无法证明修复有效。[6]

如果你发现自己已经开始争论是不是要回滚，那通常说明 Runbook 太晚被执行了。把何时回滚/如何回滚前置写进灰度策略卡，事故时才能按表执行，而不是靠胆量。[5]

## 复现检查清单（本章最低门槛）
- 发布可追溯：能指向代码/配置/提示/模型/索引的版本组合。[6]
- 灰度可执行：通过门槛、暂停条件、回滚方式事先写清。[5]
- 四线监控可用：质量/延迟/成本/风险至少各 1 个守门指标。[6]
- Runbook 可执行：10 分钟内能止损并保留证据。[5]

## 常见陷阱（失败样本）
1. **现象**：出了事故才发现不知道改了什么。  
   **根因**：提示/配置/索引没有版本化，变化不可追溯。  
   **修复**：把所有影响行为的对象纳入版本管理；上线行为可回放。[6]

2. **现象**：灰度看起来没问题，全量后爆雷。  
   **根因**：灰度样本不代表真实分布；缺少守门指标。  
   **修复**：用守门指标裁决；扩大灰度覆盖面，增加攻击/边界样本。[6]

3. **现象**：回滚很慢，越拖损失越大。  
   **根因**：回滚依赖人工拼命；缺少降级路径与开关。  
   **修复**：把回滚写进发布策略；把降级当默认能力。[5]

## 交付物清单与验收标准
- 灰度策略卡与通过/暂停门槛。[5]
- 四线监控口径与阈值（质量/延迟/成本/风险）。[6]
- Runbook（含证据包与回归更新流程）。[5]
- 可观测字段合同与落地证明：能用 `trace_id` 串起一次请求的关键耗时与成本归因。[61]
- 一张可执行仪表盘：Prometheus 采集 + Grafana 面板 + 告警规则 + 对应处置动作。[62][64]
- 推理服务运行形态说明：你选择 KServe/TGI/自研的原因与回退路径。[49][63]

## 下一章
运维解决如何持续上线而不爆。下一章把评测体系写成门禁：离线/在线、红队与回归，让每次变化都可裁决。见：[`18-evaluation.md`](18-evaluation.md)。

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
