# 第 8 章：数据工程 —— 训练的燃料

> 数据质量决定模型上限：采集、去重、去毒、脱敏与合成全流程可追踪且可回放。[34][35][36]

!!! note "关于复现、目录与 CI"
    本章中出现的 `make ...`、`CI`、目录名（如 `data/`、`tests/`、`reports/` 等）用于说明一种可复现的工程化落地方式。本仓库仅提供文档，读者需要在自己的项目仓库中按需实现/调整这些脚本与自动化门禁。

## 章节定位
本章奠定“模型好坏先看数据”的基础。你将建立可审计的数据管线，确保版权合规、质量可量化，并通过合成数据放大高质量样本。[34][36]

## 你将收获什么
- 可重放的数据采集与清洗流水线，附 datasheet 与许可证记录。[34]
- 去重/去毒/PII 过滤脚本，量化数据纯度与覆盖率。[35]
- Self-Instruct/Evol-Instruct 合成数据流程，生成高质量微调样本。[36]

## 方法论速览
1. **来源管理：** 记录数据来源、许可证、采集时间与用途，遵循 datasheet 标准。[34]
2. **质量控制：** 去重、内容安全过滤、格式标准化；质量指标纳入 CI。[35]
3. **数据合成：** 用强模型生成指令/对话，增加多样性与难度，人工抽样验收。[36]

## 实战路径
### 1. 采集与存证
- 使用爬虫/公开数据集，下载后立刻生成 SHA256 与许可证记录。
- 将元数据写入 `datasheets/*.yml`，字段包含来源、用途、限制、采集人、时间。[34]

### 2. 去重与去毒
```python
from datasketch import MinHash, MinHashLSH

lsh = MinHashLSH(threshold=0.85, num_perm=128)
# 将每条文本转 MinHash，插入 LSH，过滤重复
```
- 运行毒性/暴力/隐私检测模型，对高风险样本打标签或剔除。

### 3. 格式与统计
- 统一为 JSONL：`{"instruction": ..., "input": ..., "output": ...}`，确保键完整。
- 统计词频、长度分布、多样性指标，确保不存在单一领域垄断。

### 4. 合成数据
- Self-Instruct：用 GPT-4 生成多样指令与答案，涵盖推理、工具使用、对话礼貌。[36]
- Evol-Instruct：在原指令基础上增加复杂度（多约束、多轮上下文），提升模型推理能力。
- 对合成样本抽样人工复核，记录拒绝/修改原因，形成反馈数据。

## 复现检查（落地建议）
- `make data-clean`：执行去重、去毒、PII 过滤与格式化，CI 校验字段与统计。
- `make data-synth`：自动生成合成数据与审计报告，包含模型版本与成本记录。
- 数据版本号写入 `VERSION` 文件，任何变更需更新并在 commit 中说明。

## 常见陷阱
- **许可证不清：** 未记录来源与限制，导致后续发布受阻。必须在 datasheet 中写明可用范围。[34]
- **去重阈值过严/过松：** 过严导致数据损失，过松导致泄漏，需基于验证集性能调节阈值。[35]
- **合成数据偏见：** 强模型生成的偏见会放大，需多样化人物设定与审查。

## 延伸练习
- 对比不同去重阈值对下游 SFT loss 的影响，选择收益/成本最优点。
- 使用小模型对合成数据做“反事实”检查，筛除容易出错的样本。

## 交付物与验收（落地建议）
- `datasheets/` 元数据、采集脚本与清洗脚本；CI 报告。
- 去重/去毒统计、格式化后数据与抽样审查表。
- 合成数据与人工反馈记录，版本号与成本说明。

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
