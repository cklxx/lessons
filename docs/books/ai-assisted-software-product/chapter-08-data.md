# 第 8 章：数据工程 —— 训练的燃料

> 数据质量决定模型上限：采集、去重、去毒、脱敏与合成全流程可追踪且可回放。[34][35][36]

!!! note "关于复现、目录与 CI"
    本章中出现的 `make ...`、`CI`、以及示例目录/文件路径（例如 `path/to/file`）均为落地约定，用于说明如何把方法落实到你自己的工程仓库中。本仓库仅提供文档，读者需自行实现或用等价工具链替代。

## 章节定位
本章奠定“模型好坏先看数据”的基础。你将建立可审计的数据管线，确保版权合规、质量可量化，并通过合成数据放大高质量样本。[34][36]

## 你将收获什么
- 可重放的数据采集与清洗流水线，附 datasheet 与许可证记录。[34]
- 去重/去毒/PII 过滤脚本，量化数据纯度与覆盖率。[35]
- Self-Instruct/Evol-Instruct 合成数据流程，生成高质量微调样本。[36][66]

## 方法论速览
1. **来源管理：** 记录数据来源、许可证、采集时间与用途，遵循 datasheet 标准。[34]
2. **质量控制：** 去重、内容安全过滤、格式标准化；质量指标纳入 CI。[35]
3. **数据合成：** 用强模型生成指令/对话，增加多样性与难度，人工抽样验收。[36]

## 实战路径
- 示例（可复制）：把原始文本转为可训练 JSONL 并生成 datasheet

```text
目标：
将 `raw/*.txt` 清洗为训练用 JSONL（instruction/input/output），并生成 datasheet（来源/许可/脱敏说明）。

上下文：
- 输入：raw/（原始文本）
- 输出：data/sft.jsonl、datasheets/sft.yml、reports/data_audit.md、quarantine/

约束：
- 必须执行：去重、PII 过滤、格式校验；并输出统计（长度分布/重复率/过滤率）。
- 任何无法确认许可证的数据必须被隔离到 quarantine/。
 

输出格式：
- 只输出 unified diff（git diff 格式）

验证命令：
- make data-clean

失败判定：
- JSONL 格式不合法；或未产出统计与 datasheet；或 PII 过滤缺失。

回滚：
- git checkout -- data/ datasheets/ reports/
```

### 1. 采集与存证
- 使用爬虫/公开数据集，下载后立刻生成 SHA256 与许可证记录。
- 将元数据写入 `datasheets/*.yml`，字段包含来源、用途、限制、采集人、时间。[34]

### 2. 去重与去毒
```python
from datasketch import MinHash, MinHashLSH

lsh = MinHashLSH(threshold=0.85, num_perm=128)
# 将每条文本转 MinHash，插入 LSH，过滤重复
```
- 运行毒性/暴力/隐私检测模型，对高风险样本打标签或剔除。

### 3. 格式与统计
- 统一为 JSONL：`{"instruction": ..., "input": ..., "output": ...}`，确保键完整。
- 统计词频、长度分布、多样性指标，确保不存在单一领域垄断。

### 4. 合成数据
- Self-Instruct：用 GPT-4 生成多样指令与答案，涵盖推理、工具使用、对话礼貌。[36]
- Evol-Instruct：在原指令基础上增加复杂度（多约束、多轮上下文），提升模型推理能力。[66]
- 对合成样本抽样人工复核，记录拒绝/修改原因，形成反馈数据。

## 复现检查（落地建议）
- `make data-clean`：执行去重、去毒、PII 过滤与格式化，CI 校验字段与统计。
- `make data-synth`：自动生成合成数据与审计报告，包含模型版本与成本记录。
- 数据版本号写入 `VERSION` 文件，任何变更需更新并在 commit 中说明。

## 常见陷阱
- **许可证不清：** 未记录来源与限制，导致后续发布受阻。必须在 datasheet 中写明可用范围。[34]
- **去重阈值过严/过松：** 过严导致数据损失，过松导致泄漏，需基于验证集性能调节阈值。[35]
- **合成数据偏见：** 强模型生成的偏见会放大，需多样化人物设定与审查。

## 延伸练习
- 对比不同去重阈值对下游 SFT loss 的影响，选择收益/成本最优点。
- 使用小模型对合成数据做“反事实”检查，筛除容易出错的样本。

## 交付物与验收（落地建议）
- `datasheets/` 元数据、采集脚本与清洗脚本；CI 报告。
- 去重/去毒统计、格式化后数据与抽样审查表。
- 合成数据与人工反馈记录，版本号与成本说明。

下面把本章的数据工程实践抽象为可迁移原则：你可以换模型/换存储，但不换“合规、可追溯、可回放”的底线。

## 深度解析：核心原则
1. **合规先于规模**：数据的来源、许可证与用途约束要先被写进 datasheet；否则后续训练/发布都可能被一票否决。[34]
2. **质量可量化**：去重、去毒、PII 过滤要产出统计与抽样审查表；“我觉得干净”不构成验收标准。[35]
3. **合成数据要可审计**：合成样本必须记录生成模型版本、成本与拒绝原因；把失败样本反哺到合成提示与过滤器，而不是无限生成。[36]
4. **版本化与回滚**：任何数据变更都要可回滚（快照/版本号/差分统计），并能回答“这次训练用了哪些数据”。[34]

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
