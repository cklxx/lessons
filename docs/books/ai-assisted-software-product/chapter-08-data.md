# 第 8 章：数据工程 —— 训练的燃料

> 高质量模型始于高质量数据：来源可追溯、去重可量化、脱敏可审计、流程可回放。[34][35][36]

!!! note "关于复现、目录与 CI"
    本章中出现的 `make ...`、持续集成（CI）、以及示例目录/文件路径（例如 `path/to/file`）均为工程约定，用于演示如何将方法应用到你自己的工程仓库中。本仓库仅提供文档，读者需自行实现或用等价工具链替代。

## 章节定位
本章奠定“模型好坏先看数据”的基础。你将建立可审计的数据管线：来源追溯、合规许可证明与清洗逻辑都能说清楚；版权合规、质量可量化；并通过合成数据放大高质量样本。[34][36]

## 你将收获什么
- 可重放的数据采集与清洗流水线，附[数据卡片（Datasheet）](glossary.md#datasheet)与许可证记录。[34]
- 去重/有害内容过滤/PII（个人身份信息）过滤脚本，量化数据纯度与覆盖率。[35]
- 自指令（Self-Instruct）/进化指令（Evol-Instruct）合成数据流程，生成高质量微调样本。[36][66]

## 方法论速览
1. **来源管理：** 记录数据来源、许可证、采集时间与用途，遵循数据卡片规范。[34]
2. **质量控制：** 去重、有害内容过滤、格式标准化；质量指标纳入 CI。[35]
3. **数据合成：** 用强模型生成指令/对话，增加多样性与难度，人工抽样验收。[36]

![图 8-1：数据工程管线](../../assets/ch08-data-pipeline.png)

## 实战路径
```text
采集与存证（哈希校验与许可记录）→ 过滤与隔离（隔离区 `quarantine/`）→ 去重/有害内容过滤/脱敏 → 格式化 JSONL → 统计与抽检 → 版本化与回滚
```

### 示例（可复制）：把原始文本转为可训练 JSONL 并生成数据卡片（Datasheet）

**目标：** 将 `raw/*.txt` 清洗为训练用 JSONL（`instruction/input/output`），并生成数据卡片（Datasheet，包含来源/许可/脱敏说明），把“数据是否可用”变成可验证的门槛。[34][35]

**前置条件：**
- 你能把原始数据落盘到某个目录（例如 `raw/`），并为每个来源记录：获取方式、采集时间、用途与许可证。[34]
- 你愿意为“不确定/不可用”的数据提供隔离区（`quarantine/`），而不是硬塞进训练集。[34]

**上下文：**
- 项目形态：数据清洗与训练数据构建流水线
- 角色：数据/模型/合规（把训练输入变成可审计资产）
- 输入：`raw/`（原始文本）
- 输出：`data/sft.jsonl`、`datasheets/sft.yml`、`reports/data_audit.md`、`quarantine/`

**约束：**
- 必须执行：去重、PII 过滤、格式校验；并输出统计（长度分布/重复率/过滤率）。[35]
- 任何无法确认许可证的数据必须被隔离到 `quarantine/`，并在报告中说明原因。[34]
- 若使用 AI 辅助修改代码或文档：请要求它只输出统一差异（unified diff / `git diff` 格式），不要夹带解释文本，方便你直接应用与审查。

**输出格式：**
- 产物：`data/sft.jsonl`（每行一个样本）、`datasheets/sft.yml`（元数据）、`reports/data_audit.md`（统计与抽检）
- 命名：建议包含数据版本号（如 `data/sft.v20251216.jsonl`），并把版本写入数据卡片。[34]

**步骤：**
1. **采集与存证：** 下载原始数据后立刻计算 `SHA-256` 校验和，并记录来源/许可证；无法确认许可→直接进 `quarantine/`。[34]
2. **基础清洗：** 统一编码、去掉明显模板噪声（页眉页脚/导航/重复段落），并保留最小来源字段（source/url/ts）。[34]
3. **去重：** 使用 MinHash/LSH 或其他近似去重方法计算重复率，并把“去重前后规模变化”写进报告。[35]
4. **有害内容过滤与脱敏：** 对有害内容/暴力/隐私风险打标签；PII 命中样本按策略“剔除或脱敏重写”，但必须可审计。[35]
5. **格式化：** 将样本统一成 JSONL 的三段结构（instruction/input/output），并执行数据模式（Schema）校验（字段缺失=失败）。[35]
6. **抽样审查：** 对清洗后样本做分层抽样（按来源/长度/标签），人工抽检并记录拒绝原因（`reject_reason`），形成反馈闭环。[34]

**验证命令：**
```bash
make data-clean
# 预期输出包含：data/sft.jsonl + datasheets/sft.yml + reports/data_audit.md，且报告中包含重复率/过滤率/长度分布
```

**失败判定：**
- JSONL 格式不合法；或未产出统计与数据卡片；或 PII 过滤缺失；或 `quarantine/` 未被使用导致“许可不明混入训练集”。[34][35]

**回滚：**
- `git checkout -- data/ datasheets/ reports/ quarantine/`

### 1. 采集与存证
- 使用爬虫/公开数据集，下载后立刻生成 SHA256 与许可证记录。
- 将元数据写入 `datasheets/*.yml`，字段包含来源、用途、限制、采集人、时间。[34]

一个最小数据卡片（Datasheet）示例（可落地到 `datasheets/sft.yml`）：[34]

```yaml
name: sft
version: v20251216
sources:
  - id: forum-a
    acquired_at: "2025-12-16"
    license: "CC BY-SA 4.0"
    uri: "https://example.com/dataset"
    notes: "public posts; exclude deleted content"
intended_use:
  - "instruction tuning for product support assistant"
restricted_use:
  - "no PII; no credentials; no payment data"
pii_policy:
  action: "drop_or_mask"
  fields: ["email", "phone", "address", "id_number"]
processing:
  dedup: {method: "minhash_lsh", threshold: 0.85}
  toxicity_filter: {enabled: true}
  format: "jsonl: instruction/input/output"
```

### 2. 去重与有害内容过滤
```python
from datasketch import MinHash, MinHashLSH

lsh = MinHashLSH(threshold=0.85, num_perm=128)
# 将每条文本转 MinHash，插入 LSH，过滤重复
```
- 运行有害内容/暴力/隐私风险检测模型，对高风险样本打标签或剔除。

将“去重阈值”参数化，并通过对比实验确定最优值，避免单纯依赖经验设定：[35]

| 阈值 | 去重后保留率 | 验证集 loss（损失值）变化 | 备注 |
|---:|---:|---:|---|
| 0.80 |  |  | 更激进，风险：丢失有效多样性 |
| 0.85 |  |  | 常用折中 |
| 0.90 |  |  | 更保守，风险：泄漏与过拟合 |

PII 过滤的最小“禁区清单”（示例，按地区合规要求补齐）：[35]
- 身份凭据：API key、token、cookie、私钥片段
- 个人信息：邮箱、手机号、地址、身份证/护照号
- 支付信息：卡号、CVV、账单地址、支付凭据
- 内部机密：内网域名、工单号、未公开链接（如果属于公司数据）

### 3. 格式与统计
- 统一为 JSONL：`{"instruction": ..., "input": ..., "output": ...}`，确保键完整。
- 统计词频、长度分布、多样性指标，确保不存在单一领域垄断。

建立标准化的“数据健康度”审计报告（示意，落地到 `reports/data_audit.md`）：[35]

| 指标 | 定义 | 目标/门槛（示例） | 备注 |
|---|---|---|---|
| 重复率 | 去重前后差分 | < 15% | 过高=泄漏与模板化 |
| PII 命中率 | PII 检测器命中比例 | < 0.5% | 视场景而定 |
| 有害内容（Toxicity）检出率 | Toxicity 标签占比 | < 1% | 视场景而定 |
| 长度分布 | token（词元）分位数（P50/P95） | P95 < 上下文窗 * 0.8 | 防止截断 |
| 领域覆盖 | 来源/标签分布熵 | 不低于基线 | 防止单域垄断 |
| 语言覆盖 | zh/en/… 占比 | 与目标一致 | 多语需分层 |

### 4. 合成数据
- Self-Instruct：用 GPT-4 生成多样指令与答案，涵盖推理、工具使用、对话礼貌。[36]
- Evol-Instruct：在原指令基础上增加复杂度（多约束、多轮上下文），提升模型推理能力。[66]
- 对合成样本抽样人工复核，记录拒绝/修改原因，形成反馈数据。

![图 8-2：合成数据闭环](../../assets/ch08-synthetic-data-loop.png)

一个可执行的“合成数据提示约定”（示意，避免生成不可审计样本）：[36][66]

```text
目标：生成指令微调样本（instruction/input/output），覆盖真实业务边界。
约束：
- 必须显式标注“是否需要外部工具/是否允许联网”：默认不允许。
- 输出必须包含：difficulty（难度 1–5）、tags（标签）、safety_flags（安全标记）。
- 禁止输出：任何凭据样式字符串、PII、支付信息。
验证：抽样人工审查 50 条，记录拒绝原因（`reject_reason`）分布。
```

![图 8-3：数据版本化](../../assets/ch08-data-versioning.png)

## 复现检查清单
- `make data-clean`：执行去重、有害内容过滤、PII 过滤与格式化，CI 校验字段与统计。
- `make data-synth`：自动生成合成数据与审计报告，包含模型版本与成本记录。
- 数据版本号写入 `VERSION` 文件，任何变更需更新并在 commit 中说明。

## 常见陷阱
1. **现象：** 数据集看起来“很大”，但训练后无法发布或因合规问题被一票否决。  
   **根因：** 许可证/用途约束未记录；来源不可追溯，导致无法证明可用范围。[34]  
   **复现：** 随机抽 100 条样本，问：来自哪里？许可是什么？能否商用？如果答不上来，就是不可审计。  
   **修复：** 强制数据卡片；许可不明→进入 `quarantine/`；发布前做一次“来源抽查”并记录。[34]  
   **回归验证：** `reports/data_audit.md` 必须包含来源分布与许可清单，且抽检可回溯到具体 uri。[34]

2. **现象：** 训练集与验证集发生泄漏，指标虚高，上线后性能失效。  
   **根因：** 去重只在单集合内做；跨数据集划分（split）/跨版本未做近似去重，重复样本泄漏。[35]  
   **复现：** 对 train/valid/test 做跨集合 LSH 去重，统计交集比例。  
   **修复：** 把去重作为“跨数据集划分（split）”的门禁；对新增数据做增量去重，输出差分统计。[35]  
   **回归验证：** 数据版本变更时，CI 输出 train/valid/test 泄漏率，超阈值直接失败。

3. **现象：** 合成数据呈现高度同质化或单一模式，导致模型输出缺乏多样性。  
   **根因：** 合成提示单一、人物设定单一、过滤策略过于简单，导致偏见被放大。[36][66]  
   **复现：** 统计合成数据的标签（`tags`）/难度/文体分布；若集中在少数模式，说明多样性不足。  
   **修复：** 引入多人物设定（persona）、多任务族、多难度层级；对输出做风格去重与多样性约束；人工抽检记录拒绝原因（`reject_reason`）并回写提示。[36]  
   **回归验证：** 抽检报告显示拒绝原因（`reject_reason`）数量下降，多样性指标（如标签熵/覆盖）不低于基线。

4. **现象：** 数据里出现 PII/凭据，训练后模型“学会”输出敏感信息。  
   **根因：** 只做格式化，不做敏感信息检测；或把日志/工单直接入库未脱敏。[35]  
   **复现：** 对数据集跑一次 PII/secret（敏感凭据）扫描，抽查命中样本。  
   **修复：** 建立禁区清单与过滤策略（drop/mask/重写）；对敏感项目禁止把原始工单正文直接用于训练。[35]  
   **回归验证：** CI 报告中 PII/secret 命中率低于门槛；抽检样本不包含明显敏感字段。

## 延伸练习
- 对比不同去重阈值对下游 SFT loss（损失值）的影响，选择收益/成本最优点。
- 使用小模型对合成数据做“反事实”检查，筛除容易出错的样本。

## 交付物清单与验收标准
- `datasheets/` 元数据、采集脚本与清洗脚本；CI 报告。
- 去重/有害内容过滤统计、格式化后数据与抽样审查表。
- 合成数据与人工反馈记录，版本号与成本说明。

下面把本章的数据工程实践抽象为可迁移原则：你可以换模型/换存储，但不换“合规、可追溯、可回放”的底线。

## 深度解析：核心原则
1. **合规先于规模**：数据的来源、许可证与用途约束要先被写进数据卡片；否则后续训练/发布都可能被一票否决。[34]
2. **质量可量化**：去重、有害内容过滤、PII 过滤要产出统计与抽样审查表；“我觉得干净”不构成验收标准。[35]
3. **合成数据要可审计**：合成样本必须记录生成模型版本、成本与拒绝原因；将失败样本反馈至合成提示与过滤器，而不是无限生成。[36]
4. **版本化与回滚**：任何数据变更都要可回滚（快照/版本号/差分统计），并能回答“这次训练用了哪些数据”。[34]

## 资料笔记（可选）
- [Datasheets（数据来源/许可/用途的说明模板）](../../materials/ai-assisted-software-product/notes/ref-034-datasheets.md)
- [数据去重（减少训练污染与评测虚高）](../../materials/ai-assisted-software-product/notes/ref-035-llm-dedup.md)
- [Self-Instruct（低成本生成指令数据）](../../materials/ai-assisted-software-product/notes/ref-036-self-instruct.md)
- [WizardLM / Evol-Instruct（进化指令）](../../materials/ai-assisted-software-product/notes/ref-066-wizardlm.md)

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
