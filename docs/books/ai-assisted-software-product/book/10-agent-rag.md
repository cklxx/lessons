# 第 10 章：Agent 架构与 RAG：证据、边界与回归

在构建智能系统的过程中，我们常常追求模型能够“更聪明”，能够理解更复杂的指令，执行更多样化的任务。然而，真正的挑战并非让模型在实验室环境中偶尔展现其潜力，而在于如何将其融入实际业务场景，确保其能够长期、稳定、可靠地运行。特别是当涉及生成式AI，如大语言模型（LLM）时，其固有的“幻觉”问题、执行任务时的“越权”风险以及系统成本与延迟的失控，都可能让用户对系统的信任瞬间崩塌。因此，将“聪明”转化为“可控”，是每个产品技术负责人必须直面的核心问题。

本章旨在为读者提供一套实用的决策与治理框架，聚焦于如何通过 Agent 架构与检索增强生成（RAG）技术，构建一个既智能又可控的AI系统。我们将探索在遇到幻觉、注入攻击、越权操作、成本飙升或延迟恶化等问题时，应优先审视哪些关键环节。更重要的是，本章将帮助你理解何时选择 RAG 以增强事实准确性，何时利用 Agent 实现自动化行动，以及何时需要回归到产品设计和数据质量的根本问题，而非盲目追求技术上的“智能”。

## 章节定位

本章在整体架构中扮演着承上启下的关键角色，它位于“全栈底座”的坚实构建之后，标志着我们正式迈入“智能层”的构建。不同于专注于某个特定技术框架的实现细节，本章的核心目标是将“智能”封装成一个可治理、可审计的系统。这意味着我们不仅要关注功能实现，更要着重于建立一套全面的管理机制，确保智能系统的运行符合预期，并且在出现偏差时能够迅速定位与纠正。

具体而言，我们将围绕三个核心治理原则展开：首先是**证据链**，确保模型的所有回答都能追溯到清晰的来源片段，任何无引用或无法验证的回答都应被视为失败。其次是**边界**，为模型的工具调用（Agent 能力）设定严格的白名单、Schema 校验、预算限制和明确的停止条件，任何越权行为都将触发系统阻断。最后是**回归**，强调在任何系统改动后，都需要通过同口径的评测体系进行对比验证，一旦发现性能或安全指标退化，必须能够及时回滚。这些原则共同构成了智能层的基础治理体系。更深层次的 RAG 实现细节和 Agent 行为模式，将在 [`10-agent-rag-rag.md`](10-agent-rag-rag.md) 和 [`10-agent-rag-agent.md`](10-agent-rag-agent.md) 两章中进行深入探讨。

## 你将收获什么

通过本章的学习，你将获得一套关于 Agent 架构与 RAG 融合的全面认知与实践框架，而不仅仅是零散的技术点。首先，你将理解一个**端到端闭环**的智能系统是如何运作的，这涵盖了从数据摄入、检索策略、内容生成、工具调用、到线上审计落盘以及最终的评测回归的全链条。其次，你将掌握一套**最小门禁**的落地策略，例如如何强制实现“无引用即失败”的知识问答规则、如何阻断非法工具调用、以及如何通过失败样本集进行持续回归测试，确保系统的健壮性和安全性。

此外，本章还将提供一张实用的**“选型决策表”**。这张决策表将帮助你在面对不同的业务挑战时，清晰地判断是优先采用 RAG 来解决信息准确性问题，还是通过 Agent 赋予模型行动能力，抑或是暂时放弃“智能”的幻想，回归到产品设计或数据质量的源头问题。最终，本章将赋能你构建一个不仅功能强大，而且可信、可控、可演进的 AI 辅助软件产品。

## 把“聪明”变成“可控”

将一个“聪明”的AI模型转化为一个“可控”且能够在生产环境中稳定运行的智能系统，需要产品与技术团队进行多维度的深入思考。这并非仅仅是技术实现层面的问题，更是关于用户体验、系统健壮性和业务风险管理的系统性工程。我们将其凝练为三个层面的思考，层层递进，帮助你构建一个既强大又可靠的智能系统。

先把这章要解决的核心矛盾和边界说清楚。

在设计任何智能系统时，我们首先要明确的是用户真正需要什么，以及我们希望为用户提供怎样的确定性。这种确定性可以被拆解为两个核心维度。首先是**结果的确定性**：用户需要确信从系统中获取的信息是准确的、有据可查的。这意味着系统提供的每一个回答都应该是可验证的，能够回溯到其原始来源，并允许用户进行复核。当模型产生幻觉或提供错误信息时，用户将失去对系统的基本信任。一个好的智能系统，其回答必须如同法庭证据一般，有理有据，可追溯，确保用户获得可靠的知识。

其次是**行为的确定性**：当系统拥有 Agent 能力，能够执行操作时，用户需要清楚地知道这个系统“能做什么”、“不能做什么”，以及在执行过程中“做到哪一步就会停止”。这种透明度是建立信任的关键。例如，一个具备邮件发送能力的 Agent，用户必须知道它是否能访问所有联系人、发送任意内容，以及在何种情况下会停止发送。缺乏清晰的权限边界和执行规则，会导致用户在使用时充满疑虑，甚至拒绝使用，因为他们无法承担潜在的错误或越权行为带来的风险。通过明确这些边界，我们可以让用户在使用智能系统时感到安心和可控。

再把从问题到方案再到验收的推演补齐。

智能层的建设并非一蹴而就，而是一个环环相扣、逻辑严密的论证链条。这个链条从最开始的**任务定义**出发，它要求我们清晰地界定智能系统所要解决的具体问题和目标。紧接着，我们需要深入分析潜在的**失败模式**，预判系统可能在哪里出错，例如出现幻觉、指令注入、越权操作等。对这些失败模式的预判是构建防御机制的基础。一旦识别了失败模式，我们就需要构建**证据链（RAG）**来对抗信息不准确的问题，确保模型能够从可靠的外部知识源中获取信息，并能指明其信息来源。

同时，为了应对模型可能带来的行动风险，我们需要设计**行为边界（Agent）**，通过工具定义、权限控制、调用预算等机制，严格限定 Agent 的行动范围。然而，仅仅有这些还不够，一个健康的智能系统必须包含**评测门禁**，通过建立量化的指标和自动化测试来持续评估系统的表现，及时发现退化。所有的线上行为都需要通过**线上审计与观测**来记录和分析，确保每一个关键决策和操作都能被追溯。最终，当系统表现不佳或出现问题时，能够通过**退化回滚**机制迅速恢复到稳定状态。这个论证链条揭示了一个核心真理：**只要评测与审计环节缺失，任何看似有效的“优化”都将最终演变为不可解释、不可预期的系统漂移。**

最后落到可执行的门禁、证据与回滚。

在智能系统的落地与验收阶段，我们必须摆脱“感觉更聪明”的主观判断，转而依赖清晰、量化的“门槛”标准。这意味着验收成功的核心不再是用户对“智能”的模糊感知，而是系统是否能够满足一系列严格的功能与安全指标。首先，对于任何知识型问答或信息生成任务，核心的验收标准是**回答必须带引用，或者明确拒答/追问**。如果模型给出的答案无法追溯到明确的引用来源，那么无论其内容听起来多么合理，都应被视为失败。这是对抗幻觉、建立用户信任的基石。

其次，当系统具备 Agent 能力、能够调用外部工具时，其所有**工具调用必须在白名单与预算内**。任何不在预设工具白名单内的调用尝试、参数不匹配的请求、或者超出权限范围的操作，都应被立即阻断。这种“越权即阻断”的策略，是确保 Agent 安全性和可控性的关键。最后，每一次对智能系统的改动，无论是模型更新还是策略调整，都**必须通过回归集验证**。这意味着系统要有一套针对常见失败模式（如指令注入、长上下文理解、边界语义等）的固定测试集。如果改动导致系统在这些回归测试中出现退化，那么该改动就应被回滚。这些严格的验收标准，共同构筑了智能系统从开发到部署全生命周期的质量保障。

![图 10-1：智能层端到端闭环（证据链/边界/评测/审计）示意](../../../assets/figure_10_1_1765971099603.png)

## 先做决策：你到底需要 RAG 还是 Agent

在构建 AI 辅助软件产品时，面对 RAG（检索增强生成）和 Agent（智能体）这两种强大的范式，许多团队往往会陷入选择困境，甚至盲目追求最新的技术。然而，一个成功的智能系统首先需要一个清晰的决策框架。核心问题在于：**你的系统当前面临的挑战是“信息缺失”还是“行动力不足”？**这两种问题需要截然不同的解决方案。下面的决策表提供了一个思考路径，帮助你在投入资源之前，明确问题的本质，并选择最匹配的解法。

| 你遇到的问题 | 更可能的解法 | 为什么 |
| --- | --- | --- |
| 回答缺事实、编造引用（幻觉） | RAG | 你的模型缺乏**可检索的外部证据**来支撑回答，导致其“胡编乱造”。此时，核心在于补齐证据链，通过 RAG 从外部知识库中获取准确信息。Agent 在此场景下帮助不大，因为问题不在于执行，而在于知识。 |
| 需要调用外部系统完成任务 | Agent | 你的模型需要**实际的行动能力**来与外部世界互动，完成诸如发送邮件、查询数据库、执行代码等操作。RAG 仅能提供信息，无法执行动作。此时，Agent 通过工具调用机制，赋予模型“手脚”，使其能够“做事情”。 |
| 输出不稳定、风格漂移 | 评测与回归先行 | 无论 RAG 还是 Agent，如果系统输出质量波动大、难以预测，这通常表明你**缺乏稳定可靠的基线和评估机制**。在没有明确的质量衡量标准和回归测试体系下，任何所谓的“优化”都可能只是无谓的漂移，甚至导致系统性能退化。 |
| 成本与延迟失控 | 预算与降级先行 | 如果智能系统的运行成本过高或响应延迟无法接受，这通常是系统设计或资源分配的问题，而非 RAG 或 Agent 本身。你需要**优先建立预算限制和降级策略**，确保系统在经济可行性和用户体验可接受的范围内运行，然后再谈优化。 |
| 用户不信任、不敢用 | 证据与边界先行 | 当用户对智能系统抱有疑虑，不信任其提供的信息或执行的操作时，问题在于**系统缺乏透明度、可解释性和可控性**。RAG 的引用机制提供了证据，Agent 的边界限制（如权限、停止条件）提供了安全保障。让系统“可解释、可拒绝”是建立信任的关键。 |

**案例分析：某电商客服机器人**

**案例一：提升商品信息准确性（RAG的成功应用）**

一家大型电商平台希望通过AI客服机器人解答用户关于商品属性、库存、物流等问题。初期版本的机器人经常“一本正经地胡说八道”，比如用户询问某个型号手机的电池容量，机器人可能会编造一个不存在的参数。分析发现，这是因为大模型自身的训练数据无法实时覆盖最新、最细致的商品信息，且容易产生幻觉。

团队决定引入RAG架构。他们构建了一个包含所有商品 SKU 详细信息、库存数据库、物流状态的实时知识库。当用户提问时，机器人首先将用户问题转化为检索请求，从知识库中精确检索出相关商品信息、库存记录和物流数据，然后将这些检索结果作为上下文提供给大模型，让大模型基于“事实证据”进行回答。上线后，机器人关于商品信息的回答准确率显著提升，幻觉现象大大减少，用户满意度也随之提高。团队甚至实现了回答带引用来源，用户点击即可跳转到商品详情页或订单页面，极大地增强了信任感。

**案例二：自动化退货流程（Agent的成功应用）**

同一家电商平台在商品信息准确性得到提升后，注意到退货处理流程耗时且人工成本高昂。用户常常需要反复与客服沟通，提供订单号、退货原因等信息，并等待人工审核。团队希望 AI 能够自动化部分退货流程，减轻人工压力。

他们设计了一个具备 Agent 能力的退货处理智能体。这个 Agent 被赋予了几个核心工具：
1.  **查询订单信息工具：** 接入订单系统 API，根据用户提供的订单号获取商品、购买日期、退货政策等信息。
2.  **验证退货资格工具：** 结合订单信息和退货政策，自动判断用户是否符合退货条件（如是否在退货期内、商品类型是否支持退货）。
3.  **创建退货请求工具：** 如果符合条件，通过调用内部服务接口，自动在后台创建退货请求，并生成退货单号。
4.  **通知用户工具：** 通过短信或站内信，将退货处理进度和退货单号告知用户。

同时，团队设定了严格的**行为边界**：Agent 只能处理已付款订单的退货请求，不能执行退款操作，且必须在用户明确授权后才能创建退货请求。初期，他们还设定了“高价值商品”退货需人工介入的限制。上线后，大部分简单的退货请求实现了自动化处理，显著缩短了用户等待时间，降低了客服部门的工作量。

## 最小门禁（建议先落地这 5 条）

在智能系统设计和部署过程中，再强大的技术架构也需要一套严密的“门禁”机制来确保其安全、稳定和可靠。这些最小门禁并非可选项，而是构建企业级智能系统不可或缺的基石。它们是系统能够“长期稳定地跑”的根本保障。我们建议团队优先落地以下五条最小门禁：

1.  **引用缺失 = 失败**：对于任何涉及知识问答或信息提取的智能应用，如果模型在生成回答时无法提供可追溯的引用来源，或者引用的内容与回答事实不符，那么这个回答就应被明确标记为失败。这意味着在代码合并、功能上线前，必须强制要求回答带引用，或者在无法引用时明确告知用户无法提供准确信息或进行追问。此门禁尤以知识问答类应用为甚，它是对抗“幻觉”最直接、最有效的手段。
2.  **非法工具调用 = 阻断**：当智能系统具备 Agent 能力，能够调用外部工具时，必须对其行为进行严格限制。任何不在预设工具白名单内的调用尝试、参数与工具 Schema 不匹配的请求、或者执行权限不足的操作，都应被系统立即阻断，并详细记录审计日志。这种“越权即阻断”的策略，是防止 Agent 误操作、数据泄露或恶意利用的关键防御。
3.  **失败样本集回归**：智能系统的迭代优化不应仅仅关注平均指标的提升。一个成熟的系统必须维护一套精心 curated 的“失败样本集”，其中包含各种边缘案例、攻击性指令（如指令注入）、长上下文理解挑战、边界语义歧义以及越权尝试等。每次代码改动或模型更新后，都必须强制要求通过这个失败样本集的回归测试。如果新的改动导致在这些已知失败模式上出现新的失败或原有失败未被修复，则该改动不予发布。
4.  **成本/延迟守门**：智能系统的运行往往伴随着计算资源和时间成本。每一次系统改动都必须提供同口径的质量、延迟和成本对比报告。例如，新的模型版本在提升回答准确率的同时，是否显著增加了推理时间或API调用费用？如果改动导致任何一项关键指标出现无法接受的退化（例如，推理延迟超过阈值，或单次调用成本显著上升），那么即使在其他方面有进步，也应考虑回滚，优先保证系统的整体服务质量和经济性。
5.  **审计可追责**：所有智能系统的核心行为，包括检索知识库、调用外部工具、生成内容并引用来源等，都必须进行详细且标准化的审计记录。这些记录应包含足够的信息，使得关键动作在未来可追溯、可重放。例如，记录检索时的查询语句、检索结果、Agent 调用的工具名称、入参、出参，以及模型生成答案时使用的具体引用片段。完整的审计链条不仅有助于故障排查和性能优化，更是满足合规性要求、明确责任归属的重要保障。

## 常见陷阱（失败样本）

在构建 Agent 架构与 RAG 融合的智能系统时，许多团队会遭遇一些看似偶然实则必然的陷阱。这些陷阱往往是由于对系统治理和风险控制不足导致的。理解这些失败模式及其根源，并学习如何修复它们，对于提升系统的稳定性和用户信任至关重要。

**失败案例一：产品运营的“幻觉之旅”**

某内容平台推出了一款基于 RAG 的智能内容辅助工具，旨在帮助产品运营快速生成营销文案和产品介绍。上线初期，运营团队反响热烈，工具能够快速生成高质量的初稿。然而，随着使用深入，运营人员开始抱怨：“这工具偶尔非常精准，能抓住热点，但有时候又会编造一些闻所未闻的市场数据或用户反馈，让人哭笑不得，根本不敢直接发布！”

**现象**：线上偶尔表现惊艳，但时不时出现“幻觉”，编造事实，导致用户不敢完全依赖，使用率逐渐降低。
**根因**：团队在开发初期，过于关注模型在通用评测集上的平均指标，而忽视了对真实业务场景中“失败样本”的资产化和回归测试。他们没有建立一套包含运营反馈的“反例集”，导致优化方向被平均指标“漂白”，未能解决用户最痛的“幻觉”问题。当模型更新或知识库变化时，没有固定门禁来捕捉这种事实性错误。
**修复**：痛定思痛，团队建立了一个由运营人员提交的“幻觉样本库”和“错误引用样本库”。每次模型或 RAG 策略更新，都必须通过这两个样本库的回归测试。同时，强制要求所有内容生成必须附带内部知识库的引用链接，无引用或引用不匹配则直接标记为低质量。通过“无引用不发布”的强门禁，极大地遏制了幻觉。

**失败案例二：初创公司的 Agent “失控之手”**

一家初创公司开发了一款 AI 助理，旨在帮助用户管理日程、发送邮件和处理简单的财务报销。产品在小范围内测表现出色，Agent 能够根据用户指令灵活调用内部工具。然而，一次正式发布后，一位早期用户在尝试让 Agent “帮我发一封邮件给所有供应商，通知他们下周会议”，却不慎触犯了一个 Bug：Agent 循环调用了供应商邮件列表，并且在邮件内容生成上出现了偏差，发送了多封格式不统一甚至包含错误信息的邮件，导致了不小的沟通混乱。更糟糕的是，Agent 在尝试“整理我的报销单”时，因为缺乏明确的停止条件，多次尝试调用财务系统，甚至差点触发了重复报销。

**现象**：Agent 表现“勤奋”，但有时会执行过度的操作，或尝试调用非授权工具，导致成本飙升、外部系统压力增大，甚至产生业务风险。
**根因**：团队在设计 Agent 时，过于强调其“会做事”的能力，而忽略了**预算限制、停止条件和工具边界**的严格定义。Agent 被赋予了过于宽泛的权限，缺乏细粒度的控制，导致在面对模糊指令或异常情况时，未能进行有效阻断，而是持续尝试操作。没有明确的调用预算，也使得成本失控。
**修复**：团队重新审视了 Agent 的设计，为每一个工具调用设定了明确的**白名单机制**，并要求所有工具都必须定义严格的 **Schema（输入参数规范）**。同时，引入了**调用预算和停止条件**，例如，在一次会话中，Agent 对同一工具的调用次数限制，或在连续失败 N 次后自动停止。所有越权尝试都被定义为阻断级失败，并触发告警和详细审计记录，确保每个 Agent 行为都能被追溯。

## 读者练习

为了更好地掌握本章内容，并将其应用于实际项目中，请尝试完成以下练习：

1.  **评估你当前项目的幻觉风险：** 审视你正在开发或规划的智能应用，是否存在模型“编造事实”的风险。如果有，思考如何设计一个“引用缺失 = 失败”的门禁，并构思一份至少包含 5 个典型幻觉案例的失败样本集。
2.  **绘制智能层行动流图：** 如果你的项目包含 Agent 功能，请为其中一个核心任务（例如“日程管理”或“数据查询”）绘制一个详细的行动流图。在图中明确标注 Agent 将调用的所有外部工具、每一个工具的输入/输出 Schema、以及在哪些环节需要进行权限验证和预算检查。
3.  **设计一套最小审计字段：** 设想你的智能系统上线后，需要对 Agent 的关键行为进行审计。请列出至少 5 个你认为最重要的审计字段（例如：用户 ID、请求时间、Agent 动作、工具调用详情、RAG 检索关键词、引用来源等），并说明每个字段的意义。
4.  **构建你的回归测试清单：** 根据你对 RAG 和 Agent 常见陷阱的理解，为你的项目构建一份“最小失败样本回归测试清单”。清单中应包含至少 3 种针对 RAG 的失败模式（如长上下文、模糊查询导致错误引用），和 3 种针对 Agent 的失败模式（如指令注入、越权调用、循环调用）。
5.  **反思“智能”与“产品价值”：** 结合本章的决策表，思考你当前的项目是否真的需要 RAG 或 Agent 的深度介入。有没有可能通过更简单的产品设计或更高质量的数据清洗，就能解决当前面临的问题？尝试论证你的观点。

## 交付物清单与验收标准

完成本章所述的治理框架建设，你将能够交付以下关键产物，并用明确的验收标准来衡量其有效性：

1.  **智能层端到端闭环说明文档：** 详细阐述从用户请求到最终响应的整个智能处理流程，特别要突出其中证据链（RAG）、行为边界（Agent）、评测门禁及线上审计的关键节点和机制。
2.  **最小门禁规则与阈值配置清单：** 明确定义所有核心门禁（如引用强制性、非法工具调用的阻断规则、失败样本回归的通过率阈值、以及成本/延迟的容忍区间），并提供相应的技术配置或实现方案。
3.  **审计字段规范与追溯指南：** 制定一套标准的智能系统关键行为审计字段（包括检索、工具调用、引用信息等），并提供如何通过这些字段进行问题追溯、故障排查和合规性验证的指南。

这些交付物和验收标准将共同确保你的 AI 辅助软件产品不仅具备强大的智能能力，更是一个可信赖、可管理、可持续发展的系统。

## 下一章

在成功构建并治理了智能层之后，我们将把目光转向“产品模块”的核心要素。下一章将深入探讨如何将用户管理、权限体系、计费模型以及数据管理等业务逻辑，无缝集成到整个软件产品中，从而实现商业闭环并构筑强大的风险防御体系。敬请期待：[`11-user.md`](11-user.md)。

## 延伸阅读

-   [Agentic RAG架构全解析：7种典型系统设计与实战应用 层级、多Agent、自适应、纠错型一次讲透｜大模型RAG进阶｜智能体Agent ...](https://www.bilibili.com/video/BV1e4E9zuEGh/)
-   [Agentic RAG 全面教程：从理论到实战 - Heywhale.com](https://www.heywhale.com/mw/project/6884b448916af1453c9e4bb8)
-   [Agent × RAG 联动系统实战：从推理决策到知识增强的动态协同架构设计_agent rag 推理-CSDN博客](https://blog.csdn.net/sinat_28461591/article/details/147672599)
-   [实战指南：从零构建 MCP 架构下的 Agentic RAG 系统，无第三方MCP Server - 知乎](https://zhuanlan.zhihu.com/p/1909185749624025459)
-   [从零学习大模型（13）——RAG 与 Agent 进阶：基于 LangChain 的落地实践与框架解析](https://www.woshipm.com/ai/6247270.html)
-   [手把手教你构建Agentic RAG：一种基于多文档RAG应用的AI Agent智能体](https://developer.volcengine.com/articles/7373874019113631754)
-   [从RAG到Agentic RAG：10章系统拆解大模型增强技术的进阶路径](https://www.sohu.com/a/913245490_122415966)
-   [企业级 RAG Agent 开发指南：RAG Agent 开发的 10 条实战准则 - 53AI-AI知识库|企业AI知识库|大模型知识库|AIHub](https://www.53ai.com/news/RAG/2025061906592.html)
