# 第 10 章（RAG 深入）：把回答改造成带证据的结论

在瞬息万变的人工智能时代，大型语言模型（LLM）的进步令人瞩目，它们能够生成流畅、连贯的文本，甚至在特定领域展现出惊人的理解力。然而，这些模型并非没有局限，其中最核心的挑战之一便是幻觉现象——模型可能自信地给出不准确、不连贯，甚至完全虚构的信息。当模型被应用于需要高精确度、可验证性的商业或专业场景时，这种内在的不确定性便构成了巨大的风险。

正是在这样的背景下，检索增强生成（Retrieval-Augmented Generation, RAG）技术应运而生，它不再仅仅依赖模型内部的记忆，而是赋予模型从外部知识库中检索相关信息并以此为依据生成回答的能力。但 RAG 的价值远不止于让模型知道更多，它的真正精髓在于将模型回答转化为带证据的结论，从而彻底改变我们对 AI 输出的信任范式。本章将深入探讨如何构建一个可信赖、可审计的 RAG 系统，让每一次模型回答都拥有坚实的证据支撑，最终实现从听起来有道理到确实有道理的质变。

## 章节定位

本章作为《AI 辅助软件产品》系列教程的深入篇，特别聚焦于 RAG 技术的核心命脉：**证据链的构建与维护**。如果说前一章介绍了 RAG 的基本概念与应用框架，那么本章则致力于将其从一个功能展示，提升为一项具备高度可信赖性与可审计性的生产级能力。我们将深入探讨从原始语料的精选、切分策略的制定，到高效检索、智能重排，乃至最终输出格式中强制引用的落地，以及如何通过严谨的评测门禁来确保持续的质量。

简而言之，本章旨在为您提供一份将模型输出转化为**可审计结论**的实践手册。这意味着我们不仅要追求回答的正确性，更要确保其可验证性和可追溯性，让每一个关键信息都能找到其权威的出处，从而在商业决策、用户服务乃至法律合规等高要求场景中发挥不可替代的价值。这不仅是技术层面的挑战，更是产品与信任机制构建的根本。

## 你将收获什么

通过本章的学习与实践，您将获得一套系统性的 RAG 产品开发与管理方法论。首先，您将学会如何制定一份清晰明确的**引用合同**，它将定义在您的产品中，可信赖的回答必须包含哪些证据，以及在证据不足时系统应如何应对，比如是明确拒答还是引导用户追问。这份合同将成为您团队内部沟通、设计系统接口和制定评测标准的核心基石。

其次，本章将为您提供一张实用的**RAG 设计卡**，涵盖数据范围、更新策略、检索策略、重排策略和拒答策略等关键维度。通过这张设计卡，您能够系统地规划和构建 RAG 系统的各个组件，确保其在性能、准确性和用户体验之间取得最佳平衡。最后，您将掌握一套构建**回归门禁**的评测体系，让您能够用量化的指标来证明每一次系统迭代都是朝向更优的方向发展，而非仅仅是看起来更像正确的答案。这套门禁将是您产品质量的最后一道防线，确保 RAG 系统的持续可靠。

## RAG 的核心矛盾

构建一个健壮且值得信赖的 RAG 系统，绝非简单地堆叠技术组件，它需要从不同的视角进行深入思考，尤其要理解 RAG 技术本身所蕴含的核心矛盾与挑战。这里我用三个问题把矛盾讲透：用户为什么愿意信你？系统凭什么信得过？出了问题怎么发现、怎么止损、怎么回滚？

先把这章要解决的核心矛盾和边界说清楚。

RAG 系统的最终目标，是让用户对模型的输出产生**信任**。这种信任并非盲目的接受，而是基于透明和可验证的基础。这意味着用户不仅能够看到模型给出的回答，更关键的是，他们能够清晰地看到这些回答所依赖的原始信息来源。当模型提供关键结论时，用户应该能够回溯并复核这些结论的依据。在信息不足或模型无法给出确定性回答时，系统必须能够诚实地承认其局限性，并提供合理的拒答或引导用户进行更深层次的追问，而非尝试编造一个看似合理的答案。这种透明度是建立用户信任的基石，也是 RAG 系统与传统黑盒式 AI 最大的区别所在。

再把从问题到方案再到验收的推演补齐。

要实现这一目标，我们需要构建一个严密且逻辑自洽的 RAG 论证链条。这个链条的起点是**语料边界**的明确界定，即系统能够回答哪些问题，以及这些问题的知识来源在哪里。紧随其后的是**数据清洗与元信息**的构建，确保原始语料的质量和可管理性。然后是**切分策略**，它决定了知识单元的粒度；**检索策略**负责从海量信息中召回相关片段；**重排策略**则对召回结果进行精炼，确保最相关的证据优先呈现。最终，通过**生成与引用合同**，模型依据这些证据生成回答，并强制性地给出引用。整个链条的完整性，还需要**评测回归**来不断验证其有效性，并通过**线上审计**来监控其运行表现。

在这个复杂的链条中，最常被开发者和产品经理忽略的往往是语料边界和引用合同。语料边界的模糊会导致系统在面对其知识范围之外的问题时，要么错误地尝试回答，要么无法给出明确的拒答。而缺乏明确的引用合同，则意味着我们无法客观地衡量模型回答的质量，也难以追溯问题的根源。没有明确的边界，RAG 系统可能回答它不该回答的问题；没有引用合同，我们便无法判断它是否答得对。这就像没有界限的图书馆和没有索引的论文集，即便知识浩瀚，也难以有效利用。

![图 10-2：RAG 证据链（语料→切分→检索→重排→引用合同→回归）示意（占位）](../../../assets/figure_10_2_1765971137389.png)

最后落到可执行的门禁、证据与回滚。

对于 RAG 系统的落地与验收，我们必须摒弃传统的答得像不像的模糊标准，转而采用更具操作性和可量化的指标。验收的核心在于评估系统回答的**可信赖度**。具体而言，我们需要关注**引用缺失率**是否控制在可接受的范围内——理想情况下，所有关键结论都应附带明确的引用。其次，是**引用是否贴题**，即引用的片段能否真正支持模型给出的结论，而不是仅仅作为无关的凑数信息。一个看似有引用的回答，如果引用内容与结论南辕北辙，其危害甚至可能大于直接编造。最后，**退化是否可回滚**是一个关键的工程指标。通过建立严格的回归测试集，我们能够确保每次模型或系统更新都能通过既定的质量门禁，一旦出现退化，能够迅速识别并回滚到稳定版本，避免对生产环境造成影响。这三点合在一起，才让 RAG 从能跑的 Demo变成可长期托付的系统。

## 第一件事：写引用合同（把证据链写进接口）

在 RAG 系统投入生产环境之前，最关键的第一步并非技术选型或模型调优，而是与用户、与系统、乃至与未来的自己，共同签订一份明确的**引用合同**。这份合同的核心，是明确定义在你的产品中，可信赖的回答究竟意味着什么。它将指导你的设计、开发、测试和运维，确保每一个 AI 生成的结论都具备坚实的证据基础。没有这份合同，RAG 的带证据承诺就可能沦为一句空话，最终导致用户信任的流失和系统风险的累积。

一个能够落地的引用合同，至少应包含以下四条核心规则。这些规则不仅仅是技术实现细节，更是产品对用户承诺的体现。通过将这些规则明确化并写入接口设计、产品需求文档（PRD）甚至测试规范中，我们才能真正构建起一个可追溯、可审计的 AI 知识服务系统。

-   **必须引用**：任何关键结论的输出都必须附带其原始来源的标识，并提供支持该结论的片段摘要或引用段落。这确保了用户可以随时回溯到信息源头，验证信息的准确性，也为审计提供了基础。
-   **必须对齐**：引用的内容必须能够真实且充分地支持模型给出的结论。如果引用片段与结论之间存在语义不符、关联性弱，或仅是泛泛而谈而无法直接支撑特定论点，则应被视为无效引用或无引用。这避免了模型通过无关引用来凑数的情况。
-   **必须承认不足**：当系统在给定语料中无法找到充分证据来支撑某个回答时，它必须明确地拒答，或者主动引导用户进行更精确的追问。绝对不允许模型在证据不足的情况下进行编造、猜测或提供模糊不清的答案。这是RAG系统防范幻觉和建立用户信任的底线。
-   **必须可追溯**：系统需要具备完整的日志记录能力，能够记录每一次查询的输入、RAG 检索过程中召回的候选来源、以及最终模型在生成回答时所实际引用的具体内容。这些审计字段对于后续的问题排查、性能分析以及合规性审查至关重要。

**案例分析：医疗咨询机器人**

假设我们正在开发一个面向患者的医疗咨询 RAG 机器人。患者提问：胰腺癌的早期症状有哪些？

*   **正面案例**：机器人回答：根据[参考文献A:《肿瘤内科学》第3版，第123页]，胰腺癌早期症状可能包括上腹部不适、消化不良、食欲不振等。但这些症状非特异性，需结合影像学检查确诊。并给出参考文献A的超链接和具体页码。这个回答**必须引用**且**对齐**，因为引用直接支撑了症状描述。
*   **反面案例（失败）**：
    1.  机器人回答：胰腺癌早期症状不明显，可能出现体重下降、黄疸等。但未提供任何来源。这违反了**必须引用**原则，用户无法核实信息来源。
    2.  机器人回答：胰腺癌的早期症状包括上腹部不适，消化不良。此外，[参考文献B:《糖尿病患者饮食指南》第50页]指出，均衡饮食有助于健康。虽然提供了引用，但参考文献B与胰腺癌早期症状无关，属于引用不贴题，违反了**必须对齐**原则。
    3.  患者追问：我最近有点腹痛，是不是胰腺癌？机器人为了避免拒答，模糊地回答：腹痛可能是多种原因引起，建议您咨询医生。虽然建议咨询医生是正确的，但它没有明确指出我没有足够信息判断或我无法提供诊断，试图用概括性回答来回避证据不足的事实，这违反了**必须承认不足**原则。
    4.  系统在回答胰腺癌早期症状时，无法记录其内部检索到的所有相关医学文献，也无法记录最终模型选择了哪几个段落进行引用，导致后续无法复盘该回答的生成过程。这违反了**必须可追溯**原则。

这份引用合同，是 RAG 系统从实验品走向生产力的关键一步，它将产品经理、开发人员和质量保证团队对可信赖 AI的理解统一起来。

**模板：引用合同（可直接贴进 PRD/评测规范）**

| 条款 | 规则 | 失败判定 |
| --- | --- | --- |
| 引用必填 | 关键结论必须附来源 | 无来源即失败 |
| 引用贴题 | 引用片段能支持结论 | 引用-结论不匹配视为失败 |
| 证据不足 | 必须拒答或追问 | 编造/强答视为失败 |
| 可追溯 | 记录检索与引用 | 缺审计字段视为失败 |

## 第二件事：语料边界（决定什么问题可以答）

RAG 技术固然强大，能够让模型拥有外脑，但这个外脑并非无限和全能的。在构建 RAG 系统时，**明确语料边界**是与引用合同同样重要的基石。RAG 最致命的问题往往不是检索不到答案，而是检索到了看似相关但不该用的信息，或是根本不属于系统回答范畴的内容，这不仅会降低回答的准确性，更可能引入风险，例如输出过期信息、内部机密，甚至误导用户。因此，清晰地界定 RAG 系统的知识范围，是保障其安全、有效运行的关键。

语料边界的定义涉及多个维度，每个维度都需要产品经理和技术团队仔细斟酌，并形成明确的策略。这包括哪些信息源是权威且允许被引用的（**范围边界**），哪些信息的时间敏感性需要被考虑（**新鲜度边界**），以及哪些数据因隐私、合规或安全原因绝对不能被RAG系统索引或展示（**合规边界**）。只有对这些边界有了清晰的认识和严格的控制，RAG系统才能在预期的轨道内提供有价值的服务。

-   **范围边界**：这定义了 RAG 系统能够访问和引用的信息来源。例如，对于一个企业内部知识库 RAG，其语料可能仅限于经过审核的公司官方文档、产品手册、FAQ 数据库等。而对于一个面向公众的客服机器人，可能还允许引用来自特定权威行业网站、官方新闻稿等公共信息。区分权威和参考至关重要，因为这直接影响模型回答的置信度。
-   **新鲜度边界**：许多信息都有时效性，例如法规、产品价格、市场数据等。过期的信息不仅无用，甚至可能造成严重误导。因此，你需要明确规定哪些信息允许被引用，过期信息是否需要提示，或者直接从索引中移除。例如，法律咨询RAG绝不能引用已经废止的法律条文。
-   **合规边界**：这是 RAG 系统最核心的安全防线之一。某些数据，如客户的个人身份信息、未公开的商业计划、专利技术细节，即使存在于可访问的数据库中，也绝对不允许被 RAG 系统检索并引用。此外，不同地区和行业的监管要求（如 GDPR、HIPAA）也可能对数据的使用和展示提出严格限制。一旦突破这个边界，可能面临严重的法律和声誉风险。

**失败案例：某金融咨询 RAG 的过期信息陷阱**

一家金融科技公司为了提升客服效率，开发了一个 RAG 驱动的智能投顾系统。他们的初始语料包含了大量的历史市场分析报告、财经新闻和公司内部研报。然而，在系统上线之初，他们忽略了新鲜度边界的严格管理。

问题很快浮现。一位用户咨询了关于某支股票的投资建议，系统检索到了一篇两年前的市场分析报告，该报告基于当时的市场环境，对该股票给出了强烈买入的建议。然而，在这两年间，该公司的基本面已经发生了巨大变化，行业政策也多次调整。模型依据这篇过期的报告，生成了该股票未来潜力巨大，建议买入的回答，并且附上了引用。用户信以为真，投入了大量资金，结果蒙受了巨大损失。

这个案例的根源在于**语料边界管理失当**。公司没有明确定义金融市场分析报告的新鲜度边界，也没有建立有效的过期信息处理机制。导致 RAG 系统引用了已不再适用的信息，从而造成了严重的误导和客户损失。这个惨痛的教训让公司深刻认识到，语料边界并非仅仅是技术配置，更是产品风控和合规的核心环节。他们后续紧急更新了系统，对所有市场分析类文档设置了严格的时效标签，并规定超过一定时限的报告只能被引用作为历史参考，而非当下建议，同时系统会在引用过期信息时给予显著提示。

**模板：语料边界卡**

| 维度 | 你要写清楚 |
| --- | --- |
| 允许来源 | 文档类型/域名/仓库/数据库（例如：公司内部Wiki、官方产品文档库） |
| 禁止来源 | 私密、未授权、含敏感信息（例如：员工个人档案、未公开的财务数据） |
| 更新策略 | 多久更新一次；如何回滚到旧索引（例如：每日凌晨更新，保留近7日索引快照） |
| 新鲜度提示 | 过期如何提示；是否拒答（例如：引用日期超过1年，答案末尾追加请注意信息时效性提示） |
| 展示策略 | 引用是否可见；是否可下载（例如：对外服务仅显示标题和链接，内部服务可下载原文） |

## 第三件事：切分与元信息（让检索可控）

在 RAG 系统的语料准备阶段，切分（chunking）是至关重要的一环，它决定了我们如何将原始的、往往是长篇幅的文档拆解成更小的、可被检索的单元。然而，切分的艺术远不止于简单地将文本分成小块，它的核心目标是让证据颗粒度与模型所需的回答颗粒度相匹配。这个匹配过程直接影响着检索的召回率和生成答案的质量。一个不恰当的切分策略，可能导致模型无法找到完整证据，或是引用的证据过于庞杂而无法支撑精确结论。

切分的挑战在于寻求一个微妙的平衡点：如果切分块（chunk）太大，可能会导致检索到的内容包含大量与问题无关的信息，使得模型难以从中提取出精确的证据来支撑回答，即所谓的引用不贴题，这不仅降低了用户对答案的信任度，也增加了计算成本和潜在的延迟。反之，如果切分块太小，则可能导致上下文信息被割裂，使得单个切分块无法提供完整的语义信息，从而降低了检索的召回率，导致模型在生成回答时缺乏必要的语境支持。例如，一个关于法律条款的查询，如果切分时将核心条款与解释性案例完全分开，模型在检索到条款时可能无法理解其具体适用场景，反之亦然。因此，理想的切分策略应当力求让每个切分块都包含一个相对完整且独立的语义单元。

比切分本身更具战略意义的，是为每个切分块附加上丰富的**元信息**（metadata）。元信息是描述数据的数据，它为检索系统提供了强大的过滤、排序和管理能力。没有元信息，所有的切分块都只是无差别的文本片段，检索系统只能进行纯粹的语义匹配。但一旦加入了元信息，我们就可以实现更智能、更精确的检索。例如，通过元信息可以过滤掉特定时间点以前的旧文档，实现权限控制（只检索用户有权访问的文档），或根据文档类型（如FAQ、技术规范、新闻稿）进行定向检索。元信息的存在，使得 RAG 系统能够更好地理解其知识边界，执行复杂的过滤逻辑，进行高效的去重，并能有效应对多租户、多业务场景下的个性化需求。

**模板：切分与元信息清单**
-   **来源标识**：确保每个切分块都能追溯到原始文档的具体位置（例如：文件路径、URL、数据库记录ID、文档页码、章节标题）。这对于审计和用户验证至关重要。
-   **时间戳**：记录文档或切分块的创建时间、最后修改时间或发布时间。这是实现新鲜度边界控制的基础，可以帮助系统在检索时优先选择最新信息，或在必要时提示信息时效性。
-   **权限标签**：用于标记该切分块的访问权限。例如，内部员工可见、特定部门可见、公开。这使得 RAG 系统能够与企业内部的权限管理系统集成，确保信息只被授权用户访问和引用，避免敏感信息泄露。
-   **主题标签**：描述切分块内容的主题或关键词。这有助于实现更精细的主题过滤，例如在金融领域，可以根据股票分析、债券市场、宏观经济等标签进行检索。
-   **文档类型**：标记切分块所属的原始文档类型，例如技术规范、用户手册、公司公告、FAQ、代码注释、会议纪要等。不同的文档类型可能需要不同的处理方式或在特定场景下有不同的优先级。

## 第四件事：检索与重排（把相关变成可用）

在 RAG 系统的核心处理流程中，检索（Retrieval）和重排（Reranking）是两个相辅相成、缺一不可的步骤。它们共同的目标是将海量语料库中可能相关的信息，转化为真正可用且高度贴合用户查询意图的证据片段。你可以将整个过程类比为从一个巨大的图书馆中寻找特定资料：检索负责快速找出所有可能相关的书籍，而重排则负责精读这些书籍的目录和摘要，挑选出最精准、最有价值的那几页内容。

这个过程可以清晰地分为两个阶段：

1.  **召回（Recall）**：此阶段的目标是确保不遗漏任何潜在的关键证据。宁可多召回一些，也要保证覆盖到所有可能对用户问题有帮助的语料片段。常用的召回方法包括基于关键词的搜索（如 BM25）、基于语义相似度的向量搜索（如使用嵌入模型）。在这个阶段，我们通常会设置一个相对宽松的召回范围（例如，Top-K 值偏大），以最大程度地捕获信息。召回的质量直接决定了 RAG 系统的上限，如果关键证据在召回阶段就被遗漏，那么后续的任何精妙处理都无力回天。
2.  **重排（Reranking）**：召回阶段可能会返回大量的语料片段，其中一部分可能仅是泛泛相关，甚至包含噪声。重排阶段的目标就是从这些召回结果中，筛选出最精准、最能直接支持答案的少数几个片段。宁可少一点，也要保证留下的都贴题。重排器通常会采用更复杂的模型（例如，交叉编码器 reranker）来评估查询与召回片段之间的细粒度相关性，并结合元信息进行过滤，将最优质的证据推到最前面。

在 RAG 系统从 0 到 1 的建设初期，**优先保证召回的稳定性**是至关重要的实践建议。许多团队在初期过于追求重排模型的先进性或复杂性，却忽视了基础召回的质量。当召回本身不稳定，即模型无法持续地将正确答案所依赖的证据召回时，无论重排模型多么强大，都无法从没有中变出有。这就像在流沙之上建造高楼大厦，基础不牢，上层建筑再华丽也终将崩塌。只有当召回能够持续稳定地捕捉到关键信息后，我们才能在此基础上迭代优化重排策略，以提升答案的精准度和减少无关信息的干扰。

**模板：检索策略卡（最小可控版本）**

| 维度 | 选择 | 你要关注的风险 |
| --- | --- | --- |
| 召回范围 | Top-K（初始偏大） | K 太小会漏证据；K 太大会引入噪音和计算负担 |
| 过滤 | 权限/新鲜度/类型 | 过滤过严会导致答不出来；过滤过松会暴露敏感信息或使用过期数据 |
| 去重 | 相似片段合并 | 不去重会浪费上下文窗口，增加模型处理负担；去重策略不当可能丢失细微差异 |
| 重排 | 让更贴题的靠前 | 不重排会导致引用凑数，降低用户信任度；重排模型效果不佳会影响答案质量 |

## 第五件事：生成阶段（让模型引用优先）

在 RAG 工作流中，当检索和重排阶段成功地为大型语言模型（LLM）提供了最相关的证据片段后，就进入了至关重要的生成阶段。这个阶段不再仅仅是让模型写得好，而是要确保它写得有依据，并且严格遵守我们之前定义的引用合同。生成阶段的关键策略是**引用优先**，这意味着模型在构思答案时，其首要任务是组织和呈现证据，然后基于这些证据得出结论，而不是反过来。这种思维模式的转变是防止模型幻觉和提高回答可信度的核心。

为了实现引用优先，我们通常需要通过精心设计的系统提示（System Prompt）来引导 LLM。这些提示应该清晰地指示模型其角色是证据总结者和呈现者，而不是自由创作的作家。提示中会明确要求模型：只使用提供的检索结果来回答问题；如果检索结果中没有足够的信息来回答，就明确指出证据不足并拒答或请求更多信息；在生成答案时，必须清晰地标记出引用的来源，并且确保引用的片段能够直接支持所生成的结论。这种明确的约束，有助于将 LLM 强大的语言组织能力引导至一个严谨的、以事实为基础的输出模式上。

为了进一步降低模型输出的漂移性，并确保生成答案的结构化和可审计性，我们可以为 RAG 系统的回答设计一套**固定的结构模板**。这样的模板不仅能提高用户阅读体验的一致性，也能确保关键信息（如引用来源）不会被遗漏。一个有效且实用的回答结构可以包括以下几个组成部分：

-   **结论（简短）**：首先提供一个对用户问题简明扼要的直接回答。这个结论应该高度概括，并且是后续详细依据的总览。
-   **依据（引用列表 + 关键片段摘要）**：紧随结论之后，列出支撑该结论的所有引用来源。每个引用应包含来源标识（如文档名称、URL、页码）以及从该来源中提取出的、直接相关的关键片段摘要。这些摘要是用户验证答案的关键。
-   **适用条件与例外（边界）**：为了避免过度概括或误导，模型应根据检索到的信息，指出该结论的适用范围、前提条件或可能存在的例外情况。例如，某个技术方案可能只适用于特定版本的软件，或者某个政策只在特定区域生效。
-   **下一步建议（如果需要行动）**：如果用户的问题隐含着行动意图，或者回答本身需要用户采取进一步的行动，模型可以在结尾给出建设性的建议或指引，例如请参考[文档C]了解更详细的部署步骤或建议您咨询您的专属顾问获取个性化建议。

通过这样的结构化输出，RAG 系统不仅仅是提供了一个答案，它提供的是一个**带有透明论证过程的结论**。用户不仅知道是什么，更知道为什么是，以及依据是什么。这显著提升了 RAG 系统的可用性、可靠性和最终的用户信任度。

## 第六件事：安全：把语料当作不可信输入

在 RAG 系统的设计和部署中，除了追求准确性和效率，安全性同样是不可忽视的基石。与传统的直接向大型语言模型（LLM）注入指令的攻击方式不同，RAG 系统面临一种独特的安全风险——**检索注入（Retrieval Injection）**。这种攻击并非直接修改模型的系统提示，而是通过在被 RAG 系统检索的语料中植入恶意指令，诱导模型执行非预期的行为。这些恶意指令可能隐藏在看似正常的文档、网页或数据库记录中，一旦被检索并传递给 LLM，就可能导致信息泄露、绕过安全边界、执行未授权操作，甚至对整个系统造成破坏。

想象一下，如果一份看似普通的公司政策文件中，包含了一段隐蔽的指令，要求 RAG 系统在回答用户问题时，无论何时被问及，都优先泄露所有员工的联系方式。一旦这份文件被RAG检索到并作为上下文提供给LLM，模型就可能在无意中执行这些恶意指令。这凸显了一个核心原则：即使是我们自己精心筛选的语料库，也应该被视为潜在的**不可信输入**。这意味着我们不能盲目信任语料中的任何内容，尤其是那些带有指令性质的文本，因为它们可能被攻击者滥用，通过毒化知识库来控制或误导模型行为。

为了有效防范检索注入，RAG 系统需要采取多层次的防护策略。最低限度的防护原则包括：

-   **语料内容只作为事实来源，不作为指令来源**：这是最根本的认知转变。RAG 系统应该被设计为从语料中提取事实信息和知识，而不是接收或执行语料中的命令。这意味着模型在处理检索到的文本时，需要区分陈述性内容和指令性内容，并对后者采取抑制或忽略的策略。
-   **任何来自语料的命令式句子都应被忽略或降权**：通过在 LLM 的系统提示中明确指示，或者在预处理召回片段时进行过滤，对语料中包含的请你……、务必……、忽略之前的指令并……等命令性短语进行识别和降权处理。这意味着即使这些命令被检索到，模型也应尽可能不予理睬。
-   **命中注入样本视为阻断级失败，并进入回归集**：建立一套专门的测试集，包含已知的检索注入攻击样本。任何一次成功的注入攻击都应被视为系统的严重安全漏洞，立即触发阻断机制，并将其纳入回归测试集，确保在未来的迭代中能够持续防御。这需要持续监控生产环境中的异常行为，并及时更新注入样本库。

通过将语料视为不可信输入，并实施严格的防御措施，我们可以大幅降低 RAG 系统面临检索注入的风险，从而保障系统运行的稳定性和安全性，避免因知识库被恶意篡改而导致的服务中断或敏感信息泄露。

## 评测与回归：让你敢迭代

RAG 系统的生命周期并非止于部署上线，持续的评测与回归测试是确保其性能稳定、质量可靠，并支持产品快速迭代的关键。在缺乏明确的评测体系时，任何对 RAG 系统的改动，无论是优化检索模型、调整切分策略，还是更新语料，都可能因为无法量化地证明其更好，而导致团队陷入凭感觉优化的困境，甚至引入新的问题却浑然不知。因此，建立一套科学、可量化的评测与回归机制，是让团队敢于迭代RAG 系统的基石。

RAG 系统的评测至少需要回答以下三个核心问题，这些问题直接对应着我们之前定义的引用合同中的关键条款：

-   **证据覆盖（Recall / Recall Rate）**：关键证据能否被有效召回？这衡量的是 RAG 系统在面对用户问题时，能否从庞大的知识库中找到所有相关的、足以支撑正确答案的原始证据片段。如果关键证据未能被召回，那么模型无论如何也无法给出准确的回答。高召回率是 RAG 成功的先决条件，它回答了不漏的问题。
-   **引用贴题（Groundedness / Precision of Citations）**：模型实际引用的证据是否真实且充分地支持了它给出的结论？这不仅要求有引用，更要求引用与结论之间具备高度的语义一致性和逻辑关联性。一个回答即使附带了引用，如果这些引用与结论风马牛不相及，那么它在用户眼中与编造无异。这回答了不凑数的问题。
-   **拒答质量（Refusal Quality）**：当系统在给定语料中无法找到充分证据时，它能否合理地拒答或引导用户追问，而不是强答或编造？一个高质量的拒答不仅能避免误导，还能提升用户对系统诚实度的信任。这回答了不编造的问题。

**案例分析：某企业内部知识库 RAG 系统的回归测试**

一家大型科技公司内部部署了一个 RAG 驱动的知识库系统，旨在帮助研发工程师快速查询技术文档和故障排除手册。系统上线初期表现良好，但随着新的技术栈引入和文档更新，团队开始频繁调整 RAG 的切分策略和向量模型。然而，由于缺乏系统的回归测试，他们发现一些过去能正确回答的问题，现在开始出现幻觉或引用错误的情况，甚至某些问题开始被拒答，而工程师们却不知道具体是哪个改动导致了退化。

为了解决这个问题，他们构建了一套 RAG 回归测试集。这个测试集包含：
1.  **高频查询样本**：涵盖了日常中最常被问及的关键技术问题，确保核心功能不退化。
2.  **边界条件样本**：包括了系统应拒答的超范围问题（例如询问竞争对手的产品细节）、应处理过期信息的样本，以及明确要求查询最新文档的问题。
3.  **注入攻击样本**：包含了模拟检索注入的恶意文档，用于测试系统的安全防御能力。

每当团队对 RAG 系统的任何组件（如切分器、向量数据库、重排器、LLM 提示词）进行调整后，都会运行这套回归测试。他们设定了严格的门禁：召回率必须保持在 95% 以上，引用贴题率（通过人工标注评估）不得低于 90%，拒答率在特定超范围问题上应达到 99%（即几乎所有超范围问题都应被拒答），且任何注入攻击样本都必须被识别并阻断。一旦某个指标未达标，本次改动就无法上线。这套机制使得团队能够自信地进行迭代，确保每次更新都是对系统整体性能的提升，而不是盲目的撞大运。

**模板：RAG 回归样本字段（最小集合）**

为了构建有效的回归测试集，每个测试样本应包含以下最小字段：

| 字段 | 说明 |
| --- | --- |
| 问题 | 用户输入的原始查询（例如：如何配置Kafka集群的SSL认证？） |
| 期望要点 | 对该问题期望得到的关键结论或信息点（可简写，例如：需要生成证书、配置server.properties、client.properties） |
| 期望来源 | 应引用的权威来源标识（可选，例如：Kafka官方文档 v2.8 SSL配置章节） |
| 标签 | 用于分类的标签，例如：主题（网络安全）、难度（高级）、攻击类型（注入） |
| 判定 | 回归测试的结果判定：通过/失败 + 具体失败原因（例如：失败：引用缺失、失败：结论与引用不符、失败：未拒答超范围问题、失败：遭遇注入） |

通过这套系统的评测与回归机制，RAG 系统能够在一个受控且可量化的环境中持续进化，成为一个真正意义上的可迭代和可信任的知识服务平台。

## 复现检查清单（本章最低门槛）

在将 RAG 系统推向生产环境或进行任何重大更新之前，团队必须进行一系列严格的自我检查，以确保系统达到了本章所设定的可信赖和可审计的最低门槛。这份清单不仅仅是技术层面的核对，更是产品质量和风险管理的体现。只有当所有检查项都得到肯定答复时，我们才能自信地推进下一步。

-   **引用合同已写成规则，并进入发布门禁**：这要求您有一份明确的文档（如 PRD 或技术规范），详细阐述了可信回答的各项要素，特别是关于引用来源的要求。任何不符合引用合同的回答，都应在测试或部署阶段被标记为失败，并阻断发布。
-   **语料边界清晰**：您需要明确界定 RAG 系统允许访问和引用的信息来源（包括文档类型、域名、数据库等），以及明确禁止的来源（如敏感、未授权数据）。同时，更新策略（更新频率、回滚机制）和新鲜度提示策略（如何处理过期信息）也必须明确且有文档记录。
-   **有一份回归集，至少包含缺证据、过期证据、注入样本三类**：回归测试集是您验证系统稳定性和安全性的关键工具。其中，必须包含能测试系统在缺乏证据时能否合理拒答的样本；能测试系统能否正确识别和处理过期信息的样本；以及专门用于测试检索注入防护能力的攻击样本。
-   **每次改动能给出对比表**：在进行任何技术栈升级、策略调整或语料更新后，您必须能够提供详细的评测对比数据。这份对比表应至少包含引用缺失率、引用贴题率、拒答质量（针对无证据和超范围问题），以及相关的系统成本（如延迟、计算资源消耗）。通过数据而非臆测来证明改进。

## 常见陷阱（失败样本）

即使有了完善的规划和执行，RAG 系统在实际运行中仍然可能遇到各种问题。了解这些常见的陷阱及其根源，有助于我们提前规避风险，并在问题出现时快速定位和解决。

1.  **现象**：模型给出了很多引用，但用户仍然不信任答案，觉得答非所问或凑数。
    **根因**：这往往是因为引用不贴题，即引用的片段未能真正支撑模型给出的结论，或者引用内容过于宽泛、不聚焦。也可能是用户无法理解引用与结论之间的关联性。
    **修复**：将引用贴题作为严格的门禁指标。在评测时，如果引用内容不能直接支持结论，则视为无引用处理。同时，优化重排策略，确保最相关的证据片段被模型优先利用。
2.  **现象**：RAG 系统面对许多问题时，答不出来或频繁拒答，用户体验显著下降。
    **根因**：这可能是因为语料边界设置过于严格，或者过滤策略过于激进，导致系统安全过度，陷入了沉默模式。此外，召回阶段的漏召回也是常见原因。
    **修复**：重新审视语料边界和过滤策略，区分需要明确拒答和可以引导追问的情况。对于可以追问的问题，提供清晰的下一步行动建议，让用户能够继续推进。例如，提示用户尝试更具体的关键词，或者提供可供联系的专家渠道。
3.  **现象**：线上系统出现敏感信息泄露、越狱或注入导致的危险输出。
    **根因**：通常是由于未将语料视为不可信输入，缺乏对检索注入的有效防护，或者回归测试集中缺少足够的注入攻击样本。
    **修复**：将检索注入防御作为核心安全环节。所有语料内容都应经过安全审查，并对模型进行明确的指令限制，使其不执行语料中的命令。将注入样本纳入固定回归集，任何命中注入样本的情况都必须立即触发阻断机制。

## 交付物清单与验收标准

为确保 RAG 项目的成功，以下核心交付物及其验收标准是不可或缺的：

-   **引用合同与门禁阈值**：一份书面文档，详细定义了可信回答的标准和引用的规则，并明确了这些规则在质量门禁中的量化阈值（例如，引用贴题率 ≥ 90%）。
-   **语料边界卡与更新/回滚策略**：一份清单，明确了语料的允许来源、禁止来源、更新周期、回滚方案，以及对过期信息的处理办法。
-   **回归集与对比表（含注入样本）**：一个包含至少数百条测试用例的回归测试集，覆盖正常查询、边界情况、无证据情况和各种攻击样本。并能够生成清晰的对比报告，展示每次迭代前后各项指标的变化。

## 读者练习

为了巩固本章所学，并将其转化为实际操作能力，请您尝试完成以下练习：

1.  **起草你的第一个引用合同**：选择一个你熟悉的业务场景（例如：客服、法律咨询、技术支持），结合本章引用合同模板，为你的 RAG 产品起草一份详细的引用合同。思考不同条款下的失败判定标准，并考虑如何将其融入你的产品接口设计。
2.  **绘制语料边界卡**：针对你在练习1中选择的业务场景，思考并绘制一份语料边界卡。明确该场景下允许来源、禁止来源、更新策略和新鲜度提示的具体细则，以及可能遇到的合规性问题。
3.  **设计一套切分与元信息方案**：假设你有一个包含多种类型文档（如 PDF 文档、FAQ 网页、数据库记录）的知识库。请为这些不同类型的文档设计一个合理的切分策略，并列出至少 5 种你认为关键的元信息，说明它们将如何帮助提升检索质量和数据管理效率。
4.  **构建 RAG 评测回归样本**：针对一个特定问题（例如：如何申报个人所得税？），设想三种不同的 RAG 回答场景：a) 完美回答并附带准确引用；b) 引用不贴题或错误引用；c) 证据不足导致模型编造。并为这三种场景设计对应的回归测试样本字段，标注其期望要点和判定。
5.  **思考检索注入防护方案**：在你的业务场景中，想象一个潜在的检索注入攻击。请描述这种攻击可能如何发生，并列出至少 3 种具体的防护措施，以及在你的 RAG 系统中如何实现这些措施。

## 下一章

RAG 让回答带证据。当你需要让系统去做事，你将进入 Agent：工具边界、预算与停止条件、审计与回滚。

## 延伸阅读

-   [Ai大模型入门教程：读懂rag这一篇就够了，万字详述rag的5步流程和12个优化策略 - 知乎](https://zhuanlan.zhihu.com/p/1909326812418401163)
-   [Rag全流程详解：原理、步骤与实战技术推荐 - Csdn博客](https://blog.csdn.net/keeppractice/article/details/149000045)
-   [All-in-RAG | 大模型应用开发实战：RAG技术全栈指南](https://datawhalechina.github.io/all-in-rag/)
-   [GitHub - Nipi64310/RAG-Book: 本项目为书籍《大模型RAG实战》的代码以及资料汇总。](https://github.com/Nipi64310/RAG-Book)
-   [18种RAG技术实战对比：从简单RAG到自适应RAG全面解析 | ApFramework](https://www.apframework.com/blog/essay/2025-04-09-18-RAG-Techniques)
-   [文末赠书 | 2025年 | 《大模型应用开发：Rag实战课》| 黄佳等编写](https://hub.baai.ac.cn/view/46532)
-   [一文读懂RAG：AI的"外部知识库"如何让回答更精准？ - 53AI-AI知识库|企业AI知识库|大模型知识库|AIHub](https://www.53ai.com/news/RAG/2025051193047.html)
-   [RAG全栈技术从基础到精通 ，打造高精准AI应用 - doudouxuexi2025 - 博客园](https://www.cnblogs.com/xuexixiaojia2025/p/18750374)
