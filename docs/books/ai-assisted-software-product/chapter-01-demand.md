# 第 1 章：AI 驱动的需求挖掘与市场验证

> 用数据与自动化访谈而非直觉驱动产品假设，确保在写第一行代码前完成商业可行性验证。[4][7]

## 章节定位
本章回答“值得做吗？”的根本问题。你会把零散的市场信号转化为可量化的需求矩阵，并在 7 天内完成一次小规模可行性验证。所有结论必须有数据来源、可复现脚本或统计显著性支撑，否则不得进入后续设计开发环节。[34][35]

## 你将收获什么
- 建立“问题—证据”矩阵：每个需求点都有可追溯的数据样本与显著性检验结论。[8]
- 会用 LLM/向量化工具把零散的评论转成主题模型，支撑优先级决策。[9]
- 搭建无人值守的虚拟焦点小组，验证产品方向并收集反例。[10]

## 方法论速览
1. **数据池构建：** 使用爬虫 Agent 抓取公开评论或论坛帖子，记录时间戳、来源与许可证，避免数据污染。[34]
2. **语义建模：** 结合情感分析（BERT）与主题建模（LDA/BERTopic）提炼高频痛点，形成可度量的需求分布。[8][9][26]
3. **虚拟访谈：** 预置 Persona 与问卷，运行对话代理收集回答，并用情感/立场分类验证假设强度。[10]
4. **商业画布：** 结合 Lean Canvas，建立假设→指标→验证动作的闭环，明确 CAC、留存、付费转化等北极星指标。[4]

## 典型场景
- **SaaS 工具选题：** 用自动爬虫收集 GitHub Issues 与 Product Hunt 评论，识别用户未被解决的痛点。
- **B2C 应用验证：** 从应用商店评论抽样，量化“卸载原因”与“留存动力”权重，决定首版 MVP 功能组合。

## 实战路径
### 1. 数据抓取与清洗
- 使用 requests/Playwright 抓取评论，保留原文、评分、来源链接。
- 对每条记录写入 `datasheet`（数据表格）并标注许可证与采集时间。[34]
- 去重与去噪：用 MinHash 或局部敏感哈希过滤重复文本，降低主题偏移风险。[35]

### 2. 痛点提炼与显著性验证
```python
import pandas as pd
from bertopic import BERTopic
from sklearn.feature_extraction.text import CountVectorizer

reviews = pd.read_csv("data/reviews.csv")
vectorizer_model = CountVectorizer(stop_words="english", min_df=5)
model = BERTopic(language="multilingual", vectorizer_model=vectorizer_model)
topics, probs = model.fit_transform(reviews["text"].tolist())
print(model.get_topic_freq().head())
```
- 用手工标注的 100 条样本计算主题纯度，绘制混淆矩阵，CI 中断即提示重新标注。[9]
- 将主题与评分/情感得分关联，输出“主题 × 满意度”热力图，辅助优先级排序。[26]

### 3. 虚拟焦点小组
- 设计 5–8 个 Persona（如重度/轻度用户、付费/免费用户），预置提纲（痛点、预算、替代品）。[10]
- 让对话 Agent 每日轮询提问并存 SQLite，利用情感/立场分类模型统计赞成率、反对率。
- 形成《需求访谈日报》：包含新出现的反例、阻碍采纳的理由、潜在追加功能。

### 4. 商业可行性判定
- 依据 Lean Canvas 列出问题、方案、关键指标与成本结构，估算获客成本与回收周期。[4]
- 对高优先级假设设置“七天内可验证”的实验（登陆页点击、原型反馈、候补名单转化）。

## 复现检查
- `make demand-benchmark` 执行抓取、去重、主题建模与显著性检验，CI 必须通过。
- Jupyter 笔记本导出 PDF 与热力图快照，确保审稿人可离线核查。
- 样本与结果均附统计功效说明，避免“小样本伪阳性”。

## 常见陷阱
- **样本偏倚：** 单一平台评论会放大局部偏好，需跨源采样并注明权重。[34]
- **主题漂移：** 版本更新后语义改变，需按时间窗口重跑模型并记录差分。
- **假设过多：** 每周最多 3 个待验证假设，确保实验成本可控。

## 延伸练习
- 将痛点主题映射到现有竞品的功能列表，验证“市场空白”是否真实存在。
- 使用 Prophet 建模需求随时间的趋势，评估淡旺季对功能优先级的影响。

## 交付物与验收
- `data/` 目录：原始评论、清洗结果、datasheet；CI 校验文件存在且列完整。
- `notebooks/01-demand.ipynb`：主题模型、情感分析、混淆矩阵截图。
- 《需求访谈日报》与 Lean Canvas 文档；未给出指标或证据的需求不得进入开发。

## 正文扩展稿（用于成书排版）
1. **场景化起手式：** 从一条用户投诉开始——用正反两种假设框定问题，再让代理爬取 1,000 条相似评论验证是否具备“共性痛点”。以混合检索定位语义近邻，拒绝凭感觉扩写需求。[7][34]
2. **数据护栏：** 每个数据源附带“可信度评分”（采集渠道、样本量、时间跨度、噪声水平），分为 A/B/C 级。低于 B 级的数据仅做辅助，不得支撑产品决策，并在 datasheet 中明示原因。[35]
3. **主题—用户—价值对齐表：** 构建三维表格：主题（痛点）、目标 Persona、价值/节省的成本或时间。每行附来源与样本量，未能量化价值的主题暂缓进入路线图。[8]
4. **一页式决策白板：** 每周输出一次决策白板，包含“当前假设、证据、反例、风险、下周实验”。在仓库 `docs/decisions/` 下以编号保存，作为后续复盘的审计链路。[4][18]
5. **复现流水线：** 通过 `make demand-benchmark` 自动跑爬虫、清洗、主题建模、显著性检验与 PDF 报告导出；CI 检查主题 Top5 覆盖度、混淆矩阵 F1、文件完整性。失败则阻止合并，保证读者可在本地“一键复现”。[9][26]

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
