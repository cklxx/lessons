# 第 1 章：AI 驱动的需求挖掘与市场验证

> 用数据与自动化访谈而非直觉驱动产品假设，确保在写第一行代码前完成商业可行性验证。[4]

!!! note "关于复现、目录与 CI"
    本章中出现的 `make ...`、`CI`、以及示例目录/文件路径（例如 `path/to/file`）均为落地约定，用于说明如何把方法落实到你自己的工程仓库中。本仓库仅提供文档，读者需自行实现或用等价工具链替代。

## 章节定位
本章回答“值得做吗？”的根本问题。你会把零散的市场信号转化为可量化的需求矩阵，并在短周期内完成一次小规模可行性验证。关键不是“有没有结论”，而是“结论能否被复核”：每个结论都要绑定数据来源、采集时间、许可信息与可复现脚本；对数据去重与污染风险要有明确策略。[34][35]

## 你将收获什么
- 建立“问题—证据”矩阵：每个需求点都有可追溯的数据样本、反例与不确定性说明，便于需求评审与后续验收。[4][11]
- 会用 LLM/向量化工具把零散的评论转成主题模型，支撑优先级决策。[9]
- 搭建无人值守的虚拟焦点小组，验证产品方向并收集反例。[10]

## 方法论速览
1. **数据池构建：** 使用爬虫 Agent 抓取公开评论或论坛帖子，记录时间戳、来源与许可证，避免数据污染。[34]
2. **语义建模：** 结合情感/立场分类（例如基于 BERT 的[微调](glossary.md#fine-tuning)模型）与主题建模（LDA/BERTopic）提炼高频痛点，形成可度量的需求分布。[8][9][26]
3. **虚拟访谈：** 预置 Persona 与问卷，运行对话 [Agent（智能体）](glossary.md#agent) 收集回答，并用情感/立场分类验证假设强度。[10]
4. **商业画布：** 结合 Lean Canvas，建立假设→指标→验证动作的闭环，明确 CAC、留存、付费转化等北极星指标。[4]

![图 1-1：需求验证闭环](../../assets/ch01-demand-validation-loop.png)

## 典型场景
- **SaaS 工具选题：** 用自动爬虫收集 GitHub Issues 与 Product Hunt 评论，识别用户未被解决的痛点。
- **B2C 应用验证：** 从应用商店评论抽样，量化“卸载原因”与“留存动力”权重，决定首版 MVP 功能组合。

## 实战路径
```text
数据抓取 → 去重/清洗 → 主题/情绪建模 → 需求矩阵（问题—证据） → 虚拟访谈（反例） → 七天实验（门槛）
```

### 示例（可复制）：把“评论样本”变成可评审的需求矩阵

**目标：** 基于 `data/reviews.csv` 生成《问题—证据》需求矩阵（Top 10 痛点），并附样本量与反例。

**前置条件：**
- 你能导出一份结构化评论数据（CSV/JSONL 任一即可），并能运行一段脚本或 Notebook（语言不限）。
- 你愿意把“结论”绑定到可追溯证据（样本文本/来源链接/采集时间/许可证）。[34]

**上下文：**
- 项目形态：需求验证与研究流水线（可落地到你自己的工程仓库）
- 角色：产品/研究/创业者（你需要做“可评审的需求证据”）
- 输入：`data/reviews.csv`（列：`text, rating, source, ts`）

**约束：**
- 必须给出：每个痛点的样本文本引用（至少 3 条）与样本量；不得只给结论。
- 对数据来源/许可证不明的样本要标注“不可用于决策”。[34]
- 需求矩阵每行至少包含：痛点/Persona/证据样本/样本量/不确定性/反例/下一步实验。
- 若使用 AI 辅助修改代码库文件：要求它只输出统一差异格式（unified diff，git diff 格式），避免夹带解释文本。

**输出格式：**
- 产物：`docs/demand/matrix.md`（Markdown 表格）
- 命名：每次生成建议写入日期（例如 `docs/demand/matrix-YYYYMMDD.md`），并在变更说明里标注数据快照版本。

**步骤：**
1. 从一个或多个公开渠道采集评论，落盘为 `data/reviews.csv`；同时生成一份最小[数据卡片（Datasheet）](glossary.md#datasheet)（包含来源/采集时间/许可证/样本量/去重策略）。[34][35]
2. 对评论做去重与基础清洗，保证主题分布不会被模板化文本污染。[35]
3. 跑主题建模/情绪或评分关联，得到 Top 痛点候选与样本索引。[9][26]
4. 生成 `docs/demand/matrix.md`：每个痛点至少附 3 条原文样本（带 `source`）、样本量、反例与下一步“七天内可验证实验”。[4]

**验证命令：**
```bash
make demand-benchmark
# 预期输出包含：生成 docs/demand/matrix.md + 导出一份摘要报告（例如 Top5 主题覆盖度/样本量）
```

**失败判定：**
- 未生成矩阵文件；或矩阵缺少样本引用/样本量/反例字段；或样本来源/许可证不可追溯。[34]

**回滚：**
- `git checkout -- docs/demand/matrix.md`

### 1. 数据抓取与清洗
- 使用 requests/Playwright 抓取评论，保留原文、评分、来源链接。
- 对每条数据源写入数据卡片（Datasheet）并标注许可证与采集时间。[34]
- 去重与去噪：用 MinHash 或局部敏感哈希过滤重复文本，降低主题偏移风险。[35]

### 2. 痛点提炼与显著性验证
```python
import pandas as pd
from bertopic import BERTopic
from sklearn.feature_extraction.text import CountVectorizer

reviews = pd.read_csv("data/reviews.csv")
vectorizer_model = CountVectorizer(stop_words="english", min_df=5)
model = BERTopic(language="multilingual", vectorizer_model=vectorizer_model)
topics, probs = model.fit_transform(reviews["text"].tolist())
print(model.get_topic_freq().head())
```
- 用手工标注的 100 条样本计算主题纯度，绘制混淆矩阵，CI 中断即提示重新标注。[9]
- 将主题与评分/情感得分关联，输出“主题 × 满意度”关联表（可视化时再画热力图），辅助优先级排序。[26]

![图 1-2：主题 x 满意度热力图](../../assets/ch01-topic-satisfaction-heatmap.png)

### 3. 虚拟焦点小组
- 设计 5–8 个 Persona（如重度/轻度用户、付费/免费用户），预置提纲（痛点、预算、替代品）。[10]
- 让对话 Agent 每日轮询提问并存 SQLite，利用情感/立场分类模型统计赞成率、反对率。
- 形成《需求访谈日报》：包含新出现的反例、阻碍采纳的理由、潜在追加功能。

### 4. 商业可行性判定
- 依据 Lean Canvas 列出问题、方案、关键指标与成本结构，估算获客成本与回收周期。[4]
- 对高优先级假设设置“七天内可验证”的实验（登陆页点击、原型反馈、候补名单转化）。

## 复现检查（落地建议）
- `make demand-benchmark` 执行抓取、去重、主题建模与显著性检验；建议将其设为 CI 门禁。
- Jupyter 笔记本导出 PDF 与热力图快照，确保审稿人可离线核查。
- 样本与结果均附统计功效说明，避免“小样本伪阳性”。

## 常见陷阱
1. **现象：** “Top 痛点”看起来很清晰，但上线后没人用。  
   **根因：** 采样只来自单一平台/单一人群，评论风格把局部偏好放大成“共识”。[34]  
   **复现：** 只用 App Store/只用某论坛的评论跑一次主题建模，对比不同渠道 Top5 主题差异。  
   **修复：** 跨源采样并记录权重与时间窗口；在矩阵里为每个痛点标注“来自哪些源/占比”。[34]  
   **回归验证：** 复跑 `make demand-benchmark`，检查 Top5 主题在多源数据上仍稳定（或明确写出分歧与取舍）。

2. **现象：** 主题模型每次重跑结论都变，评审无法对齐。  
   **根因：** 去重/清洗与随机性控制缺失，重复与模板化文本导致主题漂移。[35]  
   **复现：** 同一份数据在不同清洗参数/不同随机种子下重跑，观察主题排序变化。  
   **修复：** 固定数据快照、清洗参数与随机种子；对重复文本做 MinHash/LSH 去重，并记录差分。[35]  
   **回归验证：** 抽检 3 次运行结果，Top5 主题的覆盖度与样本量变化不超过阈值（阈值由你的基线决定）。[9]

3. **现象：** 团队每周都在“验证”，但从未做出可执行的决策。  
   **根因：** 假设过多、实验不可证伪、没有停止条件，导致验证永远在路上。[4]  
   **复现：** 罗列当前所有假设，发现多数无法在七天内证伪或没有明确指标。  
   **修复：** 每周最多 3 个待验证假设；每个假设必须绑定“证据/反例/七天实验/门槛/回滚”。[4][6]  
   **回归验证：** 每两周产出一页《决策白板》（保存在版本库），明确“保留/放弃/延期”的决策与证据链。[4]

## 延伸练习
- 将痛点主题映射到现有竞品的功能列表，验证“市场空白”是否真实存在。
- 使用 Prophet 建模需求随时间的趋势，评估淡旺季对功能优先级的影响。

## 交付物与验收（落地建议）
- `data/` 目录：原始评论、清洗结果与数据卡片（Datasheet）；建议由 CI 校验文件存在且列完整。
- `notebooks/01-demand.ipynb`：主题模型、情感分析、混淆矩阵截图。
- 《需求访谈日报》与 Lean Canvas 文档；未给出指标或证据的需求不得进入开发。

下面把本章的实战路径抽象为可迁移的原则，便于你换数据源/工具链时仍能复现与审计。

## 深度解析：核心原则
1. **场景化起手式：** 从一条用户投诉开始——用正反两种假设框定问题，再让 [Agent（智能体）](glossary.md#agent) 爬取 1,000 条相似评论验证是否具备“共性痛点”。以混合检索（例如 BM25 + 向量相似度）定位语义近邻，拒绝凭感觉扩写需求。[7][27]
2. **数据护栏：** 每个数据源附带“可信度评分”（采集渠道、样本量、时间跨度、噪声水平），分为 A/B/C 级。低于 B 级的数据仅做辅助，不得支撑产品决策，并在数据卡片中明示原因；对重复与模板化文本应明确去重策略。[34][35]
3. **主题—用户—价值对齐表：** 构建三维表格：主题（痛点）、目标 Persona、价值/节省的成本或时间。每行附来源与样本量，未能量化价值的主题暂缓进入路线图。[8]
4. **一页式决策白板：** 每周输出一次决策白板，包含“当前假设、证据、反例、风险、下周实验”。建议在你的项目仓库中以编号保存（示例：`docs/decisions/`），作为后续复盘的审计链路。[4]
5. **复现流水线：** 通过 `make demand-benchmark` 自动跑爬虫、清洗、主题建模、显著性检验与 PDF 报告导出；CI 检查主题 Top5 覆盖度、混淆矩阵 F1、文件完整性。失败则阻止合并，降低复现成本并减少结论漂移。[9][26]

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
