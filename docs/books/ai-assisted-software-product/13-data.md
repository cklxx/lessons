# 第 13 章：数据收集与清洗：从语料到可训练数据集
![Chapter 13 Header](../../assets/chapter_13_header_1766035711036.png)

> 数据不是原材料，而是你的产品资产：它决定你能训练什么、能评测什么、能否合规上线，以及你能否在同一问题上持续变强。[34]

在 AI 产品里，数据有两张脸：一张是面向用户的事实（他们的输入、反馈、失败样本），另一张是面向系统的燃料（训练集、评测集、检索语料）。做得好，你积累的是护城河；做得坏，你积累的是风险与偏差。

## 章节定位
本章连接产品与系统到训练与评测。你会把零散的语料与日志，整理成可复用的数据资产：有范围、有许可、有字段、有清洗报告、有版本、有回滚。这样你才能在后续训练、RAG、评测与治理里建立同一个事实源。[34][35]

## 你将收获什么
- 一套数据资产化流程：范围 → 许可 → 采集 → 清洗 → 标注 → 版本化 → 评测回归。[34]
- 三个可复用模板：数据卡（Datasheet）、标注指南、清洗报告（含阈值与例外）。[34]
- 一条底线：先合规后增长；先可追溯后训练。[35]

## 三层思考：数据工作的价值不在量，在可用
### 第 1 层：读者目标
你要交付的是可训练、可评测、可治理的数据集：别人（或未来的你）能理解它、复现它、质疑它、回滚它。

### 第 2 层：论证链条
数据变成资产的链条是：

数据边界与许可 → 字段与口径 → 清洗与过滤 → 标注与一致性 → 版本化与审计 → 回归与迭代

缺许可与边界，后面都是风险；缺版本化与审计，后面都是不可复现。[34][35]

### 第 3 层：落地与验收
验收不靠我收集了很多，而靠：
- 你能解释数据从哪里来、能不能用、能用到什么范围；
- 你能给出清洗报告与例外（为什么删、为什么留）；
- 你能复跑一遍处理流程并得到同级别结论（趋势一致）。[34]

![图 13-1：数据资产化流水线（边界→清洗→标注→版本→回归）示意](../../assets/figure_13_1_1765971297073.png)

文字版图 13-1：数据资产化流水线（不依赖图片也能执行）

| 阶段 | 输入 | 输出 | 质量门禁（最低要求） |
| --- | --- | --- | --- |
| 边界与许可 | 数据卡草稿 | 可用范围声明 | 许可明确、目的明确、留存明确 |
| 采集 | 产品埋点、日志、工单 | 原始区 raw | schema 固定、可追溯到来源 |
| 清洗与脱敏 | raw | 清洗版 cleaned | 去重率、PII 扫描、例外清单 |
| 标注与一致性 | cleaned | 标注版 labeled | 抽检、仲裁、IAA 指标 |
| 版本化与审计 | labeled | 快照 snapshot | 数据指纹、处理配置、可回滚 |
| 回归与迭代 | snapshot | 评测报告 | 指标达标才进入训练或索引 |

## 第一步：先写数据边界（不要先抓再说）
数据边界决定两件事：你能不能用，以及你该不该用。建议你先写清楚：
- 数据来源（用户输入、客服对话、公开资料、内部文档等）
- 使用目的（训练/评测/RAG/分析）
- 敏感性（是否含个人信息、机密、版权风险）
- 留存与删除（保留多久、如何删除、如何审计）[35]

### 合规行动指南（别只写原则，要能落地）
把下面问题写进数据卡，能显著降低你未来的返工概率：
- 这份数据的授权链条是什么（用户同意、合同授权、开源许可、内部权限）？谁能签字负责？
- 是否涉及个人信息或敏感个人信息（例如身份证号、地址、未成年人信息）？能否做数据最小化？[35]
- 是否存在跨境传输或第三方共享？数据处理者与接收方的责任边界是什么？
- 用户能否请求导出、删除、撤回同意？删除后对会计/审计留存如何处理（去标识化替代直接 PII）？
- 哪些数据永远不进入训练与索引（密钥、支付、医疗、合同机密等）？如何强制门禁？

## 模板 1：数据卡（Datasheet）
用法：每个数据集都先写一张卡，哪怕很短。[34]

| 字段 | 说明 |
| --- | --- |
| 名称与版本 | 数据集名 + 版本号 |
| 目的 | 用于训练/评测/RAG/分析 |
| 来源 | 从哪里来；是否可复现 |
| 许可与合规 | 授权、隐私、版权边界 |
| 覆盖范围 | 适用人群/任务类型/语言 |
| 不覆盖范围 | 明确不保证的部分 |
| 字段与口径 | 关键字段定义与计算口径 |
| 已知偏差 | 采样偏差、标签偏差、分布偏差 |
| 风险与止损 | 发现问题如何停用/回滚 |

## 第二步：采集策略（宁可少，但要干净）
0→1 阶段常见误区是先把量堆上去。更聪明的做法是先建立失败样本优先的采集：
- 记录用户无法完成闭环的案例（失败的输入、失败的输出、用户的纠正）。
- 记录高风险案例（越权尝试、注入、敏感内容）。
- 记录高价值案例（用户明确标注有用/采纳的输出）。[34]

这些样本会直接变成你的评测集与训练集的种子，价值远高于随机大规模抓取。

### 失败样本优先的最小采集机制（0→1 可直接照做）
- 产品侧：在关键输出旁放反馈入口（有用/无用、原因、改写建议），并允许用户一键把更正内容提交为样本。
- 工程侧：把错误与失败变成结构化事件，而不是一堆字符串日志（error_code、stage、retry_count、fallback）。
- 风险侧：把越权、注入、敏感内容命中也当作样本资产，进入红队评测与回归，而不是一删了之。[35]
- 运营侧：把客服工单与争议样本串起来，形成从投诉到数据回写的闭环。

### 最小数据事件 schema（建议从日志里长出来）

| 字段 | 用途 |
| --- | --- |
| event_id | 去重与追溯 |
| tenant_id / user_id | 归属与权限边界 |
| timestamp | 时间窗与回放 |
| entrypoint | 入口（页面/接口/批处理） |
| capability | 能力点（对话、检索、导入等） |
| request_id / trace_id | 证据定位 |
| input_summary / output_summary | 训练与评测摘要（避免落原文） |
| feedback_label | 用户反馈（有用/无用/纠正） |
| error_code / failure_stage | 失败分桶 |
| safety_flags / pii_flags | 风险标记与门禁 |
| consent_state | 是否允许用于训练/评测 |
| dataset_route | 进入哪个数据流（train/eval/redteam/none） |

## 第三步：清洗与过滤（必须有报告）
清洗不是随便删，而是可解释的决策。每一次清洗都要回答：
- 你删掉了什么（规则与阈值）？
- 你为什么删（风险或质量理由）？
- 你删掉后会损失什么（覆盖面/多样性）？
- 你保留了哪些例外（为什么保留）？[34]

**模板 2：清洗报告（最小集合）**

| 项 | 写法 |
| --- | --- |
| 输入范围 | 原始数据量、时间范围、来源 |
| 去重策略 | 重复判定规则与比例 |
| 脱敏策略 | 哪些字段脱敏/删除；验证方式（抽样人工、PII 扫描、脱敏前后统计对比） |
| 过滤规则 | 低质量、垃圾、注入、敏感内容规则 |
| 例外清单 | 为什么保留；风险如何控制 |
| 输出统计 | 清洗后数据量、分布变化、抽样示例 |
| 回滚策略 | 如何回到上一版数据集 |

### 脱敏与验证：别把自己骗了
脱敏不是把邮箱打星号就算赢。你需要能证明它真的生效：
- 抽样人工复核：对高风险字段做分层抽样，验证是否仍可反推个人身份。
- 自动化扫描：用规则与模型对 PII 做扫描，产出命中率与漏报样本。
- 统计对比：脱敏前后做长度分布、字符集分布、实体类型分布对比，防止规则失效。
- 红队回归：对脱敏后的数据做反推测试，把可逆脱敏当作缺陷回写到规则。

## 第四步：标注与一致性（让标签可被信任）
标注最贵的不是人工成本，而是不一致：同一个问题，不同标注者给出不同标准，训练出来的模型会学会矛盾。

**模板 3：标注指南（让一致性可回归）**

| 模块 | 说明 |
| --- | --- |
| 任务定义 | 什么算一个样本；输入/输出边界 |
| 标签集合 | 标签名、含义、正反例 |
| 判定规则 | 评分尺度与判定优先级 |
| 冲突处理 | 标注冲突如何仲裁 |
| 质量抽检 | 抽检比例与返工规则 |

0→1 的建议：先做小规模标注，先把一致性跑通，再扩量。

## 第五步：版本化与审计（让数据可复现）
数据版本化的目标不是存档，而是可追溯：任何一次训练、评测、RAG 索引都能指向一个明确的数据快照。[34]

最低要求：
- 每次数据变更都能说明变了什么、为什么变、影响了什么；
- 能回滚到上一版本；
- 能复跑处理流程得到同级别结果（趋势一致）。

### 最小实现：先把可追溯做出来
0→1 阶段你不需要一口吃成湖仓，但至少要把下面三件事钉死：
- 数据快照：每次产出一个不可变快照（snapshot_id），并保存 manifest（文件列表、校验和、行数、统计摘要）。
- 处理可复现：记录处理流水线的 code_revision（git commit）、config_hash、schema_version、运行参数与时间窗。
- 元数据可查询：有一个数据注册表（dataset registry），能查到某次训练或索引到底用了哪个 snapshot。[34]

### 常见工具与选型方向（给你一个可走的路）
- 小团队：对象存储 + manifest + dataset registry（自建最小实现）
- 数据版本：DVC（更接近代码工作流）
- 湖仓快照：Delta Lake / Iceberg（更接近数据平台）
- 追溯与血缘：元数据系统（例如数据目录与血缘追踪）

### 数据版本记录最小字段

| 字段 | 说明 |
| --- | --- |
| dataset_id / dataset_version | 数据集标识 |
| snapshot_id | 不可变快照 |
| source_range | 来源时间窗与范围 |
| schema_version | 字段口径 |
| code_revision | 处理代码版本 |
| config_hash | 清洗与过滤配置 |
| stats_summary | 样本数、分布、命中率 |
| approval | 合规与质量审批记录 |
| rollback_to | 回滚指针 |

## 复现检查清单（本章最低门槛）
- 每个数据集都有数据卡（目的、来源、许可、风险、止损）。[34][35]
- 每次清洗都有清洗报告（规则、阈值、例外、回滚）。[34]
- 标注有指南与抽检策略（一致性可回归）。
- 数据可版本化：训练/评测/RAG 都能指向明确数据快照。[34]

## 常见陷阱（失败样本）
1. **现象**：训练或 RAG 越做越乱，表现波动难解释。  
   **根因**：数据版本不可追溯；每次清洗都像重新洗牌。  
   **修复**：强制数据卡 + 清洗报告 + 版本化；没有证据的清洗不进入训练。[34]

2. **现象**：模型学会了危险行为（泄露、越权、注入）。  
   **根因**：采集时把风险样本当噪声删掉；或未做合规边界。  
   **修复**：把高风险失败样本当资产；纳入评测与回归；合规边界先行。[35]

3. **现象**：数据量很大，但训练收益很小。  
   **根因**：数据与任务不匹配；噪声比例高；标注不一致。  
   **修复**：回到数据卡的覆盖范围；先提升一致性与密度，再扩量。[34]

## 交付物清单与验收标准
- 数据卡（Datasheet）与合规边界说明。[34][35]
- 清洗报告（含阈值、例外、回滚）。[34]
- 标注指南与抽检记录（一致性可复核）。
- 数据版本与快照策略（训练/评测/RAG 可追溯）。[34]

## 下一章
数据资产准备好后，才轮到训练与适配。下一章进入预训练：你该追求什么目标、怎么核算成本、什么时候不做。见：[14-pretrain.md](14-pretrain.md)。

## 参考
详见本书统一参考文献列表：[references.md](references.md)。
