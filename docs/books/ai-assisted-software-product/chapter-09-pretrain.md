# 第 9 章：LLM 预训练与增量预训练

> 当通用模型不足以支撑业务时，需要在领域语料上进行预训练或增量预训练，控制成本同时提升知识覆盖。[2][37][39]

!!! note "关于复现、目录与 CI"
    本章中出现的 `make ...`、`CI`、目录名（如 `data/`、`tests/`、`reports/` 等）用于说明一种可复现的工程化落地方式。本仓库仅提供文档，读者需要在自己的项目仓库中按需实现/调整这些脚本与自动化门禁。

## 章节定位
本章解决“需要懂行业/编程语境的模型”问题。你将理解 Transformer 核心、分词器训练、增量预训练策略，以及分布式训练的成本规划。[2][37][39]

## 你将收获什么
- 增量预训练流程：语料准备、分词器扩展、继续预训练、对齐评估。[37]
- 分布式训练样板配置（DeepSpeed/Megatron-LM），附算力与成本估算方法。[39]
- 训练数据选择与覆盖率评估，避免灾难性遗忘。

## 方法论速览
1. **架构理解：** Attention、位置编码、残差与 LayerNorm 的作用与瓶颈。[2]
2. **分词器策略：** 基于领域语料扩展词表，减少 OOV；保持旧词表兼容，降低迁移成本。[38]
3. **继续预训练：** 采用小学习率在领域语料上训练数千 steps，监控困惑度与灾难性遗忘指标。[37]

## 实战路径
### 1. 数据与分词器
- 收集领域语料（法律/医疗/代码），清洗、去重并标注版权。
- 使用 `sentencepiece`/`tokenizers` 训练领域词表，比较 BPE 与 Unigram 的压缩率与 OOV 率。[38]

### 2. 继续预训练
```bash
accelerate launch pretrain.py \
  --model_name_or_path llama-7b \
  --dataset /data/domain.jsonl \
  --num_train_epochs 1 \
  --learning_rate 5e-5 \
  --deepspeed ds_config.json
```
- 控制学习率与训练步数，监控训练/验证困惑度；发现遗忘时混合通用语料。

### 3. 分布式与成本
- 估算显存、吞吐与费用：基于参数量、序列长度、batch size、显卡单价计算。
- 使用零冗余优化（ZeRO）与梯度检查点减少显存；记录能耗，参考碳排放评估。[44]

### 4. 质量评估
- 构建领域特定评测集（例如法律问答、API 代码生成），对比预训练前后的指标。
- 若指标回退或偏差增大，调整语料比例或回滚词表修改。

## 复现检查（落地建议）
- `make pretrain-tokenizer`：训练并导出新词表，生成 OOV 与压缩率报告。
- `make pretrain-run`：启动继续预训练并记录日志、成本、能耗估计。
- `make pretrain-eval`：对比基线与增量模型的领域基准得分。

## 常见陷阱
- **词表不兼容：** 完全替换词表导致下游模型不可用，应优先增量扩展。
- **灾难性遗忘：** 纯领域语料训练导致泛化下降，需混合少量通用语料。[37]
- **成本超支：** 未估算计算/存储费用，训练中途停机浪费预算。

## 延伸练习
- 对比不同学习率计划（cosine、linear）对继续预训练效果的影响。
- 尝试多语种场景下的词表扩展，评估跨语种迁移性能。

## 交付物与验收（落地建议）
- 语料描述、词表文件与训练脚本；OOV/压缩率/覆盖率报告。
- 预训练日志、成本与能耗估算；模型权重与评测结果。
- 回滚策略与灾难性遗忘监控说明。

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
