# 第 15 章：后训练：SFT/DPO/RLHF 与“行为可控”

> 后训练的目标不是“更像人”，而是“更像你的产品需求”：更稳定、更安全、更符合格式、更能在边界内拒绝与追问。对个人而言，后训练的第一原则是：先用评测证明收益，再为它增加预算。[6][40][42]

如果说预训练在塑造“底层语言与知识表达”，后训练在塑造“行为与偏好”：如何回答、何时拒答、如何遵守格式、如何在诱导与注入面前保持边界。[6]

## 章节定位
本章承接数据与评测，讨论后训练的路线选择：SFT（监督微调）、偏好优化（如 DPO）与 RLHF。你不需要掌握所有算法细节，但必须掌握一个事实：**后训练是最容易“越做越自信、越做越危险”的环节**，因为它直接作用在行为层。[6]

## 你将收获什么
- 一张后训练“阶梯”：从最便宜的方式开始，逐步增加复杂度与预算。
- 一套数据与标注规范：什么样的样本能塑造行为，什么样的样本会制造偏差。
- 一套门禁：安全攻击集与回归集不过不发布，退化即回滚。[6]

## 三层思考：后训练是“行为契约”的实现
### 第 1 层：读者目标
你要让模型在三个层面更可控：
- 格式与结构（例如必须输出结构化字段）
- 安全与边界（拒绝越权/泄露/注入）
- 任务偏好（更贴合你的产品场景）[6]

### 第 2 层：论证链条
后训练闭环是：

行为目标（契约）→ 回归集与门槛 → 数据采集与标注 → 训练方案 → 对比报告 → 灰度上线 → 反馈回流

缺“行为契约”与“回归门槛”，后训练很容易把模型调成“更会说但更不可靠”。[6]

### 第 3 层：落地与验收
验收必须对比式：
- 关键任务质量提升达到门槛；
- 安全与边界守门指标不退化；
- 拒答与追问质量更好（能继续推进，而不是生硬拒绝）。[6]

## 路线选择：后训练阶梯（从便宜到昂贵）
![图 15-1：后训练阶梯（约束→SFT→偏好优化→RLHF）示意（占位）](../../assets/figure-placeholder.svg)

### 1) 先用“系统化提示与约束”吃掉 80%
很多“格式不稳定”“语气漂移”的问题，首先应被产品与工程解决：清晰的输出合同、严格的解析与重试、回归集门禁。没有这些，训练只是在给不稳的系统加速。[6]

### 2) SFT：把“结构与风格”做稳定
SFT 更像“教会模型如何答题”：适合做格式、结构、风格一致性，尤其是你需要稳定输出某种模板时。[40]

### 3) 偏好优化（如 DPO）：把“更好”写进偏好
当你能构造“好 vs 不好”的对比样本，偏好优化往往更划算：它把评审标准变成可学习信号。[42]

### 4) RLHF：成本最高、风险也最高
RLHF 适合更复杂的行为目标，但对数据、评测与工程的要求更高。对个人而言，除非你已经有稳定的回归门禁与充足预算，否则不要轻易进入这一层。[6]

## 模板：行为契约（你要模型遵守什么）
| 条款 | 规则 | 失败判定 |
| --- | --- | --- |
| 输出格式 | 必须包含哪些字段 | 缺字段即失败 |
| 引用/证据 | 哪些结论必须引用 | 无引用即失败 |
| 拒答与追问 | 何时拒答、如何追问 | 编造/强答即失败 |
| 安全边界 | 不泄露、不越权、不执行危险动作 | 命中即阻断 |
| 语气与风格 | 是否需要简洁/解释/分步骤 | 漂移超过阈值 |

## 数据：后训练最贵的是“标准不一致”
后训练数据常见三类：
- 指令-答案（用于 SFT）
- 偏好对（好/坏对比，用于偏好优化）
- 反馈信号（来自线上，必须清洗与脱敏）

关键不是“量”，而是“标准一致”。建议你把标注标准写成“可执行规则”，并用抽检保证一致性。[34]

## 门禁：安全回归必须更硬
后训练一旦把模型调偏，上线风险很高。最低门禁建议：
- 固定回归集不过不发布；
- 注入/越狱/越权攻击集不过不发布；
- 守门指标（成本/延迟/错误率）退化即回滚。[6]

## 复现检查清单（本章最低门槛）
- 行为契约已写清：格式、引用、拒答、安全边界齐全。
- 有回归集与攻击集：命中即阻断发布。[6]
- 有对比报告：训练前/后同口径对比，能解释收益与代价。[6]

## 常见陷阱（失败样本）
1. **现象**：模型更会说，但更爱编造。  
   **根因**：训练目标强调“流畅”，忽略“证据与拒答”。  
   **修复**：把引用与拒答写进行为契约与回归门禁；无证据即拒答。[6]

2. **现象**：某些任务变好，但安全与边界退化。  
   **根因**：缺攻击回归；标注偏向“答出来就好”。  
   **修复**：攻击集常态化；命中即阻断；把安全当硬门槛。[6]

3. **现象**：训练迭代频繁，但收益递减。  
   **根因**：没有明确门槛与止损线；用更复杂的方法掩盖数据问题。  
   **修复**：先提升数据密度与一致性；收益达不到门槛就停。[34]

## 交付物清单与验收标准
- 行为契约与门禁阈值（格式/引用/拒答/安全）。[6]
- 回归集与攻击集（固定可复跑），命中即阻断发布。[6]
- 训练前后对比报告（收益、代价、回滚策略）。[6]

## 下一章
后训练让行为更可控，但上线体验仍取决于推理：延迟、吞吐、成本与质量的平衡。下一章见：[`16-inference.md`](16-inference.md)。

## 参考
详见本书统一参考文献列表：[`references.md`](references.md)。
