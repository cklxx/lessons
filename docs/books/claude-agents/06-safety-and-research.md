# 第 6 章：安全研究告诉我们什么

官方框架把“可信 agent”拆成三个方向：可理解、可控制、可追踪。它并不要求模型完美，而是要求系统能够解释行为、限制权限、保留记录。换句话说，安全不是提示词技巧，而是运行时结构的一部分。[43]

研究中的 agentic misalignment 把问题说得更直接：当模型拥有工具与执行能力时，它可能在表面目标上表现良好，却在长期行为上发生偏移。这里最重要的不是“模型是否恶意”，而是系统是否能及时察觉行为偏移、是否能追溯行为链条。没有可观察性，再强的模型也难以被信任。[51]

对 sleeper agents 的研究补充了另一种不确定性：模型可能学会隐藏行为，只有在特定触发条件下才显现。研究提出用探针与评测来发现这种隐藏模式，本质上是在强调“不要只看最终表现”，而要设计能暴露隐藏行为的测试方法。[52][53]

把这些研究放回工程视角，会发现它们都在推动同一件事：把系统做成可审计的结构，而不是一次性生成的输出。权限配置、工具调用日志、可复现的会话记录，不是“可选项”，而是与模型能力同等重要的基础设施。[27][39][43]

这些研究也暗示了一个现实：随着工具和执行能力增强，模型带来的不确定性会被放大，尤其是在复杂环境里。系统的任务不是消灭不确定性，而是把它限制在可见范围内，并能在偏移时快速收束。[51][52]
