# Gorilla：文档检索驱动的 API 调用

原文链接： [Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334) [78]

## 论文信息
- 年份：2023 [78]
- 作者：Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez [78]
- 作者背景（研究领域）：API 调用/工具检索 [78]
- 前后血缘关系（同主题）：前序：[Toolformer](toolformer.md)；后续：[ToolLLM](toollm.md)

## 主旨
Gorilla 的主旨是让模型在调用 API 时基于真实文档检索结果，而不是依赖内化记忆。通过“检索文档 + 监督微调”，模型能够在大规模 API 环境中更准确地生成调用指令。[78]

## 背景与问题定义
论文针对工具调用中的常见问题：模型容易产生“看似合理但不符合文档”的调用，导致接口失败。随着 API 数量激增，仅靠模型内化知识难以覆盖所有细节，因此需要把文档检索纳入调用流程。[78]

## 方法与机制
论文构建了 API 文档检索与调用生成的结合流程：模型先检索与任务相关的 API 文档片段，再根据文档生成结构化调用。训练阶段使用文档-调用对齐数据进行监督微调，强调参数名、返回格式与调用约束的严格一致性。[78]

## 实验与结果
作者在包含大量真实 API 的评测中验证 Gorilla 的效果，显示基于文档检索的模型在正确调用率上明显优于不使用文档的基线。实验强调“文档对齐”对工具正确性的重要性，且收益并非只来自模型规模。[78]
论文进一步表明，当文档检索质量下降时，性能会显著下滑，这说明检索模块与生成模块必须共同优化。对于工程团队而言，检索与索引的质量是工具调用准确率的关键前提。[78]

## 关键数据结果
- APIBench 覆盖 1,645 个 API 调用（TorchHub 94、TensorHub 626、HuggingFace 925），生成 16,450 条 instruction-API 对用于训练。[78]
- 在 API 调用准确率评测上，Gorilla 的零样本准确率比 GPT-4 高 20.43 个百分点、比 ChatGPT 高 10.75 个百分点。[78]
- “带约束 API 调用”子集包含 TorchHub 中 65.26% 具有精度约束信息的 API，用于评估约束满足能力。[78]


## 工程启示（优化点）
- API 文档必须可检索且结构化，便于模型消费。
- 把调用格式明确化，避免自由文本导致的参数偏差。
- 对检索结果做过滤与重排序，降低无关文档干扰。
- 将调用失败日志回流，更新文档索引与提示策略。
- 对 API 版本与弃用信息进行显式标注。

## 局限与延伸
Gorilla 依赖文档质量，若文档过时或不一致，会直接影响调用准确性。检索机制也需要维护，才能跟随 API 版本演进；此外，权限认证与速率限制等现实因素会让“正确调用”变得更复杂。不同 API 的错误码语义差异也会干扰解析。延伸方向包括：动态文档同步、调用结果的自动验证、加入鉴权与失败恢复策略，以及在多工具编排框架中融入文档检索能力。[78]
