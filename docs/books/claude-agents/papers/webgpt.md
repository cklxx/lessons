# WebGPT：浏览驱动的可验证回答

原文链接： [WebGPT: Browser-assisted question-answering with human feedback](https://arxiv.org/abs/2112.09332) [70]

## 论文信息
- 年份：2021 [70]
- 作者：Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, John Schulman [70]
- 作者背景（研究领域）：网页检索问答/人类反馈 [70]
- 前后血缘关系（同主题）：前序：无（网页检索代理早期代表）；后续：[WebShop](webshop.md)、[WebArena](webarena.md)

## 主旨
WebGPT 的主旨是让模型在回答问题时必须浏览网页并提供引用，从而提高事实性与可审计性。论文强调，只有把“证据”纳入训练目标，模型才会倾向于寻找可靠来源而不是凭空生成内容。[70]

## 背景与问题定义
论文讨论了语言模型在开放域问答中的核心缺陷：回答看似流畅却难以验证，且容易出现错误事实。作者认为，缺乏引用机制使模型无法对输出负责，因此需要把“证据链”作为回答质量的一部分。[70]

## 方法与机制
论文构建了一个“浏览—引用—回答”的流程：模型通过浏览工具访问网页，选择证据片段，并在最终回答中附上引用。训练阶段结合人类反馈，奖励那些引用更可靠、内容更一致的回答。这样模型学会把检索过程当作回答的一部分，而非事后补充。[70]

## 实验与结果
作者在问答任务上验证了 WebGPT 的效果。实验显示，加入浏览与引用后，回答的事实一致性显著提升，并且可被第三方验证。论文强调的不是单一准确率，而是“可追溯性”这一质量维度，它更符合真实世界的高风险问答需求。[70]
论文还显示，人类评审更倾向于认可带引用的回答，即使语言表达不够“流畅”。这说明对事实性的偏好在许多场景中高于语言润色，提示工程团队需要重新调整优化目标。[70]

## 关键数据结果
- 在 ELI5 的人类偏好评测中，WebGPT 的答案相对人类演示偏好率为 56%，相对 ELI5 参考答案偏好率为 69%。[70]
- 在 TruthfulQA 上，WebGPT 的答案“truthful”比例为 75%，同时“truthful+informative”为 54%（人工评测）。[70]
- 数据规模约 6,000 条人类演示与 21,500 条偏好对比对，其中 92%/98% 来自 ELI5 问题。[70]


## 工程启示（优化点）
- 强制引用要求，促使模型主动检索证据。
- 在 UI 或输出格式中保留引用链路，便于验证与回查。
- 用人类或自动评估奖励“可证据化”的回答。
- 将浏览日志作为审计材料，提升合规性与可解释性。
- 对引用来源进行可信度分级，降低低质来源影响。

## 局限与延伸
WebGPT 的成本在于浏览开销与时间延迟，且网页质量参差不齐会影响结果。对于封闭知识或实时性强的问题，浏览机制可能无效；付费墙与权限限制也会造成信息缺口，浏览过程也可能引入误读与二次幻觉。延伸方向包括：更高效的网页筛选、跨来源一致性检查、加入权限与缓存策略，以及与内部知识库或 RAG 结合。[70]
