# MRKL Systems：模块化路由的专家协作架构

原文链接： [MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning](https://arxiv.org/abs/2205.00445) [66]

## 论文信息
- 年份：2022 [66]
- 作者：Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, Moshe Tenenholtz [66]
- 作者背景（研究领域）：神经符号/NLP/工具路由 [66]
- 前后血缘关系（同主题）：前序：无（模块化工具路线早期代表）；后续：[Toolformer](toolformer.md)、[Gorilla](gorilla.md)、[ToolLLM](toollm.md)

## 主旨
MRKL Systems 的主旨是把大语言模型从“全能推理器”变成“意图路由器”。模型负责理解用户问题、选择合适的外部专家模块，并把模块输出整理成回答，而确定性计算与事实检索由外部模块承担，从而扩展系统能力并降低幻觉风险。[66]

## 背景与问题定义
论文针对的核心问题是：纯语言模型在面对计算、检索或符号推理时容易产生“看似合理但不可验证”的答案，而这些能力恰恰是工程系统必须稳定提供的。作者希望用可插拔模块补足 LLM 的弱项，让系统在不牺牲语言能力的前提下具备更强的可靠性与可扩展性。[66]

## 方法与机制
论文提出一种模块化、神经符号融合的架构。LLM 先对输入问题做意图解析，决定调用哪个专家模块（如计算器、知识库检索、符号求解等），再把模块结果整合成自然语言回复。核心在于“路由与解释”被模型接管，而“执行”由可验证的模块完成，这使系统能力可以通过插拔模块持续扩展。[66]

## 实验与结果
作者在需要明确外部能力支持的任务上验证该架构，如需要检索事实或进行数值推理的问题。实验显示，相比纯语言模型，MRKL 的路由机制能减少错误猜测，尤其在多步推理场景下更稳定。重要的不是单次指标提升，而是证明模块化策略可以系统性提高可靠性。[66]
此外，论文强调了路由错误的代价：一旦调用了错误模块，模型往往会在错误信息上继续“合理化”，因此路由质量决定了系统上限。这也提示工程落地时需要在路由策略与模块覆盖面之间做权衡。[66]

## 工程启示（优化点）
- 把“路由 + 整理”交给模型，把“可验证执行”交给工具或服务。
- 设计统一的工具接口与返回格式，降低模型路由与解析成本。
- 允许按需替换专家模块，让系统升级不影响整体协议。
- 对路由决策记录中间日志，便于审计与回放。

## 局限与延伸
MRKL 的有效性高度依赖模块覆盖度与路由准确率，模块稀缺或路由失误会导致性能下降。实际工程里需要维护工具目录、权限与版本策略，否则模块化会变成运维负担。后续工作可以在路由层引入更强的检索与置信度估计，让系统能在“调用工具”与“直接回答”之间更稳健地切换。[66]
