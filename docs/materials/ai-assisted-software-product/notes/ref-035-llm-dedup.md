# [35] LLM 数据去重：为什么重复会伤模型（以及怎么测）

- 资料类型：论文
- 原始来源：https://arxiv.org/abs/2307.03195
- 对应章节：第 1 章（需求数据清洗）、第 8 章（数据工程）

## 一句话
重复数据会让模型“记住模板”，也会让你的评测看起来虚高。

## 你该从论文带走什么
- **去重不仅是省空间**：它影响训练分布、过拟合与泛化。
- **要区分重复类型**：完全重复、近似重复、模板化重复（最容易污染主题/情绪统计）。

## 在本书里怎么用
- 第 1 章的数据池构建里，明确“去重策略 + 抽样复核方式”（不然主题模型会漂移）。
- 第 8 章把去重报告写进产物（去重前后大小、重复率、抽检样本）。

## 常见误用
- 只做 hash 去重，忽略语义近似与模板化（导致“看起来去重了，其实没去掉污染”）。

