# [77] NIST AI RMF：把“AI 风险”从口号变成可审计的治理框架

- 原始来源：https://www.nist.gov/itl/ai-risk-management-framework
- 对应章节建议：第 20 章（合规与伦理）+ 第 11 章（用户/权限/审计）+ 第 18 章（评测与红队）

## 一句话摘要
NIST AI RMF 的价值在于给你一套“说人话也能落地”的风险治理结构：你不必先成为合规专家，但你可以用框架把风险识别、评估、缓解与持续监控写进产品生命周期。

## 你应该从这里带走什么（面向产品）
- **风险不是上线前一次性检查**：AI 系统的风险会随数据、模型、用户行为变化；治理必须是持续过程。
- **把风险映射到产品机制**：权限、审计、评测门禁、回滚、告知与申诉，这些都是治理能力的一部分。

## 可落地做法（最小集合）
- 为每个关键能力写一张“风险卡”：风险是什么、触发条件、影响范围、监控信号、缓解措施、责任人。
- 把“红队/越界样本”纳入回归：每次事故都要回写到评测集与门禁里，避免同类问题复发。

## 常见误用提醒
- **把框架当成文件堆**：治理不是写更多文档，而是让系统默认具备“可解释、可追责、可回滚”的机制。

