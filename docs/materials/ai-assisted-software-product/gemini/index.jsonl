{"title": "The Lean Startup | The Movement That Is Transforming How New Products Are Built And Launched", "url": "https://theleanstartup.com/", "category_id": "product_discovery", "category": "Discovery & Product Strategy", "chapter_targets": ["01-method", "02-discovery", "05-validation", "19-iteration"], "one_liner": "精益创业方法论，通过快速实验和验证性学习优化产品开发流程。", "summary": "精益创业（Lean Startup）是一种变革性的产品构建与发布方法。它强调通过“开发-测量-学习”的反馈循环进行快速实验，以减少资源浪费并实现验证性学习。该方法帮助创业者在高度不确定的环境下，通过科学的迭代过程，更有效地开发市场所需的成功产品。", "key_points": ["验证性学习（Validated Learning）：通过科学实验验证商业假设，而非凭空猜测。", "开发-测量-学习（Build-Measure-Learn）：核心反馈循环，旨在缩短产品开发周期。", "创新核算（Innovation Accounting）：建立衡量指标以评估进步并设定优先级。", "创业即管理：在极端不确定的情况下，需要一种新的管理模式来引导创新。"], "tags": ["精益创业", "产品验证", "快速迭代", "MVP", "验证性学习"], "scores": {"relevance": 9, "authority": 10, "recency": 6, "depth": 8, "actionability": 9}, "score_reason": "作为精益创业方法论的官方资源，它定义了现代产品发现的核心框架。虽然内容发布时间较早，但其关于验证性学习和快速迭代的原则是AI产品原型验证的基石，具有极高的实操指导意义。", "ok": true, "snapshot_path": "sources/md/theleanstartup-com-4d36f965363d.md", "note_path": "notes/ref-004-lean-startup.md", "score_total": 8.6}
{"title": "Accelerate", "url": "https://itrevolution.com/product/accelerate/", "category_id": "engineering", "category": "Engineering Workflow", "chapter_targets": ["07-engineering", "18-evaluation", "19-iteration"], "one_liner": "揭示如何通过 DORA 指标和科学研究方法衡量并提升软件交付性能的权威指南。", "summary": "本书基于四年的开创性研究，通过严格的统计方法定义了衡量软件交付性能的核心 DORA 指标。它深入探讨了哪些技术能力和管理实践能驱动高绩效，证明了交付性能与业务价值之间的强相关性，为组织实现从精益软件开发到 DevOps 的高效转型提供了科学依据。", "key_points": ["定义了四个核心度量指标：部署频率、变更交付周期、平均修复时间（MTTR）和变更失败率。", "通过严谨的统计分析证明，优秀的软件交付能力能够显著提升组织的竞争力和市场表现。", "强调了技术实践（如持续交付）、管理实践和文化对组织性能的驱动作用。", "提供了可量化的方法论，帮助管理者科学地评估和改进团队的开发效率。"], "tags": ["DORA指标", "DevOps", "软件交付性能", "统计研究", "精益管理"], "scores": {"relevance": 9, "authority": 10, "recency": 7, "depth": 9, "actionability": 8}, "score_reason": "作为 DevOps 度量领域的行业标准，书中提出的 DORA 指标对本项目在 AI 辅助开发背景下的效能评估具有极高的参考价值，是衡量技术工程卓越性的权威基石。", "ok": true, "snapshot_path": "sources/md/itrevolution-com-product-accelerate-d1a2cf84e0c6.md", "note_path": "notes/ref-006-accelerate.md", "score_total": 8.75}
{"title": "Continuous Delivery", "url": "https://martinfowler.com/books/continuousDelivery.html", "category_id": "ops", "category": "Deployment & Operations", "chapter_targets": ["07-engineering", "17-deployment", "19-iteration"], "one_liner": "通过自动化构建、测试和部署实现可靠的软件发布。", "summary": "本书介绍了如何通过持续集成和部署流水线将集成后的代码转化为生产软件。它强调了开发与运维的协作（DevOps），并通过高度自动化减少发布风险与压力，使发布过程变得常规化、频繁且可靠，从而缩短从想法到可用软件的生命周期。", "key_points": ["建立部署流水线（Deployment Pipelines）将集成后的代码转化为生产软件。", "持续集成（CI）是保持团队同步并消除集成延迟的基础。", "通过高度自动化的构建、测试和部署减少人为错误，降低发布压力。", "打破开发与运维之间的隔阂，构建频繁、可靠的交付文化。"], "tags": ["持续交付", "部署流水线", "自动化", "DevOps", "持续集成"], "scores": {"relevance": 9, "authority": 10, "recency": 5, "depth": 9, "actionability": 8}, "score_reason": "该资源是持续交付领域的奠基之作，由业内权威撰写，深度探讨了自动化部署流水线的构建。虽然出版时间较早，但其关于自动化交付和快速反馈循环的核心原则，对于现代软件产品的工程化迭代仍具有极高的指导价值。", "ok": true, "snapshot_path": "sources/md/martinfowler-com-books-continuousdelivery-html-7b817f9cdde9.md", "note_path": "notes/ref-005-continuous-delivery.md", "score_total": 8.45}
{"title": "OWASP Application Security Verification Standard (ASVS) | OWASP Foundation", "url": "https://owasp.org/www-project-application-security-verification-standard/", "category_id": "engineering", "category": "Engineering Workflow", "chapter_targets": ["07-engineering", "09-backend", "20-governance"], "one_liner": "OWASP 提供的 Web 应用程序技术安全控制测试基准和安全开发需求清单。", "summary": "OWASP ASVS 是一个标准化的 Web 应用安全验证框架，旨在规范安全测试的覆盖范围和严谨性。它为开发者提供了明确的安全开发要求，并为测试人员提供了验证技术安全控制的基准，适用于安全度量、开发指导及采购合同规范。", "key_points": ["提供标准化的 Web 应用程序技术安全控制测试基准。", "为开发者提供详细的安全开发需求清单，辅助防御 Cross-Site Scripting (XSS) 和 SQL 注入等漏洞。", "建立了一套可量化的安全度量体系，用于评估 Web 应用的信任程度。", "可直接用于采购合同中，作为定义应用安全验证要求的标准参考。"], "tags": ["Web安全", "安全标准", "OWASP", "安全开发", "渗透测试"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 10, "actionability": 9}, "score_reason": "该资源是全球公认的 Web 安全验证标准，由 OWASP 维护，具有极高的权威性和深度。2025 年发布的 5.0.0 版本确保了时效性。其提供的结构化核查清单对于 AI 产品的后端安全工程和合规性治理具有直接且极高的实践指导价值。", "ok": true, "snapshot_path": "sources/md/owasp-org-www-project-application-security-verification-standard-50b4bc9ed328.md", "note_path": "notes/ref-068-owasp-asvs.md", "score_total": 9.35}
{"title": "OpenAPI Specification v3.2.0", "url": "https://spec.openapis.org/oas/latest.html", "category_id": "prd_spec", "category": "PRD & Specs", "chapter_targets": ["03-prd", "07-engineering", "09-backend"], "one_liner": "全球通用的 HTTP API 接口描述标准，是 AI 辅助开发中实现契约驱动与自动化调用的基石。", "summary": "OpenAPI 规范（OAS）是与编程语言无关的 HTTP API 接口定义标准。它通过 JSON 或 YAML 格式详细描述 API 的路径、操作、参数及响应模型。在 AI 辅助开发背景下，该规范是实现自动文档生成、代码基架构建以及 Agent 调用工具（Tool Use）的核心语义协议。", "key_points": ["定义了标准的 OpenAPI 对象结构，包括 Info、Paths、Components 等核心组件。", "支持利用 JSON Schema 进行复杂的交互数据模型定义，确保前后端数据一致性。", "3.2.0 版本强化了 URI 引用解析逻辑（如 $self 字段）和多文档描述结构。", "提供了完善的安全方案（Security Schemes）定义，支持 OAuth2、API Key 等机制。"], "tags": ["API规范", "OpenAPI", "契约驱动开发", "接口定义", "Agent调用标准"], "scores": {"relevance": 10, "authority": 10, "recency": 10, "depth": 9, "actionability": 9}, "score_reason": "作为 API 设计的事实标准，OpenAPI 是现代软件工程必不可少的规范。其 2025 年发布的 3.2.0 版本提供了最严谨的接口描述机制，对于 AI 辅助生成高质量代码及定义可理解的 Agent 插件具有极高的工程价值。", "ok": true, "snapshot_path": "sources/md/spec-openapis-org-oas-latest-html-529619ee7996.md", "note_path": "notes/ref-067-openapi-spec.md", "score_total": 9.7}
{"title": "RFC 6749: The OAuth 2.0 Authorization Framework", "url": "https://www.rfc-editor.org/rfc/rfc6749", "category_id": "user_auth", "category": "User / Auth / Audit", "chapter_targets": ["09-backend", "11-user", "12-billing"], "one_liner": "OAuth 2.0 是互联网行业标准的授权框架，定义了第三方应用获取受限访问权限的规范。", "summary": "本文档详细定义了 OAuth 2.0 授权框架，允许第三方应用通过资源所有者批准或自身凭据获取对 HTTP 服务的有限访问。规范涵盖了授权码、隐式、密码凭据和客户端凭据四种核心许可模式，以及访问令牌、刷新令牌的颁发流程和安全端点定义。", "key_points": ["定义了资源所有者、资源服务器、客户端和授权服务器四个核心角色及其交互流程。", "提供了四种标准的授权许可类型，以适应 Web 应用、原生应用及纯后端等不同场景。", "引入令牌（Token）机制，将身份验证与授权分离，避免第三方应用直接接触用户密码。", "详细规定了协议端点（授权、令牌、重定向）的实现要求及相关的安全防护建议。"], "tags": ["OAuth 2.0", "授权框架", "身份认证", "API 安全", "RFC 标准"], "scores": {"relevance": 10, "authority": 10, "recency": 7, "depth": 9, "actionability": 8}, "score_reason": "作为全球通用的授权标准，其权威性无可置疑，是现代软件产品后端开发和用户权限设计的必读基石。", "ok": true, "snapshot_path": "sources/md/www-rfc-editor-org-rfc-rfc6749-9c8f86060b94.md", "note_path": "notes/ref-022-oauth2.md", "score_total": 9.1}
{"title": "Final: OpenID Connect Core 1.0 incorporating errata set 2", "url": "https://openid.net/specs/openid-connect-core-1_0.html", "category_id": "user_auth", "category": "User / Auth / Audit", "chapter_targets": ["09-backend", "11-user"], "one_liner": "OpenID Connect 1.0 的核心规范，定义了基于 OAuth 2.0 的身份层协议。", "summary": "本规范定义了 OpenID Connect 1.0 的核心功能，包括构建在 OAuth 2.0 之上的身份认证机制和用于传递用户信息（Claims）的 ID Token。详细说明了授权码、隐式和混合三种认证流，以及 UserInfo 端点、声明管理、安全与隐私考量，是实现互操作性身份层的基础标准。", "key_points": ["定义了 ID Token 数据结构及其包含的标准声明（iss, sub, aud, exp, iat 等）", "详细规定了授权码流 (Authorization Code Flow) 的步骤、请求验证及响应处理", "描述了隐式流和混合流的适用场景及其与令牌端点的交互方式", "规范了 UserInfo 端点的访问方式及其返回的 End-User 个人资料信息", "包含了关键的安全考量，如 TLS 要求、签名与加密顺序以及防范常见攻击的措施"], "tags": ["OIDC", "OAuth 2.0", "身份认证", "ID Token", "用户声明"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 10, "actionability": 9}, "score_reason": "该文档是 OpenID Connect 的官方核心规范，具有最高的权威性和深度；对于后端实现用户认证系统具有决定性的指导意义。虽然 errata set 2 发布于2023年底，但作为基础协议标准，其时效性极强。", "ok": true, "snapshot_path": "sources/md/openid-net-specs-openid-connect-core-1-0-html-cfd2790a544c.md", "note_path": "notes/ref-069-oidc-core.md", "score_total": 9.55}
{"title": "RFC 7519: JSON Web Token (JWT)", "url": "https://www.rfc-editor.org/rfc/rfc7519", "category_id": "user_auth", "category": "User / Auth / Audit", "chapter_targets": ["09-backend", "11-user", "12-billing"], "one_liner": "JSON Web Token (JWT) 的官方标准规范，定义了紧凑且 URL 安全的声明表示方式。", "summary": "本规范定义了 JWT，一种用于在两方之间传输声明的紧凑方式。声明编码为 JSON 对象，作为 JWS 或 JWE 的负载，支持签名或加密。它是现代 Web 开发中身份认证、授权声明和跨服务信任传递的基础协议，确保了数据的完整性和可选的私密性。", "key_points": ["定义了 JWT 的三段式结构：Header、Claims Set (Payload) 和 Signature/Encryption", "规定了标准的注册声明名称（如 iss, sub, aud, exp, nbf, iat, jti）及其语义", "描述了 JWT 的创建与验证流程，强调了对 UTF-8 编码和 Base64url 编码的要求", "提供了安全建议，包括签名与加密的推荐顺序、抗碰撞命名以及隐私保护措施"], "tags": ["JWT", "RFC", "身份认证", "API安全", "JSON"], "scores": {"relevance": 10, "authority": 10, "recency": 7, "depth": 9, "actionability": 9}, "score_reason": "作为 JWT 的官方 RFC 标准，具有最高的权威性和技术深度。它是现代软件产品实现用户系统和分布式授权的基石，对于后端架构师和安全工程师具有极强的实践指导意义。", "ok": true, "snapshot_path": "sources/md/www-rfc-editor-org-rfc-rfc7519-7bb6aaba0f31.md", "note_path": "notes/ref-070-jwt.md", "score_total": 9.25}
{"title": "PCI Security Standards Council – Protect Payment Data with Industry-driven Security Standards, Training, and Programs", "url": "https://www.pcisecuritystandards.org/document_library/?category=pcidss&document=pci_dss", "category_id": "billing", "category": "Billing & Pricing", "chapter_targets": ["12-billing", "20-governance"], "one_liner": "PCI DSS 支付卡行业数据安全标准官方文档库，涵盖支付数据保护的权威规范。", "summary": "该资源是 PCI 安全标准委员会的官方文档库，提供了 PCI DSS v4.0.1 等核心安全标准。它为处理持卡人信息的机构提供了一套完整的技术和操作要求框架，是构建合规支付系统、保障交易安全的行业基石。", "key_points": ["提供最新的 PCI DSS v4.0.1 标准文档及其变更摘要。", "包含终端设备（PTS POI）的模块化安全要求。", "提供官方的框架规范、评估工具和支持资源。", "定义了保护支付卡数据免受泄露的技术与操作基准。"], "tags": ["PCI DSS", "支付安全", "合规性", "数据保护", "金融标准"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 10, "actionability": 8}, "score_reason": "作为支付卡行业的全球权威标准，该文档库提供了最核心的合规要求和技术细节，对于任何涉及支付功能的软件产品而言，是确保安全性与合法性的必备参考。", "ok": true, "snapshot_path": "sources/md/www-pcisecuritystandards-org-document-library-cb73a6d59e55.md", "note_path": "notes/ref-023-pci-dss.md", "score_total": 9.2}
{"title": "Web Content Accessibility Guidelines (WCAG) 2.2", "url": "https://www.w3.org/TR/WCAG22/", "category_id": "ux_ui", "category": "UX / UI & Design Systems", "chapter_targets": ["06-ui", "08-frontend", "11-user", "20-governance"], "one_liner": "全球权威的 Web 内容可访问性标准，定义了如何使残障人士能够无障碍地使用网页和应用。", "summary": "WCAG 2.2 是 W3C 发布的最新 Web 可访问性标准，涵盖感知、操作、理解和鲁棒性四大原则。它通过 A/AA/AAA 三级成功准则，为视觉、听觉、肢体及认知障碍用户提供支持，是构建包容性 AI 产品 UI 和前端界面的核心设计依据。", "key_points": ["确立了 Web 无障碍的四大核心原则：可感知、可操作、可理解和鲁棒性。", "定义了可量化的成功准则（A/AA/AAA 级），用于评估产品的合规性和易用性。", "2.2 版本新增了关于焦点显示、拖拽操作、点击目标尺寸及无障碍认证等 9 项新标准。", "强调技术中立性，适用于桌面、移动端及各种新兴 Web 交互技术。", "不仅服务于残障群体，也能通过改善交互逻辑显著提升全体用户的通用体验。"], "tags": ["无障碍", "WCAG", "W3C标准", "UX设计", "前端开发", "合规性"], "scores": {"relevance": 10, "authority": 10, "recency": 10, "depth": 10, "actionability": 9}, "score_reason": "该文档是全球 Web 可访问性的事实标准，具有极高的权威性和指导性。对于 AI 产品在 UI 设计、前端实现、用户包容性以及合规治理方面的讨论至关重要，且 2.2 是目前的最新发布版本。", "ok": true, "snapshot_path": "sources/md/www-w3-org-tr-wcag22-a3b0aa493d7c.md", "note_path": "notes/ref-017-wcag-2-2.md", "score_total": 9.85}
{"title": "Design Tokens Format Module 2025.10", "url": "https://www.designtokens.org/TR/drafts/format/", "category_id": "ux_ui", "category": "UX / UI & Design Systems", "chapter_targets": ["06-ui", "08-frontend"], "one_liner": "W3C 设计令牌社区小组发布的 2025.10 版规范草案，定义了跨工具交换设计决策的标准 JSON 格式。", "summary": "该规范描述了用于在不同工具间交换设计令牌（Design Tokens）的技术标准。它定义了令牌的 JSON 结构，支持颜色、尺寸等基本类型及阴影、排版等复合类型。核心特性包括属性命名规范、层级分组、别名引用语法以及基于 JSON Schema 语义的组继承与深度合并规则。", "key_points": ["确立了跨工具交换设计决策的标准 JSON 文件格式规范及 MIME 类型。", "规定了令牌的核心属性如 $value（必填）、$type、别名引用及扩展机制。", "定义了灵活的令牌层级分组结构，并支持通过 $root 显式声明组的根令牌值。", "引入了 $extends 属性，实现组之间的令牌继承、深度合并与局部覆盖逻辑。", "提供了详细的令牌解析算法、循环引用检测规则以及对各种复合样式的标准化定义。"], "tags": ["设计令牌", "设计系统", "W3C规范草案", "JSON交换格式", "UI工程化"], "scores": {"relevance": 9, "authority": 10, "recency": 10, "depth": 9, "actionability": 8}, "score_reason": "该资源是设计令牌领域的最新官方社区报告草案，发布日期为2025年12月，具有极高的时效性和权威性。规范内容详尽，涵盖了从基础属性到复杂继承算法的完整技术细节，是构建自动化UI系统和 AI 辅助前端开发工具的关键底层参考标准。", "ok": true, "snapshot_path": "sources/md/www-designtokens-org-tr-drafts-format-3248b3ab62e4.md", "note_path": "notes/ref-053-design-tokens.md", "score_total": 9.2}
{"title": "axe-core", "url": "https://github.com/dequelabs/axe-core", "category_id": "ux_ui", "category": "UX / UI & Design Systems", "chapter_targets": ["06-ui", "07-engineering", "18-evaluation"], "one_liner": "开源的网站和 HTML 用户界面自动化可访问性测试引擎。", "summary": "axe-core 是一个快速、安全且轻量级的可访问性测试引擎，旨在无缝集成到现有测试环境。它支持 WCAG 2.0/2.1/2.2 等标准，通过自动化手段平均可发现 57% 的可访问性问题，帮助开发者在开发早期识别并修复 UI 缺陷，确保产品的包容性。", "key_points": ["支持 WCAG A/AA/AAA 级别规则及多种无障碍最佳实践。", "承诺零误报，确保自动化测试结果的准确性与可靠性。", "兼容 Chrome、Firefox、Safari 等主流浏览器及 JSDOM 环境。", "高度可配置，支持多种语言本地化以及运行时 API 配置。"], "tags": ["可访问性", "自动化测试", "WCAG", "前端开发", "UI"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 8, "actionability": 10}, "score_reason": "该工具是行业标准的可访问性评估引擎，由 Deque Systems 维护，具有极高的权威性和实操性，是 UI 质量评估与包容性设计的核心工具。", "ok": true, "snapshot_path": "sources/md/github-com-dequelabs-axe-core-ffda5b0730f2.md", "note_path": "notes/ref-054-axe-core.md", "score_total": 9.2}
{"title": "Lighthouse &nbsp;|&nbsp; Chrome for Developers", "url": "https://developer.chrome.com/docs/lighthouse/", "category_id": "evaluation", "category": "Evaluation", "chapter_targets": ["08-frontend", "17-deployment", "18-evaluation"], "one_liner": "Google 开发的一款开源、自动化工具，旨在提高网页质量。", "summary": "Lighthouse 是 Google 提供的开源自动化工具，用于审核网页的性能、可访问性、最佳实践、SEO 及 PWA。它支持在 Chrome DevTools、命令行或作为 Node 模块运行，生成详细报告并提供改进建议，帮助开发者提升用户体验和网页质量。", "key_points": ["提供性能、可访问性、SEO 等多维度自动化审计", "支持 DevTools、CLI、Node 模块等多种运行方式", "为每个审计项目提供详细的改进指南和参考文档", "可集成到 CI/CD 流程中实现自动化质量门禁"], "tags": ["网页审计", "前端性能", "可访问性", "SEO", "自动化测试"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 8, "actionability": 10}, "score_reason": "Google 官方文档，内容极其权威且实用。作为评估网页质量的工业标准工具，对前端性能优化和用户体验审计具有极高的实战参考价值。", "ok": true, "snapshot_path": "sources/md/developer-chrome-com-docs-lighthouse-1b45ffb23796.md", "note_path": "notes/ref-055-lighthouse.md", "score_total": 9.2}
{"title": "Fast and reliable end-to-end testing for modern web apps | Playwright", "url": "https://playwright.dev/", "category_id": "engineering", "category": "Engineering Workflow", "chapter_targets": ["07-engineering", "08-frontend", "18-evaluation", "04-prototype"], "one_liner": "微软出品的跨浏览器、跨平台的现代化端到端自动化测试框架。", "summary": "Playwright 是一个强大的开源自动化测试工具，支持所有现代渲染引擎（Chromium, WebKit, Firefox）。它具备自动等待、Web 优先断言和跟踪查看器等特性，旨在解决端到端测试中的脆弱性问题，支持多页面、多身份验证状态及移动端模拟。", "key_points": ["跨浏览器与跨平台支持：涵盖所有主流引擎，支持多语言 API。", "韧性测试机制：通过自动等待和智能断言消除测试的不稳定性。", "强大的调试工具：提供代码生成器（Codegen）、检查器和轨迹查看器。", "高效执行与隔离：利用浏览器上下文实现毫秒级的测试隔离与状态复用。"], "tags": ["端到端测试", "自动化测试", "Playwright", "软件工程", "前端开发"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 8, "actionability": 10}, "score_reason": "微软官方推出的行业领先测试框架，文档详尽，功能涵盖了现代 Web 应用测试的所有核心痛点，具有极高的实战参考价值。", "ok": true, "snapshot_path": "sources/md/playwright-dev-8960df5ea200.md", "note_path": "notes/ref-057-playwright.md", "score_total": 9.2}
{"title": "Test runner | Storybook docs", "url": "https://storybook.js.org/docs/writing-tests/integrations/test-runner", "category_id": "engineering", "category": "Engineering Workflow", "chapter_targets": ["07-engineering", "08-frontend", "18-evaluation"], "one_liner": "Storybook 官方组件测试工具，可将 UI Story 自动转化为基于 Playwright 的自动化测试。", "summary": "该文档介绍了 Storybook Test Runner，这是一个基于 Jest 和 Playwright 的工具，能将组件 Story 转化为真实的浏览器自动化测试。它支持验证渲染报错、执行交互逻辑、进行无障碍检查及快照对比，并通过覆盖率统计与 CI 集成方案保障组件库的稳定性。", "key_points": ["基于 Jest 与 Playwright，在真实浏览器中运行测试，支持渲染验证及 play 函数交互逻辑检查。", "内置无障碍测试（a11y）、DOM/图像快照测试以及基于 Istanbul 的代码覆盖率分析功能。", "提供强大的 Hook API（preVisit/postVisit）用于扩展测试行为，如调整视口或注入特定 Header。", "提供详尽的 CI 集成配置方案，支持在 GitHub Actions 等环境下针对已部署或本地 Storybook 运行任务。"], "tags": ["Storybook", "自动化测试", "Playwright", "组件驱动开发", "CI/CD"], "scores": {"relevance": 9, "authority": 10, "recency": 8, "depth": 9, "actionability": 10}, "score_reason": "该资源是 Storybook 官方提供的测试运行器指南，具备极高的权威性和实操性。它详细涵盖了从基础配置到高级 Hook、CI 流水线集成的全过程，对于前端工程化及质量保障章节具有核心参考价值。", "ok": true, "snapshot_path": "sources/md/storybook-js-org-docs-writing-tests-integrations-test-runner-28169fa9753f.md", "note_path": "notes/ref-056-storybook-test-runner.md", "score_total": 9.2}
{"title": "[2005.11401] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "url": "https://arxiv.org/abs/2005.11401", "category_id": "rag", "category": "RAG", "chapter_targets": ["10-intelligence", "13-data", "16-inference"], "one_liner": "检索增强生成（RAG）的奠基之作，定义了结合预训练模型与外部知识库的通用微调框架。", "summary": "本文提出了RAG模型，将预训练的seq2seq模型（参数记忆）与密集的维基百科向量索引（非参数记忆）相结合。通过端到端微调，解决了LLM在知识密集型任务中精度有限、无法溯源及知识更新困难的问题。实验证明其在问答和生成任务上均优于纯参数模型。", "key_points": ["提出RAG-Sequence和RAG-Token两种模型，分别处理整个序列或单个Token的检索条件。", "将检索器（DPR）与生成器（BART）结合，通过潜在变量模型实现端到端微分训练。", "证明了非参数记忆（知识库索引）可以在不重新训练模型的情况下直接通过更换索引来更新知识。", "在多项知识密集型任务中刷新了SOTA，并有效减少了生成任务中的事实幻觉现象。"], "tags": ["RAG", "检索增强", "DPR", "BART", "知识图谱", "深度学习", "事实准确性"], "scores": {"relevance": 10, "authority": 10, "recency": 7, "depth": 9, "actionability": 8}, "score_reason": "作为RAG概念的起源论文，它是任何AI产品工程师理解检索增强架构的必读文献。虽然发布于2020年，但其核心思想和架构至今仍是工业界的主流标准。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2005-11401-02ad74cdb0c9.md", "note_path": "notes/ref-024-rag-paper.md", "score_total": 9.1}
{"title": "now publishers - The Probabilistic Relevance Framework: BM25 and Beyond", "url": "https://www.nowpublishers.com/article/Details/INR-019", "category_id": "rag", "category": "RAG", "chapter_targets": ["10-intelligence"], "one_liner": "深入探讨信息检索核心算法 BM25 及其扩展 BM25F 的概率理论框架权威指南。", "summary": "本书系统介绍了概率相关框架（PRF），详细阐述了二值独立模型、相关反馈以及经典的 BM25 和 BM25F 算法。它是理解现代搜索引擎和 RAG 系统中关键词检索环节的奠基性理论文献，涵盖了从模型推导到参数优化的完整过程。", "key_points": ["概率相关框架（PRF）的基本建模假设", "BM25 算法的概率推导与核心逻辑", "针对结构化文档和元数据的 BM25F 扩展模型", "检索算法中的自由参数优化与非文本特征整合"], "tags": ["BM25", "BM25F", "信息检索", "RAG", "概率建模"], "scores": {"relevance": 9, "authority": 10, "recency": 5, "depth": 10, "actionability": 7}, "score_reason": "由 BM25 发明者 Stephen Robertson 撰写，是检索领域的巅峰之作。虽然出版于 2009 年，但其提供的理论框架至今仍是工业级 RAG 混合搜索召回逻辑的基石。", "ok": true, "snapshot_path": "sources/md/www-nowpublishers-com-article-details-inr-019-5b5f92061906.md", "note_path": "notes/ref-027-bm25.md", "score_total": 8.45}
{"title": "[1702.08734] Billion-scale similarity search with GPUs", "url": "https://arxiv.org/abs/1702.08734", "category_id": "rag", "category": "RAG", "chapter_targets": ["10-intelligence", "13-data", "16-inference"], "one_liner": "介绍 GPU 加速的大规模向量相似性搜索技术（Faiss 核心算法）。", "summary": "本文介绍了知名开源库 Faiss 的核心技术实现，重点探讨如何利用 GPU 显存层次结构显著提升大规模相似性搜索效率。通过优化的 k-selection 设计和乘积量化算法，实现了比此前技术快 8.5 倍的搜索速度，是现代向量数据库和高性能 RAG 系统的重要技术基石。", "key_points": ["提出了一种高效的 GPU k-selection 算法，直接在寄存器中操作，性能可达理论峰值的 55%。", "针对 IVFADC（倒排文件乘积量化）索引结构进行了深度 GPU 优化，支持十亿级规模向量检索。", "详细阐述了如何通过内核融合（Kernel Fusion）和高效的内存访问模式减少全局内存带宽瓶颈。", "该研究促成了 Faiss 库的诞生，使单机 4 块 GPU 在 12 小时内构建十亿规模向量图成为可能。"], "tags": ["向量搜索", "GPU加速", "Faiss", "乘积量化", "RAG架构", "相似度检索"], "scores": {"relevance": 10, "authority": 10, "recency": 6, "depth": 9, "actionability": 8}, "score_reason": "该论文是向量搜索领域的里程碑式著作，定义了 Faiss 的底层架构。对于理解高性能 AI 产品中 RAG 模块的底层优化具有极高的权威性，虽然是 2017 年的研究，但其提出的算法至今仍是该领域的行业标准。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-1702-08734-96401671ff5f.md", "note_path": "notes/ref-025-faiss.md", "score_total": 8.95}
{"title": "[2309.15217] Ragas: Automated Evaluation of Retrieval Augmented Generation", "url": "https://arxiv.org/abs/2309.15217", "category_id": "evaluation", "category": "Evaluation", "chapter_targets": ["18-evaluation", "10-intelligence"], "one_liner": "一个无需参考答案即可对检索增强生成（RAG）流程进行自动化评估的框架。", "summary": "本文介绍了 Ragas 框架，旨在解决 RAG 系统在缺乏人工标注参考答案时的评估难题。通过“忠实度”、“答案相关性”和“上下文相关性”三个核心指标，利用 LLM 自动化分解并验证生成的陈述。该方法可显著加快 RAG 架构的迭代速度，并提供了与主流开发框架的集成。", "key_points": ["提出了无需人工标注参考答案（reference-free）的 RAG 评估指标体系。", "定义了 RAG 评估的“三元组”指标：忠实度（Faithfulness）、答案相关性（Answer Relevance）和上下文相关性（Context Relevance）。", "描述了如何利用 LLM 将复杂答案分解为原子声明并进行逻辑校验的具体流程。", "发布了 WikiEval 数据集，验证了自动化评估方法与人工判断之间的高度一致性。"], "tags": ["RAG", "自动化评估", "LLM", "Ragas", "检索增强生成"], "scores": {"relevance": 10, "authority": 9, "recency": 8, "depth": 8, "actionability": 10}, "score_reason": "该资源是目前 RAG 领域应用最广的自动化评估方案，解决了生产环境中缺乏标注数据的痛点，提供了成熟的开源工具和 Prompt 逻辑，具有极高的工程实战参考价值。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2309-15217-ec2d122a43eb.md", "note_path": "notes/ref-028-ragas.md", "score_total": 9.2}
{"title": "[2210.03629] ReAct: Synergizing Reasoning and Acting in Language Models", "url": "https://arxiv.org/abs/2210.03629", "category_id": "agents", "category": "Agents & Tool Use", "chapter_targets": ["07-engineering", "10-intelligence", "19-iteration", "04-prototype"], "one_liner": "提出 ReAct 框架，通过在语言模型中协同推理（Reasoning）与行动（Acting），显著提升了复杂任务的解决能力。", "summary": "该研究探讨了如何让大语言模型（LLM）以交错方式生成推理轨迹和特定任务操作。推理轨迹帮助模型诱导、跟踪和更新行动计划，而行动则允许模型与外部源（如维基百科）交互获取信息。这种协同机制在问答、事实核查及交互式决策任务中表现卓越，提升了模型的可解释性与可信度。", "key_points": ["ReAct 结合了思维链（CoT）的推理能力与动作生成的交互能力，有效缓解了单纯推理导致的幻觉问题。", "在 HotpotQA 和 Fever 任务中，通过与维基百科 API 交互，ReAct 克服了模型内部知识过时和错误传播的局限。", "在 ALFWorld 和 WebShop 等决策任务中，ReAct 仅需少量 Few-shot 示例即可超越传统的强化学习基准。", "提供了极佳的可解释性，人类可以通过查看推理轨迹了解模型决策依据，并能通过编辑思维过程来控制模型行为。"], "tags": ["ReAct", "智能体", "思维链", "交互式决策", "推理与行动"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 8}, "score_reason": "该论文是智能体（Agents）领域的奠基性工作，提出的 ReAct 范式已成为构建现代 AI Agent 系统的标准模式，对本书设计 AI 自主决策逻辑具有极高的参考价值。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2210-03629-7647307fe498.md", "note_path": "notes/ref-029-react.md", "score_total": 9.25}
{"title": "LangGraph overview - Docs by LangChain", "url": "https://docs.langchain.com/oss/python/langgraph/overview/", "category_id": "agents", "category": "Agents & Tool Use", "chapter_targets": ["07-engineering", "10-intelligence"], "one_liner": "LangChain 推出的低底层、高可控性的有状态 Agent 编排框架。", "summary": "LangGraph 是一个用于构建、管理和部署长期运行、有状态 Agent 的底层编排框架。它提供了持久化执行、人机协作、综合记忆等核心能力，专注于解决复杂 Agent 工作流中的状态管理和可靠性问题，支持细粒度的流程控制，是开发生产级 AI 应用的关键基础设施。", "key_points": ["底层编排：专注于 Agent 的状态管理和复杂执行逻辑，而非简单的 Prompt 封装。", "核心特性：支持持久化运行（可从中断点恢复）、人机交互（人工审核与修改状态）、长短期记忆。", "灵活架构：基于图结构（StateGraph）构建循环工作流，支持细粒度的节点控制和流式输出。", "生态集成：与 LangChain 组件及 LangSmith 观测平台深度整合，支持从原型到生产的快速转化。"], "tags": ["Agent 编排", "有状态工作流", "LangGraph", "LangChain", "人机协作"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 8, "actionability": 9}, "score_reason": "该文档是 LangGraph 的官方概述，权威性极高。它清晰地定义了框架的核心价值（持久性、记忆、人机交互），并提供了可运行的代码示例，是理解和构建工业级 AI Agent 系统的必读资源。", "ok": true, "snapshot_path": "sources/md/docs-langchain-com-oss-python-langgraph-overview-38f4f5c73818.md", "note_path": "notes/ref-060-langgraph.md", "score_total": 9.4}
{"title": "[2308.08155] AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation", "url": "https://arxiv.org/abs/2308.08155", "category_id": "agents", "category": "Agents & Tool Use", "chapter_targets": ["07-engineering", "10-intelligence", "04-prototype"], "one_liner": "微软开源的多智能体框架 AutoGen，定义了基于对话的 LLM 应用开发新范式。", "summary": "AutoGen 是一个开源框架，支持开发者构建由多个可定制智能体协作的 LLM 应用。它通过“对话编程”简化复杂工作流，整合 LLM、工具和人类输入，实现自动化或人机协作的任务处理。实验表明，该框架在数学、编程、决策等领域表现优异，能显著提升效率并降低开发复杂度。", "key_points": ["定义了“可对话智能体”概念，能够灵活组合 LLM、代码执行工具和人类反馈。", "提出“对话编程”范式，将复杂 LLM 工作流统一为智能体之间的消息传递与交互。", "支持静态与动态对话流，包括由 GroupChatManager 驱动的复杂多智能体群聊模式。", "在数学解题、安全代码生成、RAG 增强及游戏化交互等多个实际场景中证明了其有效性。"], "tags": ["多智能体", "LLM框架", "对话编程", "AutoGen", "人机协作"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 9, "actionability": 9}, "score_reason": "该资源是多智能体协作领域的奠基性框架，详细阐述了智能体编排的底层逻辑和编程模式，对书中涉及的智能体架构设计和工程实现具有极高的参考价值。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2308-08155-ec7ede4a4fcf.md", "note_path": "notes/ref-030-autogen.md", "score_total": 9.55}
{"title": "Overview | OpenAI Platform", "url": "https://platform.openai.com/docs/", "category_id": "general", "category": "General References", "chapter_targets": ["01-method", "07-engineering", "10-intelligence", "16-inference"], "one_liner": "OpenAI 官方文档主页，全面介绍 GPT-5.2 系列模型、智能体构建、模型优化及生产环境最佳实践。", "summary": "该页面是 OpenAI 平台的入口，涵盖了从文本、代码生成到多模态的核心能力。重点介绍了 GPT-5.2 模型、智能体开发框架、结构化输出、函数调用、评估工具及模型微调等进阶功能，为开发者提供从快速入门到生产部署的全流程技术指导。", "key_points": ["核心能力：涵盖文本/代码生成、视觉/音频多模态处理及结构化输出。", "智能体开发：提供 Agents 框架，支持工具集成、MCP 连接器、网络搜索及代码解释器。", "模型优化：包含微调、提示词优化、评估（Evals）及蒸馏等提升准确性的手段。", "生产就绪：提供延迟与成本优化、安全指南、Webhooks 及生产最佳实践。"], "tags": ["OpenAI", "GPT-5.2", "智能体", "模型优化", "API文档"], "scores": {"relevance": 10, "authority": 10, "recency": 10, "depth": 8, "actionability": 9}, "score_reason": "作为官方文档首页，具有极高的权威性和时效性（包含最新的 GPT-5.2），是 AI 产品开发和工程化落地的基石资源。", "ok": true, "snapshot_path": "sources/md/platform-openai-com-docs-00a8ca075d5c.md", "note_path": "notes/ref-031-openai-tool-use.md", "score_total": 9.55}
{"title": "[1803.09010] Datasheets for Datasets", "url": "https://arxiv.org/abs/1803.09010", "category_id": "data", "category": "Data", "chapter_targets": ["13-data", "20-governance", "18-evaluation"], "one_liner": "提倡为每个机器学习数据集配备标准化说明书（Datasheet），以提高透明度和问责制。", "summary": "本文借鉴电子行业的元器件数据表，提出了一种机器学习数据集的标准化文档流程。通过记录数据集的动机、组成、收集过程、推荐用途及维护计划，旨在解决数据透明度不足、社会偏见放大及复现性差等问题，促进数据创建者与使用者之间的有效沟通。", "key_points": ["借鉴电子行业标准，为数据集建立包含动机、组成、收集等维度的标准化文档 (Datasheets)。", "强调对数据生命周期的全程记录，包括预处理、分布情况及长期维护计划。", "通过透明度建设减少模型在训练和评估阶段可能引入的社会偏见与安全风险。", "提供了一套具体的问卷模板，涵盖动机、组成、收集、用途等关键生命周期阶段。"], "tags": ["数据集文档", "数据治理", "透明度", "机器学习偏见", "数据管理"], "scores": {"relevance": 10, "authority": 10, "recency": 7, "depth": 9, "actionability": 9}, "score_reason": "该论文是AI数据集标准化记录领域的开山之作，具有极高的权威性和影响力。虽然初稿发表于2018年，但其提出的框架至今仍是工业界（如Google, IBM, Microsoft）推行数据治理的核心参考，具有极强的可操作性。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-1803-09010-641a177ce167.md", "note_path": "notes/ref-034-datasheets.md", "score_total": 9.25}
{"title": "[2107.06499] Deduplicating Training Data Makes Language Models Better", "url": "https://arxiv.org/abs/2107.06499", "category_id": "data", "category": "Data", "chapter_targets": ["13-data", "14-pretrain"], "one_liner": "证明去重训练数据能显著减少语言模型的记忆冗余，提高训练效率并改善评估准确性。", "summary": "研究发现现有语言模型数据集包含大量重复内容，导致模型输出中有超过1%的原文复制。通过后缀数组和MinHash技术进行去重，可在不降低困惑度的情况下，将模型记忆训练数据的频率降低10倍，减少4%以上的训练-测试集重叠，显著提升模型质量与训练效率。", "key_points": ["现有大规模语料库中存在严重的近重复和长重复子串问题，影响模型评估。", "提出了基于后缀数组的精确匹配和基于MinHash的近似匹配两种可扩展去重技术。", "去重使模型生成记忆内容的频率降低了10倍，同时不损害模型困惑度（Perplexity）。", "去重后的数据集更小（如C4缩减约7%），显著降低了计算成本和训练时间。"], "tags": ["数据去重", "训练语料", "Suffix Array", "MinHash", "数据质量", "模型评估"], "scores": {"relevance": 9, "authority": 10, "recency": 7, "depth": 9, "actionability": 8}, "score_reason": "该论文是LLM数据处理领域的基石研究，系统阐述了数据去重的必要性与实现路径，对AI产品的数据流水线设计有直接指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2107-06499-9237d7c1fc50.md", "note_path": "notes/ref-035-llm-dedup.md", "score_total": 8.75}
{"title": "[2106.09685] LoRA: Low-Rank Adaptation of Large Language Models", "url": "https://arxiv.org/abs/2106.09685", "category_id": "training", "category": "Training & Alignment", "chapter_targets": ["15-posttrain", "16-inference", "07-engineering"], "one_liner": "通过低秩分解实现大语言模型的高效微调，显著降低资源消耗且不增加推理延迟。", "summary": "LoRA 提出冻结预训练权重，在 Transformer 层中注入可训练的低秩矩阵来减少下游任务参数量。以 GPT-3 175B 为例，可减少一万倍训练参数并降低 3 倍显存需求，且微调后的矩阵可与原权重合并，确保推理零延迟，性能媲美全参数微调。", "key_points": ["冻结原始参数，仅训练低秩分解矩阵 A 和 B，实现极高参数效率。", "部署时可将 A、B 矩阵直接加回原始权重 W0，实现推理零开销。", "在 GPT-3 等模型上验证了性能媲美全参数微调，且训练显存需求降低 3 倍。", "揭示了语言模型任务适应具有低秩特性，为高效适配提供了理论支撑。"], "tags": ["LoRA", "PEFT", "大模型微调", "参数高效", "模型压缩"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 10}, "score_reason": "本文是参数高效微调（PEFT）领域的基石之作，其提出的方法已成为行业标准，对降低大模型工程化门槛具有极高的实践价值。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2106-09685-cae140a2c5e7.md", "note_path": "notes/ref-040-lora.md", "score_total": 9.55}
{"title": "[2212.10560] Self-Instruct: Aligning Language Models with Self-Generated Instructions", "url": "https://arxiv.org/abs/2212.10560", "category_id": "training", "category": "Training & Alignment", "chapter_targets": ["13-data", "15-posttrain", "19-iteration"], "one_liner": "利用大模型自身生成合成指令数据进行对齐的开创性框架。", "summary": "本文介绍了Self-Instruct框架，通过从预训练模型自身引导生成指令、输入和输出样本，并进行自动过滤后用于微调，显著提升模型的指令遵循能力。该方法在GPT3上仅凭极少量种子数据即实现了媲美InstructGPT的对齐效果，为构建自动化合成数据流水线和解决标注成本问题提供了行业标杆方案。", "key_points": ["提出Self-Instruct自动化管线：指令生成、任务分类、实例生成及启发式过滤。", "核心机制：利用少量手工编写的种子指令驱动模型批量生产高质量、多样化的合成任务。", "实验证明：在GPT3上使用该方法微调后的性能较原模型提升33%以上，大幅缩小了与人工标注模型的差距。", "通过ROUGE-L重叠度分析和专家评估，验证了生成数据在任务类型和指令表达上的多样性与有效性。"], "tags": ["Self-Instruct", "合成数据", "指令微调", "模型对齐", "数据管道"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 9}, "score_reason": "该论文是合成数据对齐领域的奠基之作，详细阐述了从数据生成到过滤的完整工程闭环，对于书中讨论合成数据管线（Ch13）和后训练阶段（Ch15）具有决定性的指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2212-10560-e51b4a16ecff.md", "note_path": "notes/ref-036-self-instruct.md", "score_total": 9.4}
{"title": "[2304.12244] WizardLM: Empowering large pre-trained language models to follow complex instructions", "url": "https://arxiv.org/abs/2304.12244", "category_id": "training", "category": "Training & Alignment", "chapter_targets": ["13-data", "15-posttrain", "10-intelligence"], "one_liner": "提出 Evol-Instruct 方法，通过 LLM 自动生成高复杂度指令数据，显著提升模型指令遵循能力。", "summary": "本文介绍了 WizardLM 及其背后的 Evol-Instruct 框架。该方法利用 LLM 将简单指令自动重写为包含多约束、深度推理及复杂输入的困难指令。实验证明，WizardLM 在代码、数学和复杂任务上优于 Alpaca 和 Vicuna，强调了指令复杂度在 SFT 中的核心作用。", "key_points": ["提出 Evol-Instruct：一种利用 LLM 自动进化生成高复杂度、多样化指令数据的闭环方法，减少人工依赖。", "进化策略：包含深度进化（增加约束、深化、具体化、增加推理步骤、复杂化输入）和广度进化（变异生成新领域指令）。", "性能突破：WizardLM 在多项基准测试中超越了同规模开源模型，并在高难度任务上接近 ChatGPT 水平。", "关键结论：证明了指令微调（SFT）的效果核心在于训练数据的复杂度，而非单纯的数量堆砌。"], "tags": ["LLM", "指令微调", "Evol-Instruct", "WizardLM", "合成数据"], "scores": {"relevance": 9, "authority": 9, "recency": 7, "depth": 8, "actionability": 8}, "score_reason": "该论文是指令微调领域的里程碑，详细解释了如何利用 LLM 进行自动化数据工程，其 Evol-Instruct 方法提供的 Prompt 策略具有极高的工程实践参考价值。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2304-12244-a2a03dd0f8f2.md", "note_path": "notes/ref-066-wizardlm.md", "score_total": 8.4}
{"title": "[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs", "url": "https://arxiv.org/abs/2305.14314", "category_id": "training", "category": "Training & Alignment", "chapter_targets": ["15-posttrain", "16-inference"], "one_liner": "QLoRA 实现了在单块 48GB GPU 上微调 65B 参数模型，且性能不逊于 16 位全量微调。", "summary": "本文介绍 QLoRA 算法，通过 4-bit NormalFloat 量化、双重量化和分页优化器，极大地降低了 LLM 微调的显存开销。实验证明，在高质量小数据集上进行 4 位微调可达到 SOTA 性能。该研究不仅优化了显存，还深入探讨了数据质量对模型性能的关键影响。", "key_points": ["提出 4-bit NormalFloat (NF4) 数据类型，针对正态分布的权重实现信息理论上的最优量化。", "通过双重量化（Double Quantization）处理量化常数，显著减少了显存占用而不损失精度。", "引入分页优化器（Paged Optimizers）利用 NVIDIA 统一内存管理，有效应对长序列训练时的显存峰值。", "实证分析显示数据质量比数量更重要，Guanaco 模型在 Vicuna 基准上达到了 ChatGPT 99.3% 的水平。"], "tags": ["QLoRA", "低比特微调", "显存优化", "量化技术", "Guanaco"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 10}, "score_reason": "这是高效模型微调（PEFT）领域的里程碑式论文，对于在受限资源下开发 AI 产品具有极高的实战指导价值。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2305-14314-2e95ee3ff8d6.md", "note_path": "notes/ref-047-qlora.md", "score_total": 9.55}
{"title": "[2203.02155] Training language models to follow instructions with human feedback", "url": "https://arxiv.org/abs/2203.02155", "category_id": "training", "category": "Training & Alignment", "chapter_targets": ["14-pretrain", "15-posttrain", "18-evaluation"], "one_liner": "OpenAI 关于 InstructGPT 的里程碑论文，确立了 RLHF 在大模型指令对齐中的核心地位。", "summary": "该论文详细介绍了如何通过人类反馈强化学习 (RLHF) 使 GPT-3 遵循人类指令。研究通过监督微调、奖励模型训练和 PPO 算法优化，证明了 1.3B 参数的 InstructGPT 在人工评估中优于 175B 的 GPT-3，显著提升了模型的有用性、诚实性和无害性。", "key_points": ["系统阐述了 RLHF 的三个阶段：监督微调 (SFT)、奖励模型 (RM) 训练和 PPO 强化学习优化。", "提出 InstructGPT 模型，证明了小规模参数通过对齐训练可在指令遵循任务上超越大规模基座模型。", "引入 PPO-ptx 方法，通过在强化学习中加入预训练梯度来缓解“对齐税”导致的通用能力退化。", "实验验证了模型在真实性提升、毒性降低以及对未见任务（如代码和非英语指令）的泛化能力。"], "tags": ["RLHF", "InstructGPT", "模型对齐", "PPO", "指令遵循"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 7}, "score_reason": "这是大模型领域的必读论文，定义了当前主流模型对齐的技术范式。虽然发布于 2022 年，但其工程架构和评估方法论对于构建 AI 驱动的软件产品具有深远的指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2203-02155-1098fc60be7c.md", "note_path": "notes/ref-041-rlhf.md", "score_total": 9.1}
{"title": "[2305.18290] Direct Preference Optimization: Your Language Model is Secretly a Reward Model", "url": "https://arxiv.org/abs/2305.18290", "category_id": "training", "category": "Training & Alignment", "chapter_targets": ["15-posttrain", "07-engineering"], "one_liner": "介绍了一种无需强化学习即可实现人类偏好对齐的直接偏好优化（DPO）算法。", "summary": "本文提出了直接偏好优化（DPO）算法，作为传统RLHF的替代方案。DPO通过重构奖励函数与最优策略的关系，将偏好学习转化为简单的分类损失函数。该方法消除了强化学习的不稳定性与高算力需求，在摘要生成、对话等任务中表现优于或持平于PPO，显著简化了模型对齐流程。", "key_points": ["将复杂的强化学习对齐问题转化为简单的二元交叉熵分类问题", "训练过程中无需进行模型采样，大幅降低了计算开销和内存占用", "消除了PPO等算法在超参数调优和训练稳定性方面的困难", "理论证明了通过策略模型可以直接表示隐含的奖励函数", "在情感控制、文本摘要和对话任务上的实验结果均优于或匹配PPO效果"], "tags": ["DPO", "RLHF", "模型对齐", "LLM", "微调"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 10, "actionability": 9}, "score_reason": "DPO是目前大语言模型对齐领域最主流的工业级技术之一，具有极高的理论地位和实践指导价值，是产品工程化阶段模型微调的关键参考文献。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2305-18290-d5a5216fcde8.md", "note_path": "notes/ref-042-dpo.md", "score_total": 9.7}
{"title": "[2309.06180] Efficient Memory Management for Large Language Model Serving with PagedAttention", "url": "https://arxiv.org/abs/2309.06180", "category_id": "inference", "category": "Inference & Optimization", "chapter_targets": ["09-backend", "16-inference", "17-deployment"], "one_liner": "介绍 vLLM 核心算法 PagedAttention，通过借鉴操作系统分页内存管理机制极大提升 LLM 推理吞吐量。", "summary": "本文提出了 PagedAttention 算法及 vLLM 推理引擎。针对 LLM 服务中 KV Cache 动态增长导致的严重内存碎片问题，借鉴操作系统分页技术，将 KV Cache 存储在非连续物理内存中。实验证明，vLLM 相比现有系统能提升 2-4 倍吞吐量，且支持高效的内存共享。", "key_points": ["识别出 LLM 推理瓶颈在于 KV Cache 预分配导致的内存浪费和碎片（高达 60%-80%）。", "提出 PagedAttention，允许将连续的逻辑 KV 块映射到非连续的物理内存块。", "实现 vLLM 系统，通过块级内存管理实现 KV Cache 近乎零浪费，并支持 Beam Search 等算法的内存共享。", "在多种主流模型（如 LLaMA, OPT）上验证了其在长序列和大 batch 场景下的显著吞吐量优势。"], "tags": ["vLLM", "PagedAttention", "KV Cache", "推理优化", "内存管理"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 10, "actionability": 9}, "score_reason": "该论文是 LLM 部署与服务领域的里程碑工作，其提出的 vLLM 框架已成为工业界推理服务的标准。对于理解 AI 产品如何降低推理成本、提高响应速度具有核心指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2309-06180-ef8b5f9fca84.md", "note_path": "notes/ref-045-vllm.md", "score_total": 9.55}
{"title": "github-com-nvidia-tensorrt-llm", "url": "https://github.com/NVIDIA/TensorRT-LLM", "category_id": "inference", "category": "Inference & Optimization", "chapter_targets": ["16-inference", "17-deployment", "09-backend"], "one_liner": "NVIDIA推出的高性能大语言模型推理优化加速框架。", "summary": "TensorRT-LLM是NVIDIA开源的LLM推理优化库，通过自定义注意力内核、动态批处理、分页KV缓存及多种量化技术（FP8/FP4/INT4），显著提升了在NVIDIA GPU上的推理效率。它提供易用的Python API，并深度集成于PyTorch生态。", "key_points": ["支持DeepSeek-R1和Llama等主流模型的高性能推理优化", "提供分页KV缓存（Paged KV Caching）和运行中批处理（In-flight Batching）", "支持FP8、FP4、INT4 AWQ等多种先进量化方案", "基于PyTorch的原生架构，支持多GPU和多节点部署"], "tags": ["LLM推理", "GPU加速", "量化", "NVIDIA", "深度学习框架"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 9, "actionability": 8}, "score_reason": "作为NVIDIA官方推出的推理优化框架，它是AI产品落地中处理高性能后端推理和模型压缩的权威资源，与书中推理、部署及后端架构章节高度契合。", "ok": true, "snapshot_path": "sources/md/github-com-nvidia-tensorrt-llm-754595d3bef4.md", "score_total": 9.4}
{"title": "[2210.17323] GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers", "url": "https://arxiv.org/abs/2210.17323", "category_id": "inference", "category": "Inference & Optimization", "chapter_targets": ["16-inference", "17-deployment"], "one_liner": "GPTQ 是一种高效的模型量化方法，可在几小时内将千亿参数模型量化至 3-4 bit 且几乎不损精度。", "summary": "本文提出 GPTQ，一种针对大语言模型的高效后训练量化方法。它基于二阶信息，能将 OPT-175B 等模型在 4 小时内量化至 3-4 bit，显著降低显存需求（如单卡运行 175B 模型），并实现 3-4 倍的推理加速，是当前 LLM 部署优化的核心技术之一。", "key_points": ["高效性：利用近似二阶信息，仅需约 4 个 GPU 小时即可完成 175B 参数规模模型的量化。", "高精度：在 3-4 bit 极低位宽下，模型困惑度（Perplexity）相对 FP16 基准几乎无损。", "部署优化：大幅降低硬件门槛，支持在单张 A100 或两张 A6000 上运行 175B 规模模型。", "性能提升：通过自定义 GPU 核函数减少内存带宽瓶颈，实现 3.25x 至 4.5x 的推理加速。"], "tags": ["模型量化", "GPTQ", "LLM部署", "推理加速", "后训练量化"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 9}, "score_reason": "该论文是 LLM 量化领域的基石，直接解决了大模型产品化过程中的算力和显存痛点，对 AI 工程化部署具有极高的实战指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2210-17323-d01b1de59747.md", "note_path": "notes/ref-048-gptq.md", "score_total": 9.4}
{"title": "[2306.00978] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration", "url": "https://arxiv.org/abs/2306.00978", "category_id": "inference", "category": "Inference & Optimization", "chapter_targets": ["16-inference", "17-deployment"], "one_liner": "提出 AWQ 算法，通过保护 1% 的显著权重实现大模型的高效 4 位量化与边缘端推理加速。", "summary": "本文提出 AWQ 激活感知权重量化方法，发现 LLM 中仅 1% 的权重对性能至关重要。通过分析激活分布识别显著通道，并采用等效变换缩放权重以减小量化误差。配套的 TinyChat 框架在移动 GPU 上实现 3 倍以上加速，支持 70B 模型在边缘端平滑运行。", "key_points": ["发现大模型中仅 0.1%-1% 的显著权重决定了量化性能，通过激活分布而非权重分布可精准识别。", "采用硬件友好的等效缩放变换（Scaling）保护显著权重，无需反向传播或重构，避免过拟合。", "开发 TinyChat 推理框架，通过算子融合和 SIMD 感知权重打包，在桌面及移动端实现大幅加速。", "具有极强的泛化性，不仅适用于各类 LLM，还在指令微调模型和多模态模型上表现卓越。"], "tags": ["AWQ", "模型量化", "LLM推理", "边缘计算", "TinyChat", "4-bit"], "scores": {"relevance": 9, "authority": 10, "recency": 8, "depth": 9, "actionability": 8}, "score_reason": "该论文是 LLM 量化领域的里程碑工作，获得了 MLSys 2024 最佳论文奖。它不仅在算法上解决了低比特量化的精度损耗问题，还提供了完整的系统实现（TinyChat），对于 AI 产品在终端设备上的落地具有极强的指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2306-00978-9d933cbebef5.md", "note_path": "notes/ref-059-awq.md", "score_total": 8.9}
{"title": "Text Generation Inference", "url": "https://github.com/huggingface/text-generation-inference", "category_id": "inference", "category": "Inference & Optimization", "chapter_targets": ["16-inference", "17-deployment"], "one_liner": "Hugging Face 开发的生产级高性能大语言模型推理与服务框架。", "summary": "TGI 是用于部署 LLM 的高性能工具包，支持连续批处理、张量并行和 Token 流。它集成了 Flash Attention 和 Paged Attention 优化技术，并提供多种量化方案与 OpenAI 兼容接口。虽然目前处于维护模式，但仍是理解高并发推理服务的行业标准实现。", "key_points": ["支持连续批处理（Continuous batching）技术，显著提升系统总吞吐量", "针对主流架构集成 Flash Attention 和 Paged Attention 优化推理性能", "支持 bitsandbytes、GPT-Q 和 AWQ 等多种先进的模型量化与权重加载方案", "提供兼容 OpenAI 的 Messages API，支持分布式追踪与 Prometheus 指标监控"], "tags": ["LLM 推理", "模型部署", "Hugging Face", "量化优化", "高并发"], "scores": {"relevance": 10, "authority": 10, "recency": 7, "depth": 9, "actionability": 9}, "score_reason": "作为 Hugging Face 官方工具，该项目在推理优化领域具有极高的技术深度。虽然转入维护模式，但其核心架构仍是大模型后端工程的必读参考。", "ok": true, "snapshot_path": "sources/md/github-com-huggingface-text-generation-inference-07efbedb395d.md", "note_path": "notes/ref-049-tgi.md", "score_total": 9.25}
{"title": "KServe", "url": "https://kserve.github.io/website/", "category_id": "inference", "category": "Inference & Optimization", "chapter_targets": ["16-inference", "17-deployment"], "one_liner": "基于 Kubernetes 的标准化分布式生成式与预测式 AI 推理平台。", "summary": "KServe 是 CNCF 孵化项目，为 Kubernetes 提供统一的 AI 推理平台。它支持生成式（LLM）与预测式 AI，具备 OpenAI 兼容协议、GPU 加速、模型缓存、自动缩放（支持缩容至零）及金丝雀发布等功能，显著简化了跨框架模型的部署、扩展与运维流程。", "key_points": ["提供标准化的 Kubernetes CRD (InferenceService) 简化模型全生命周期管理。", "针对生成式 AI 优化，支持 OpenAI 兼容接口、KV 缓存掉电保护及 GPU 加速。", "支持多框架部署（如 TensorFlow, PyTorch, Hugging Face 等）及推理图流水线。", "具备强大的自动缩放能力，支持基于请求的扩缩容以及在空闲时缩容至零以节省成本。", "内置高级部署策略，如金丝雀发布、A/B 测试以及模型可解释性支持。"], "tags": ["AI推理", "Kubernetes", "模型服务", "LLM运维", "CNCF"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 8, "actionability": 9}, "score_reason": "作为 CNCF 孵化项目，KServe 是 Kubernetes 环境下 AI 模型服务的行业标准。其不仅涵盖了传统的预测式 AI，还针对现代 LLM 推理提供了深度优化（如 OpenAI 协议兼容和 KV 缓存优化），对本书的推理与部署章节具有极高的参考价值和实践指导意义。", "ok": true, "snapshot_path": "sources/md/kserve-github-io-website-1fb96b32d9c9.md", "note_path": "notes/ref-063-kserve.md", "score_total": 9.4}
{"title": "Documentation | OpenTelemetry", "url": "https://opentelemetry.io/docs/", "category_id": "ops", "category": "Deployment & Operations", "chapter_targets": ["17-deployment", "16-inference", "09-backend", "07-engineering"], "one_liner": "业界领先的开源可观测性框架官方文档，涵盖指标、追踪和日志的标准实现。", "summary": "OpenTelemetry 是云原生计算基金会（CNCF）旗下的标准化可观测性框架。该文档详述了如何通过统一的 API、SDK 和工具收集并导出指标、追踪和日志数据。其语义约定部分已扩展至生成式 AI 领域，是构建可观测现代软件系统的权威指南。", "key_points": ["定义了追踪（Traces）、指标（Metrics）和日志（Logs）三位一体的开放标准。", "支持跨语言（Java, Python, JS等）的无侵入和手动插桩实现。", "提供 Collector 架构用于遥测数据的接收、转换与高效导出。", "包含专门针对生成式 AI（GenAI）的语义约定，支持监控模型调用与 Agent 状态。"], "tags": ["可观测性", "云原生", "OpenTelemetry", "分布式追踪", "GenAI监控"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 10, "actionability": 9}, "score_reason": "作为可观测性领域的事实标准，该文档不仅深度涵盖了基础设施监控，还前瞻性地制定了 GenAI 语义规范，对构建生产级可观测 AI 系统具有极高的工程实践参考价值。", "ok": true, "snapshot_path": "sources/md/opentelemetry-io-docs-8de8f872c85e.md", "note_path": "notes/ref-061-opentelemetry.md", "score_total": 9.35}
{"title": "[2306.05685] Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena", "url": "https://arxiv.org/abs/2306.05685", "category_id": "evaluation", "category": "Evaluation", "chapter_targets": ["18-evaluation", "15-posttrain", "19-iteration"], "one_liner": "探讨使用强语言模型（如 GPT-4）作为裁判来评估聊天助手在开放式任务中表现的开创性研究。", "summary": "本文介绍了使用 LLM 评估 LLM 的方法（LLM-as-a-judge），提出了 MT-bench 和 Chatbot Arena 两个基准测试。研究发现 GPT-4 作为裁判与人类偏好的一致性超过 80%，并分析了位置偏见、冗长偏见等局限性及缓解方案，证明了该方法在评估模型对齐方面的可扩展性。", "key_points": ["提出 MT-bench（多轮对话）和 Chatbot Arena（众包竞技场）两个衡量人类偏好的基准测试", "验证了 GPT-4 作为裁判与人类专家的一致性达到了人类间一致性的水平（>80%）", "识别并分析了 LLM 裁判存在的偏见，包括位置偏见、冗长偏见、自我增强偏见以及推理能力局限", "提出了缓解偏见的具体方案，如交换位置评分、少样本引导和参考答案辅助评分（Reference-guided）"], "tags": ["LLM-as-a-Judge", "MT-bench", "Chatbot Arena", "模型评测", "人类偏好对齐"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 9}, "score_reason": "该论文是 LLM 自动评测领域的奠基性工作，详细探讨了如何利用 GPT-4 等强模型替代昂贵的人类标注，对于构建 AI 产品研发中的自动化评估闭环具有极高的指导意义。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2306-05685-16e11e26be5b.md", "note_path": "notes/ref-050-llm-as-a-judge.md", "score_total": 9.4}
{"title": "Overview | Prometheus", "url": "https://prometheus.io/docs/introduction/overview/", "category_id": "ops", "category": "Deployment & Operations", "chapter_targets": ["09-backend", "17-deployment", "19-iteration"], "one_liner": "Prometheus 是一个开源的系统监控和报警工具包，专注于多维时间序列数据采集与可靠性。", "summary": "Prometheus 是一款针对云原生环境设计的监控系统，采用拉取模式采集多维时间序列指标。它不依赖分布式存储，具备强大的 PromQL 查询语言和完善的报警机制，特别适合微服务架构下的可靠性监控。但由于其追求高可用而非绝对精确，不建议用于结算计费。", "key_points": ["多维数据模型：通过指标名称和键值对标签定义时间序列。", "拉取模型：主要通过 HTTP 协议从目标拉取数据，并支持服务发现。", "自治架构：服务器节点独立运行，不依赖分布式存储或远程服务。", "生态组件：包含核心服务器、客户端库、推送网关、特殊用途导出器和报警管理器。"], "tags": ["监控", "Prometheus", "云原生", "时间序列", "运维", "指标采集"], "scores": {"relevance": 8, "authority": 10, "recency": 9, "depth": 7, "actionability": 8}, "score_reason": "作为监控领域的行业标准，该文档由官方维护，权威性极高。它清晰地定义了监控系统的边界和适用场景，对后端系统设计和运维部署具有极高的参考价值。", "ok": true, "snapshot_path": "sources/md/prometheus-io-docs-introduction-overview-e7be7b92116c.md", "note_path": "notes/ref-062-prometheus.md", "score_total": 8.4}
{"title": "Grafana OSS and Enterprise | Grafana documentation", "url": "https://grafana.com/docs/grafana/latest/", "category_id": "ops", "category": "Deployment & Operations", "chapter_targets": ["17-deployment"], "one_liner": "全球领先的开源监控与可视化平台，提供涵盖指标、日志和链路追踪的完整可观测性方案。", "summary": "Grafana 官方文档详尽介绍了其 OSS 和企业版的核心功能。内容涵盖从多源数据集成（Prometheus、Loki 等）到高级仪表盘可视化、复杂告警配置、权限管理及高可用部署。它是构建 AI 应用生产环境观测体系、确保系统性能与稳定性的权威参考指南。", "key_points": ["支持多维数据可视化，包括时间序列、日志、追踪、火焰图和地理图等多种面板。", "集成了强大的告警系统，支持多级通知策略、静默管理及多维度告警触发。", "提供详尽的数据源管理指南，兼容几乎所有主流的数据库和监控系统。", "涵盖企业级安全特性，如角色访问控制 (RBAC)、服务账号管理及审计日志功能。"], "tags": ["可观测性", "监控", "可视化", "运维", "指标分析"], "scores": {"relevance": 9, "authority": 10, "recency": 10, "depth": 10, "actionability": 9}, "score_reason": "作为行业标准的监控可视化工具，其文档极具权威性且更新及时。对于 AI 软件产品的生产部署与运行观测（Chapter 17）具有不可替代的实践指导价值。", "ok": true, "snapshot_path": "sources/md/grafana-com-docs-grafana-latest-02ef4859d21b.md", "note_path": "notes/ref-064-grafana.md", "score_total": 9.5}
{"title": "[2402.01822] Building Guardrails for Large Language Models", "url": "https://arxiv.org/abs/2402.01822", "category_id": "governance", "category": "Governance & Security", "chapter_targets": ["10-intelligence", "16-inference", "20-governance"], "one_liner": "本文系统性地探讨了构建大语言模型（LLM）护栏（Guardrails）的挑战与路径，对比了主流开源方案并提出了系统化工程方法。", "summary": "本研究深入分析了Llama Guard、Nvidia NeMo和Guardrails AI等主流框架，提出了一套构建LLM护栏的系统性方法。通过社会技术方法确定需求，利用神经符号架构应对复杂性，并结合验证与测试，旨在解决大模型在伦理、偏见、隐私及幻觉等方面的关键风险。", "key_points": ["对比分析了Llama Guard（类型1神经符号）、Nvidia NeMo及Guardrails AI（类型2）的架构差异与优劣。", "详细探讨了处理非预期响应、公平性、隐私版权及幻觉这四大类技术挑战的现状与缓解策略。", "提倡采用神经符号化（Neural-Symbolic）设计，将符号化规则的确定性与神经网络的泛化能力结合。", "强调了必须建立类似安全关键软件的严谨工程流程（规范、设计、验证），以应对LLM应用中的复杂安全需求。"], "tags": ["Guardrails", "AI安全", "神经符号系统", "幻觉治理", "合规工程"], "scores": {"relevance": 10, "authority": 9, "recency": 9, "depth": 8, "actionability": 7}, "score_reason": "ICML 2024发表的高质量论文，系统性地梳理了当前LLM护栏的技术版图，为AI产品的安全治理（第20章）和推理防护（第16章）提供了清晰的理论与架构参考。", "ok": true, "snapshot_path": "sources/md/arxiv-org-abs-2402-01822-ace66bba058a.md", "note_path": "notes/ref-051-guardrails.md", "score_total": 8.9}
{"title": "Continuous Discovery Habits (the Book) is Finally Here!", "url": "https://www.producttalk.org/continuous-discovery-habits/", "category_id": "product_discovery", "category": "Discovery & Product Strategy", "chapter_targets": ["01-method", "02-discovery", "05-validation"], "one_liner": "Teresa Torres 发布的《持续发现习惯》旨在为产品团队提供一套结构化且可持续的持续发现指南。", "summary": "Teresa Torres 的新书《持续发现习惯》正式发布，为产品团队提供了一套结构化、可持续的发现指南。内容聚焦于从明确成果目标出发，通过访谈发现机会，利用机会解决方案树进行可视化，以及通过假设测试快速验证方案，旨在通过持续实践提升产品决策质量。", "key_points": ["引入“产品三人组”协作模式进行持续且结构化的产品发现", "强调从单纯交付功能“输出”转向追求“业务成果”的目标设定", "利用机会解决方案树（OST）对客户机会、解决方案和实验进行可视化对齐", "通过快速的假设测试而非长周期的方案验证来降低产品风险"], "tags": ["持续发现", "机会解决方案树", "产品发现", "成果导向", "假设测试"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 10}, "score_reason": "该资源由领域权威 Teresa Torres 撰写，是产品发现领域的方法论基石，提供了极具实操性的练习和工具，与本书的方法论、需求挖掘及验证章节高度契合。", "ok": true, "snapshot_path": "sources/md/www-producttalk-org-continuous-discovery-habits-0bd7e1e218e1.md", "note_path": "notes/ref-073-continuous-discovery-habits.md", "score_total": 9.55}
{"title": "Guidelines for Human-AI Interaction - Microsoft Research", "url": "https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/", "category_id": "ux_ui", "category": "UX / UI & Design Systems", "chapter_targets": ["06-ui", "05-validation", "20-governance", "11-user"], "one_liner": "微软研究院发布的 18 条人机交互设计准则及 HAX 工具包。", "summary": "本资源汇总了微软研究院提出的 18 条通用人机交互设计准则，旨在解决 AI 系统的不确定性给用户体验带来的挑战。涵盖了从初始阶段、交互过程中、出错时到长期使用的全生命周期，并提供了 HAX Toolkit 辅助开发者进行以人为本的 AI 产品设计。", "key_points": ["提出 18 条经过多轮验证的人机交互设计准则", "涵盖系统初始、交互中、出错及长期演化四个阶段", "配套 HAX Toolkit 提供工作手册、设计模式和演练方案", "强调负责任的 AI 设计与用户感知、接受度之间的关键联系"], "tags": ["人机交互", "AI设计准则", "用户体验", "HAX Toolkit", "负责任AI"], "scores": {"relevance": 10, "authority": 10, "recency": 7, "depth": 9, "actionability": 9}, "score_reason": "该资源由微软研究院发布并获 CHI 2019 荣誉提名，是 AI 产品设计领域的基石。其提出的准则和配套工具包对于处理生成式 AI 的不确定性交互具有极高的指导意义。", "ok": true, "snapshot_path": "sources/md/www-microsoft-com-en-us-research-publication-guidelines-for-huma-78f401875351.md", "note_path": "notes/ref-071-human-ai-interaction.md", "score_total": 9.25}
{"title": "PAIR Guidebook", "url": "https://pair.withgoogle.com/guidebook/", "category_id": "ux_ui", "category": "UX / UI & Design Systems", "chapter_targets": ["02-discovery", "03-prd", "06-ui", "11-user"], "one_liner": "Google 出品的以人为本 AI 产品设计深度指南。", "summary": "由 Google PAIR 团队编写的权威手册，专注于 AI 产品的用户体验设计。涵盖了如何建立用户信任、设定心理预期、处理 AI 错误以及设计有效的反馈机制。它是将 AI 技术转化为可信、易用的产品体验的行业标准参考，提供了 23 种具体的设计模式和实践建议。", "key_points": ["建立用户对 AI 系统的信任与心理模型", "设计透明且可解释的 AI 交互界面", "优雅地处理 AI 模型的不确定性和错误输出", "构建以用户为中心的数据收集与反馈闭环"], "tags": ["人机交互", "UX 设计", "AI 心理学", "设计规范"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 9, "actionability": 9}, "score_reason": "Google 官方背书，是 AI 领域最权威的设计指南之一。其提供的设计原则和模式对产品经理和 UI/UX 设计师具有极高的实操价值，深度解决了 AI 产品化的核心痛点。", "ok": true, "snapshot_path": "sources/md/pair-withgoogle-com-guidebook-9f0318b11693.md", "note_path": "notes/ref-072-pair-guidebook.md", "score_total": 9.4}
{"title": "Overview", "url": "https://github.com/stoplightio/spectral", "category_id": "prd_spec", "category": "PRD & Specs", "chapter_targets": ["03-prd", "07-engineering", "09-backend", "20-governance"], "one_liner": "专注于 API 风格指南和合约校验的 JSON/YAML 自动化 linting 工具。", "summary": "Spectral 是一款开源的 JSON/YAML 校验工具，专为 OpenAPI 和 AsyncAPI 设计。它通过自动化 API 风格指南和自定义规则集确保接口一致性，支持 CLI、JS API 及主流编辑器集成，是实施 API 契约校验和治理的核心技术。", "key_points": ["内置对 OpenAPI v2/v3、AsyncAPI 和 Arazzo v1 标准的全面支持。", "支持通过规则集（Rulesets）和自定义函数实现个性化的 API 设计指南。", "提供灵活的集成选项，包括 CLI 命令行工具、JavaScript SDK 和 VS Code 插件。", "可作为质量门禁集成在 CI/CD 流程中，确保存储库中的文档符合设计规范。"], "tags": ["API Linting", "OpenAPI", "API 治理", "契约校验", "JSON/YAML"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 8, "actionability": 10}, "score_reason": "该资源是 API 校验领域的行业标准工具文档，内容详实且极具可操作性，对本书中关于 API 合约与治理的章节有极高的参考价值。", "ok": true, "snapshot_path": "sources/md/github-com-stoplightio-spectral-26c88b5d55ba.md", "note_path": "notes/ref-065-spectral.md", "score_total": 9.55}
{"title": "従量課金 | Stripe のドキュメント", "url": "https://docs.stripe.com/billing/subscriptions/usage-based", "category_id": "billing", "category": "Billing & Pricing", "chapter_targets": ["12-billing"], "one_liner": "Stripe 官方关于按量计费模式的实现指南，涵盖数据记录、信用额度与监控。", "summary": "该文档详细介绍了 Stripe Billing 的按量计费功能，允许 SaaS 企业根据产品实际使用量向客户收费。内容包括记录使用数据、提供预付或促销信用积分、设置使用阈值监控，并特别提及了针对 LLM 令牌等现代 AI 应用场景的计费支持。", "key_points": ["按量计费是 SaaS 业务中基于实际使用情况进行收费的灵活模型。", "提供了记录和上报客户使用数据的标准流程，确保账单准确性。", "支持提供计费积分（Billing Credits），适用于预付或促销场景。", "可设置使用量监控报警，当客户消费超过特定阈值时触发通知。", "集成了专门针对大语言模型（LLM）Token 消耗的计费方案。"], "tags": ["Stripe", "按量计费", "SaaS", "支付系统", "Token计费"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 7, "actionability": 9}, "score_reason": "该资源源自支付领域权威 Stripe 的官方文档，内容直接针对 AI 产品最核心的按量计费（如 Token 计费）需求，提供了完整的实施路径，具有极高的实操参考价值。", "ok": true, "snapshot_path": "sources/md/docs-stripe-com-billing-subscriptions-usage-based-06655737082c.md", "note_path": "notes/ref-075-stripe-usage-based-billing.md", "score_total": 9.25}
{"title": "RFC 2119: Key words for use in RFCs to Indicate Requirement Levels", "url": "https://www.rfc-editor.org/rfc/rfc2119", "category_id": "prd_spec", "category": "PRD & Specs", "chapter_targets": ["03-prd", "07-engineering", "20-governance"], "one_liner": "定义了技术规范文档中用于标识需求强制程度的标准关键词解释。", "summary": "RFC 2119 规定了在 IETF 及其它技术文档中使用的关键词含义，如 MUST、SHOULD 和 MAY。它为需求的约束力提供了精确定义，旨在消除规范制定者与实现者之间的歧义。对于编写高质量 PRD、工程合同及系统设计文档具有至关重要的参考价值。", "key_points": ["明确了 MUST、REQUIRED 和 SHALL 代表规范的绝对要求", "定义了 SHOULD 和 RECOMMENDED 表示除非有充分理由否则必须遵守的建议", "解释了 MAY 和 OPTIONAL 属于真正的可选项目，需保证互操作性", "强调这些命令词应谨慎使用，主要用于确保互操作性或限制有害行为", "指出不遵循 MUST 或 SHOULD 等要求可能带来的潜在安全影响"], "tags": ["标准化", "需求定义", "技术规范", "互操作性"], "scores": {"relevance": 10, "authority": 10, "recency": 5, "depth": 7, "actionability": 10}, "score_reason": "作为全球互联网标准的基础，RFC 2119 在定义需求等级方面具有无可挑战的权威性和可落地性，是编写任何技术规格说明书的必读基石。", "ok": true, "snapshot_path": "sources/md/www-rfc-editor-org-rfc-rfc2119-71c19fc9d8e6.md", "note_path": "notes/ref-074-rfc2119.md", "score_total": 8.8}
{"title": "Google SRE - Defining slo: service level objective meaning", "url": "https://sre.google/sre-book/service-level-objectives/", "category_id": "ops", "category": "Deployment & Operations", "chapter_targets": ["17-deployment", "18-evaluation", "19-iteration", "07-engineering"], "one_liner": "深入讲解如何通过服务质量指标 (SLI) 和目标 (SLO) 来量化和管理服务的可靠性。", "summary": "本文定义了 SLI、SLO 和 SLA 的核心概念及其差异。详细介绍了如何根据用户需求选择合适的度量指标（如延迟、错误率、吞吐量），强调了使用分位数而非平均值的重要性，并阐述了 SLO 如何作为控制循环的关键环节，用于平衡系统开发速度与运行稳定性之间的权衡关系。", "key_points": ["SLI 是服务水平的定量度量，SLO 是其目标范围，SLA 是包含违约后果的合同。", "不同系统（如前端、存储、管道）关注的 SLI 不同，通常包括可用性、延迟和吞吐量。", "在聚合数据时，百分位数（如 99th）比平均值更能反映影响用户体验的长尾延迟。", "设定 SLO 时应避免绝对化和过度追求完美，利用“错误预算”指导新功能的发布与迭代速度。"], "tags": ["SRE", "SLO", "SLI", "系统可靠性", "错误预算", "可观测性"], "scores": {"relevance": 10, "authority": 10, "recency": 8, "depth": 10, "actionability": 9}, "score_reason": "该资源是 SRE 领域的行业标准教材，权威性极高。它深入浅出地解释了如何量化系统稳定性，提供的指标选择方法和统计学建议对于构建现代化 AI 产品的运维体系具有极强的指导意义。", "ok": true, "snapshot_path": "sources/md/sre-google-sre-book-service-level-objectives-7b9a3e66dbb9.md", "note_path": "notes/ref-076-sre-slo.md", "score_total": 9.55}
{"title": "AI Risk Management Framework | NIST", "url": "https://www.nist.gov/itl/ai-risk-management-framework", "category_id": "governance", "category": "Governance & Security", "chapter_targets": ["20-governance", "18-evaluation", "03-prd", "05-validation"], "one_liner": "NIST 发布的权威 AI 风险管理框架，涵盖可信度标准与生成式 AI 专项指导。", "summary": "该框架（AI RMF 1.0）由 NIST 开发，旨在改善 AI 系统设计、开发和评估中的风险管理与可信度。包含操作手册及 2024 年发布的生成式 AI 专项配置文件，帮助组织识别并应对生成式 AI 带来的独特风险，是构建负责任 AI 产品的核心行业标准。", "key_points": ["提供了一套管理个人、组织和社会 AI 风险的结构化框架。", "强调将可信度考量纳入 AI 产品的全生命周期管理。", "包含 2024 年发布的生成式 AI 专项配置文件（NIST AI 600-1）。", "配套提供 Playbook 和资源中心，支持国际标准对齐与实践落地。"], "tags": ["AI治理", "风险管理", "NIST标准", "可信AI", "合规性"], "scores": {"relevance": 10, "authority": 10, "recency": 9, "depth": 10, "actionability": 8}, "score_reason": "该资源由美国国家标准与技术研究院发布，是全球 AI 治理领域最权威的框架之一，其针对生成式 AI 的最新指南对工程实践具有极高的指导价值。", "ok": true, "snapshot_path": "sources/md/www-nist-gov-itl-ai-risk-management-framework-54dbc1541342.md", "note_path": "notes/ref-077-nist-ai-rmf.md", "score_total": 9.55}
{"title": "RFC 9110: HTTP Semantics", "url": "https://www.rfc-editor.org/rfc/rfc9110", "category_id": "backend", "category": "Backend & Reliability", "chapter_targets": ["09-backend", "17-deployment", "10-intelligence", "03-prd"], "one_liner": "HTTP 协议的权威语义标准，定义了 Web 通信的核心架构与交互规则。", "summary": "本规范详细描述了 HTTP 的总体架构、核心术语及跨版本共享的语义，包括请求方法、状态码、字段、认证及内容协商。作为现代 Web 开发的基石，它取代了 RFC 7231 等旧标准，确保了不同协议版本在语义层面的一致性与互操作性。", "key_points": ["统一接口：通过资源标识与请求语义分离，支持客户端与服务器的独立演进。", "无状态通信：每个请求包含完整信息，便于缓存、负载均衡和分布式扩展。", "核心协议元素：标准化了 GET/POST 等方法、2xx/4xx 等状态码及首部字段含义。", "中间层支持：明确了代理、网关和内建缓存的行为，支撑大规模网络架构。"], "tags": ["HTTP", "Web协议", "RFC", "API设计", "系统架构"], "scores": {"relevance": 9, "authority": 10, "recency": 8, "depth": 10, "actionability": 7}, "score_reason": "作为 Web 开发的根基协议标准，其权威性无可置疑。虽然是底层技术规范，但对设计健壮的后端 API 和理解网络通信性能至关重要。", "ok": true, "snapshot_path": "sources/md/www-rfc-editor-org-rfc-rfc9110-e593c606c957.md", "note_path": "notes/ref-078-http-semantics.md", "score_total": 8.9}
{"title": "RFC 9457: Problem Details for HTTP APIs", "url": "https://www.rfc-editor.org/rfc/rfc9457", "category_id": "backend", "category": "Backend & Reliability", "chapter_targets": ["09-backend", "07-engineering", "03-prd"], "one_liner": "定义 HTTP API 错误详情的机器可读标准格式。", "summary": "RFC 9457 定义了 'problem detail' JSON/XML 对象，用于在 HTTP 响应中携带详细的错误信息。它旨在避免为每个 API 定义新的错误格式，通过标准化 type、title、status、detail 和 instance 等字段，使非人类客户端能够更有效地解析和处理 API 错误。", "key_points": ["标准化的 'problem detail' 模型使用 application/problem+json 媒体类型。", "核心字段包括 type (唯一标识)、title (摘要)、status (状态码)、detail (具体说明) 和 instance (发生实例)。", "支持自定义扩展成员，允许 API 提供特定领域的错误细节（如余额、验证错误路径）。", "废弃了 RFC 7807，增加了常见问题类型的 IANA 注册表，促进跨 API 的互操作性。"], "tags": ["HTTP API", "错误处理", "标准规范", "RFC 9457", "JSON"], "scores": {"relevance": 9, "authority": 10, "recency": 9, "depth": 8, "actionability": 10}, "score_reason": "作为 IETF 的标准规范文档，它是目前 HTTP API 错误处理的事实标准。文档内容详尽且极其权威，包含了完整的 JSON Schema 和 XML 映射，是现代后端架构设计中实现标准化错误处理的直接指南。", "ok": true, "snapshot_path": "sources/md/www-rfc-editor-org-rfc-rfc9457-394ea6adfbc8.md", "note_path": "notes/ref-079-problem-details.md", "score_total": 9.2}
