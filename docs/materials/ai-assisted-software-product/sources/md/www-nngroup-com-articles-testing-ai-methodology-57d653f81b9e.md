# Testing AI with Real Design Scenarios: Evaluation Methodology and Prompts - NN/G

- URL: https://www.nngroup.com/articles/testing-ai-methodology/
- Retrieved: 2025-12-18T10:13:46.921409+00:00

Skip to content
**NEW RESEARCH COURSES: UX Research Methods, Heatmaps | [Learn More](https://www.nngroup.com/news/item/new-courses/)**
Open main navigation [ Nielsen Norman Group ](https://www.nngroup.com/)
  * Training & UX Certification 
    * [All Live Courses](https://www.nngroup.com/courses/)
    * [Live Online Training Events](https://www.nngroup.com/training/live-courses/)
    * [Private Team Training](https://www.nngroup.com/team-training/)
    * [Bulk Discounts](https://www.nngroup.com/training/bulk-discounts/)
    * [UX Certification](https://www.nngroup.com/ux-certification/)
  * [Articles & Videos](https://www.nngroup.com/articles/)
  * [Consulting](https://www.nngroup.com/consulting/)
  * [Reports & Books](https://www.nngroup.com/reports/)
  * About NN/g 
    * [Overview](https://www.nngroup.com/about/)
    * [People](https://www.nngroup.com/people/)
    * [Clients](https://www.nngroup.com/about/about-client-list/)
    * [News](https://www.nngroup.com/news/)
    * [Contact Us](https://www.nngroup.com/about/contact/)


(https://www.nngroup.com/cart/)
Profile 
Search
Search
Reset Search
10
# Testing AI with Real Design Scenarios: Evaluation Methodology and Prompts
Huei-Hsin Wang, Megan Brown, Amy Zhang
[ Huei-Hsin Wang](https://www.nngroup.com/articles/author/huei-hsin-wang/), [ Megan Brown](https://www.nngroup.com/articles/author/megan-brown/) and [ Amy Zhang](https://www.nngroup.com/articles/author/amy-zhang/)
October 24, 2025 2025-10-24
[ Share ]
  * [ Email article ](mailto:?subject=NN/g Article: Testing AI with Real Design Scenarios: Evaluation Methodology and Prompts&body=https://www.nngroup.com/articles/testing-ai-methodology/)
  * [ Share on LinkedIn ](http://www.linkedin.com/shareArticle?mini=true&url=http://www.nngroup.com/articles/testing-ai-methodology/&title=Testing AI with Real Design Scenarios: Evaluation Methodology and Prompts&source=Nielsen%20Norman%20Group)
  * [ Share on Twitter ](https://twitter.com/intent/tweet?url=http://www.nngroup.com/articles/testing-ai-methodology/&text=Testing AI with Real Design Scenarios: Evaluation Methodology and Prompts&via=nngroup)


Summary:  This article describes the prompts and methods that we used to evaluate designs produced with AI tools. 
##  In This Article: 
(#)
  * Real Design Scenarios
  * Evaluation Method
  * AI Tools Tested
  * Single-Page-Design Prompts: Live-Training Profile Page
  * Flow-Design Prompts: Bulk Purchase
  * Evaluation Criteria
  * Challenges and Limitations
  * Lesson Learned


## Real Design Scenarios
To simulate realistic design context, we defined 2 scenarios we faced in our ongoing design workflows at NN/G:
  * **Single-Page Design ‚Äî Live-Training Profile Page** : We asked AI to design the [profile page for attendees of NN/G live online training](https://www.nngroup.com/training/live-courses/); this page should display their course list and certification progress.
  * **Flow Design ‚Äî Bulk Purchase** : [NN/G is expanding to offer an enterprise plan](https://www.nngroup.com/training/bulk-discounts/) that allows teams to buy 100 or more credits for live online courses and receive a volume discount. We asked AI to design the purchase flow based on the outlined requirements.


We share the findings of this evaluation over a series of articles:
  * Insights on single-page design scenario: [Good from Afar, But Far from Good: AI Prototyping in Real Design Contexts](https://www.nngroup.com/articles/ai-prototyping/)
  * Prompting tips: [Prompt to Design Interfaces: Why Vague Prompts Fail and How to Fix Them](https://www.nngroup.com/articles/vague-prototyping/)
  * Insights on multi-page flow scenario _(coming soon)_
  * Insights on redesign scenario _(coming soon)_


All the designs generated by the AI prototyping tools tested are [included in a FigJam board](https://www.figma.com/board/gLi4O1jr7Lo1AWQPZAdKXg/NN-G-AI-Prototyping-Evaluation?node-id=0-1&t=CbbP0fzNSeLIdup5-1).
## Evaluation Method
The evaluation took place in 3 key phases: writing prompts, generating designs with AI, and assessing AI-generated designs.
### Writing Prompts
We used a real design context to develop the prompts used in our evaluation. We started by gathering design requirements and artifacts (hand-drawn sketches, design mockups, and Figma files) from these projects, and turned the information into AI prompts[ following prompting best practices](https://www.nngroup.com/articles/careful-prompts/). To keep the testing setup consistent and ensure results were comparable, we used prompts that included all necessary context. To compare design variations within the same tool, we added a second followup prompt within the same conversation:
> _‚ÄúCreate an alternative design with a distinctly different layout. Keep the same context. Do not modify or change the content.‚Äù_
### Generating Designs with AI
We ran those prompts through each AI tool and collected the outputs. In some cases, we reran the same prompt in new chats to produce additional variants. [All designs were placed on a FigJam board](http://www.figma.com/board/gLi4O1jr7Lo1AWQPZAdKXg/NN-G-AI-Prototyping-Evaluation?node-id=0-1&t=CbbP0fzNSeLIdup5-1) so we could review and compare them side by side.
### Assessing AI-Generated Designs
We conducted[ heuristic evaluation](https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/)s to assess the AI-generated designs. Each design was evaluated through the lens of the main tasks to identify design elements, features, or decisions that violate the defined criterion. We also compared the AI-generated design to real designs created by NN/G designers without using AI.
## AI Tools Tested
We ran each prompt across 3 categories of AI prototyping tools that we considered to be most relevant to a designer‚Äôs workflow.
**Category** |  **Primary design output** |  **Tools**  
---|---|---  
**AI-assisted design** |  Static wireframes or design mockups with limited interactivity |  UX Pilot, Figma First Draft, Uizard, Stitch (formerly Galileo AI), Relume  
**AI-assisted**(vibe)**coding** |  Interactive code-based prototypes |  V0, Bolt, Lovable, Replit, Figma Make, Magic Patterns, Subframe  
**General-purpose AI chatbots** |  ChatGPT, Claude  
Note: We did not include AI code editors (such as Cursor and Windsurf) or command-line interfaces (such as Claude Code) as these tools require more technical setup and extend beyond a typical designer‚Äôs workflow.
## Single-Page-Design Prompts: Live-Training Profile Page
To match our testing to real design scenarios across various stages of the design process, we created **4 types of prompts** with various degrees of input specificity while maintaining the same context and request.
#### Prompt 1. Broad Text Prompt
> _You are a senior product designer at Nielsen Norman Group, a UX research consultancy that offers live online training on UX topics. Your task is to design a profile page in the desktop viewport for course attendees participating in online training. The page should allow attendees to view all the courses they‚Äôve taken, access downloadable course materials for each course, check the status of summative course exams, and track their progress toward UX certification._
#### Prompt 2. Specific Text Prompt
> _You are a senior product designer at Nielsen Norman Group, a UX research  
>  consultancy that offers live online training on UX topics. Your task is to design a  
>  profile page in the desktop viewport for course attendees participating in online  
>  training. The page should allow attendees to view all the courses they&#39;ve taken,  
>  access downloadable course materials for each course, check the status of  
>  summative course exams, and track their progress toward UX certification.  
>  ## Page Components  
>  ### 1. Certification Progress Panel:  
>  Show progress towards the following certifications:  
>  \- UX Certification: Requires completion of 5 courses.  
>  \- If the certification is completed, show users how to access the certification._
> _\- UX Master Certification: Requires completion of 15 courses.  
>  \- Specialty Progress Breakdown:  
>  \- Interaction Specialty: Requires 5 interaction-specific courses.  
>  \- Management Specialty: Requires 5 management-specific courses.  
>  \- Research Specialty: Requires 5 research-specific courses.  
>  ### 2. Course History Section:  
>  Display a list of all past live online courses taken by the user.  
>  \- For each course, include:  
>  \- Course title  
>  \- Specialty (Interaction, Management, Research)  
>  \- Exam deadline (if applicable)  
>  \- Remaining exam attempts (3 attempts max)  
>  \- Course material access (including material password)  
>  \- Exam status:  
>  \- Passed/Failed indicator  
>  \- Option to take or resume the exam, if applicable  
>  \- Consider various course scenarios:  
>  \- If the exam deadline has passed, display a message indicating the exam is no  
>  longer available.  
>  \- If the user did not take the exam but is eligible to purchase an exam extension,  
>  provide a purchase link.  
>  \- If the user failed all three attempts, display an option to retake the course at a  
>  discounted price.  
>  \- If the user needs to purchase an exam credit to take the exam, display a link to  
>  purchase.  
>  ### 3. Exam Credits Component:  
>  \- Show the number of available exam credits.  
>  \- Provide a purchase option for additional credits if needed.  
>  ### 4. Course Sorting and Filtering:  
>  Allow users to sort their courses by:  
>  \- Specialty (Interaction, Management, Research)  
>  \- Exam progress (Pending, Passed, Failed)  
>  ## Design Language  
>  ### Visual Style  
>  \- Mature  
>  \- Balanced  
>  \- Trustworthy  
>  \- Clear_
> _\- Research-driven  
>  \- Practical  
>  ### Colors  
>  \- Primary button color: #002AF6  
>  \- Secondary colors:  
>  \- Interaction specialty: #FFD914  
>  \- Management specialty: #42C556  
>  \- Research specialty: #8952FF  
>  \- UX Certification: #4D0001  
>  \- UX Master Certification: #BB181C  
>  \- All colors and elements on the page should meet WCAG AA accessibility  
>  standards  
>  ### Shapes &amp; Icons  
>  \- Interaction specialty: Triangle  
>  \- Management specialty: Square  
>  \- Research specialty: Circle  
>  ### Typeface  
>  \- Source Sans_
#### Prompt 3. Text plus Design Artifact
> 3a - Hand-drawn wireframe _You are a senior product designer at Nielsen Norman Group, a UX research consultancy that offers live online training on UX topics. Your task is to design a profile page in the desktop viewport for course attendees participating in online training based on the wireframe provided. The page should allow attendees to view all the courses they‚Äôve taken, access downloadable course materials for each course, check the status of summative course exams, and track their progress toward UX certification._
> _üß∑[ATTACH WIREFRAME IMAGE]_
_Photo of the handdrawn wireframe attached to Prompt 3a_
3b - Figma mockup screenshot
> _You are a senior product designer at Nielsen Norman Group, a UX research consultancy that offers live online training on UX topics. Your task is to design a profile page in the desktop viewport for course attendees participating in online training based on the mockup provided. The page should allow attendees to view all the courses they‚Äôve taken, access downloadable course materials for each course, check the status of summative course exams, and track their progress toward UX certification._
> _üß∑[ATTACH DESIGN MOCKUP]_
_Design mockup (exported directly from Figma) attached to Prompt 3b_
3c - Figma design file
> _You are a senior product designer at Nielsen Norman Group, a UX research consultancy that offers live online training on UX topics. Your task is to design a profile page in the desktop viewport for course attendees participating in online training based on the design file provided. The page should allow attendees to view all the courses they‚Äôve taken, access downloadable course materials for each course, check the status of summative course exams, and track their progress toward UX certification._
> _üß∑[LINK TO FIGMA DESIGN]_
_V0: Most AI prototyping tools enable direct connection to a Figma design frame._ _We tested linking to a Figma design with and without Auto Layout applied._
#### Prompt 4. Redesign Prompt
> _You are a senior product designer at Nielsen Norman Group, a UX research consultancy that offers live online training on UX topics. Your task is to redesign and improve the profile page for course attendees participating in online training. This page allows attendees to view all the courses they‚Äôve taken, access downloadable course materials for each course, check the status of summative course exams, and track their progress toward UX certification. Based on the current design attached, create a new design that addresses the following problems:_
>   * _Cluttered Layout & Poor Visual Hierarchy: The current interface packs too much information without clear visual organization._
>   * _Outdated Visual Style: The visual elements and color scheme appear dated and fail to project the modern, professional, trustworthy brand image._
>   * _Low User Engagement: The profile page lacks effective engagement mechanisms that make the experience delightful and encourage continued interaction._
> 

> _üß∑ [ATTACH IMAGE OF THE OLD DESIGN]_
_Old design attached to prompt 4_
## Flow-Design Prompts: Bulk Purchase
#### Prompt 1. Broad Text Prompt
> _You are a senior product designer at Nielsen Norman Group (NNG), a UX research consultancy that offers live online training on UX topics. Your company is expanding to offer an enterprise plan for organizations that want to purchase multiple seats for live training. This plan allows teams to buy 100 or more credits for live online courses and receive a volume discount._
> _A single company may have multiple teams with separate bulk orders. For example, Company A has two teams: Team 1 has purchased 200 credits, while Team 2 has placed a smaller order of 100 credits._
> _Your task:_
> _Design an intuitive, accessible web application workflow that enables companies with bulk seat purchases to:_
>   * _Log in to the business portal on our website_
>   * _View the teams for which bulk orders have been placed_
>   * _Access the order history for each team_
>   * _Request more credits (i.e., create a new bulk order)_
>   * _View the total number of available credits (both for courses and exams) per team_
>   * _Copy and share a registration link for a specific team so employees can use credits to enroll in courses_
>   * _View pending course requests from employees_
>   * _Approve or reject individual employee requests_
>   * _Track whether employees attended the courses they registered for_
> 

> _Create as many pages as necessary for an intuitive experience and follow accessibility standards and information architecture best practices._
#### Prompt 2. Redesign Text Prompt
> _You are a senior product designer at Nielsen Norman Group (NNG), a UX research consultancy that offers live online training on UX topics. Your company is expanding to offer an enterprise plan for organizations that want to purchase multiple seats for live training. This plan allows teams to buy 100 or more credits for live online courses and receive a volume discount._
> _A single company may have multiple teams with separate bulk orders. For example, Company A has two teams: Team 1 has purchased 200 credits, while Team 2 has placed a smaller order of 100 credits._
> _Your Task:_
> _Redesign and improve the current flow to create an intuitive, accessible web application that enables companies with bulk seat purchases to:_
>   * _Log in to the business portal on our website_
>   * _View the teams for which bulk orders have been placed_
>   * _Access the order history for each team_
>   * _Request more credits (i.e., create a new bulk order)_
>   * _View the total number of available credits (both for courses and exams) per team_
>   * _Copy and share a registration link for a specific team so employees can use credits to enroll in courses_
>   * _View pending course requests from employees_
>   * _Approve or reject individual employee requests_
>   * _Track whether employees attended the courses they registered for_
> 

> _Create as many pages as necessary for an intuitive experience and follow accessibility standards and information architecture best practices._
> _Address the following problems from the current flow:_
>   * _Navigational Disorientation: Users struggle to remember where they are in the interface._
>   * _Outdated Visual Design: The visual elements and color scheme appear dated and fail to project a modern, professional, trustworthy brand image._
> 

> _Current Flow:_
>   * _Dashboard Page ‚Äì Overview of all teams under a selected company. Shows each team‚Äôs pending requests, available course and exam credits, and registration link. Users can add new teams or companies._
>   * _Team Credits Page ‚Äì Connected to the Dashboard Page. Displays the team‚Äôs remaining course and exam credits, registration link, and a breakdown of credit use per order. Includes a ‚ÄúRequest More Credits‚Äù button to place a new bulk order._
>   * _Order Detail Page ‚Äì Connected to the Team Credits Page. Order summary with key details (credits remaining, start/expiry dates, credits purchased, price per course, etc.) and billing information._
>   * _Course Request Page ‚Äì Connected to the Dashboard Page. Allows users to manage employee course credit requests via four tabs:_
>   * _Pending ‚Äì New requests with request dates._
>   * _Rejected ‚Äì Denied requests with dates and who rejected them._
>   * _Approved ‚Äì Approved requests with approver, employee, course, approval/request dates, and order ID._
>   * _Course Attendance_
> 

## Evaluation Criteria
Each design was evaluated through the following criteria.
**Dimension** |  **Criterion** |  **Description**  
---|---|---  
**Goal alignment** |  **Design‚Äëobjective fit** |  The generated interface demonstrably supports the stated design objectives.  
**Prompt compliance** |  All requested features, states, constraints, and content appear as specified. No omissions or unauthorized additions.   
**Concept quality** |  **Solution diversity** |  Design iterations differ meaningfully.  
**Creative judgment** |  Generated ideas show thoughtful novelty and provide added value to the creative process.  
**Visual design** |  **Information hierarchy** |  Content priority is reflected through the proper use of visual weight. Important content and elements are visually dominant.  
**Compositional balance** |  Elements are thoughtfully arranged to create a balanced layout.  
**Consistency** |  Design execution is consistent and coherent across the interface.  
**Aesthetics** |  Visual quality meets or exceeds modern standards (appealing, clear, on-brand). The visual elements of the interface are intentional and support the page goal and band identity.  
**Interaction and usability** |  **Best‚Äëpractice compliance** |  The interface design follows established UX best practices and behaves as expected through the appropriate use of design patterns. There is no evidence of critical usability violations.  
**Accessibility** |  The design can accommodate users of diverse abilities: the content is easy to see and read, and the interface can be navigated using different input methods.  
**Responsive performance** |  Content can be rendered seamlessly across devices (mobile, tablet, desktop) without content loss or overlap.  
## Challenges and Limitations
  * **Jagged capabilities** : Some AI tools impose strict limits ‚Äî for instance, Uizard caps text input at 500 characters, so we had to shorten prompts to fit. Others only accept plain text or lack the ability to connect with Figma frames. We had to adapt our testing process around these constraints.
  * **Tool and model updates** : AI tools evolve quickly. While this evaluation wasn‚Äôt about chasing the ‚Äúlatest and greatest,‚Äù we did need to rerun tests in response to major updates (like the release of ChatGPT-5) to ensure our findings reflected current tool behavior.
  * **Free-trial limitations** : We kept the testing at the free-account level. Some tools require a paid subscription to unlock certain features.


## Lesson Learned
  * **Treat the evaluation like research.** We approached the evaluation as a research project ‚Äî drafting a plan, controlling variables, establishing evaluation criteria, and standardizing the process for testing and analysis. Applying research best practices kept the work structured and allowed us to generate insights that were both objective and useful.
  * **Pilot test and iterate on prompts.** We first tested prompts with general-purpose AI chatbots before moving to specialized tools with stricter credit limits. This gave us space to refine and optimize prompts without burning through credits too quickly.
  * **Maintain strong documentation.** A project of this scale requires consistency and collaboration. We created a shared prompt document as our single source of truth and used a FigJam board to track and display results across tools. This setup kept everyone aligned and informed throughout the evaluation process.


## Related Courses
  * #### [AI for Design Workflows Leverage AI to enhance creativity, efficiency, and impact in everyday design work  Interaction ](https://www.nngroup.com/courses/ai-for-design/?lm=testing-ai-methodology&pt=article)
  * #### [Accelerating Research with AI The AI-assisted user research workflow  Research ](https://www.nngroup.com/courses/research-with-ai/?lm=testing-ai-methodology&pt=article)
  * #### [Designing AI Experiences Design innovative, trusted, and useful AI products and features  Interaction ](https://www.nngroup.com/courses/designing-ai-experiences/?lm=testing-ai-methodology&pt=article)


Artificial Intelligence,Design Process,Web/UI Design
## Related Topics
  * Artificial Intelligence [Artificial Intelligence](https://www.nngroup.com/topic/ai/)
  * [Design Process](https://www.nngroup.com/topic/ux-design-process/)


## Learn More:
  * [ Humanizing AI Does Not Help Your Users  Caleb Sponheim  ¬∑ 4 min ](https://www.nngroup.com/videos/humanizing-ai-does-not-help/?lm=testing-ai-methodology&pt=article)
  * [ AI Strategy: 3 Key Questions  Caleb Sponheim  ¬∑ 5 min ](https://www.nngroup.com/videos/ai-strategy-key-questions/?lm=testing-ai-methodology&pt=article)
  * [ AI-Assisted Prototyping: Promise and Pitfalls  Megan Brown  ¬∑ 5 min ](https://www.nngroup.com/videos/ai-assisted-prototyping/?lm=testing-ai-methodology&pt=article)


## Related Articles:
  * [ AI Design Tools Are Marginally Better: Status Update Megan Brown, Caleb Sponheim, and Taylor Dykes  ¬∑ 7 min ](https://www.nngroup.com/articles/ai-design-tools-update-2/?lm=testing-ai-methodology&pt=article)
  * [ Redefine Your Design Skills to Prepare for AI Pablo Fern√°ndez Vallejo  ¬∑ 6 min ](https://www.nngroup.com/articles/prepare-for-ai/?lm=testing-ai-methodology&pt=article)
  * [ Google AI Mode: Powerful Search, Poor Usability Josh Brown and Kate Moran  ¬∑ 12 min ](https://www.nngroup.com/articles/google-ai-mode/?lm=testing-ai-methodology&pt=article)
  * [ 7 Deadly AI Sins for UX Professionals Tanner Kohler  ¬∑ 8 min ](https://www.nngroup.com/articles/7-ai-sins/?lm=testing-ai-methodology&pt=article)
  * [ Prioritize Smarts over Sentience to Increase Trust with AI Evan Sunwall  ¬∑ 6 min ](https://www.nngroup.com/articles/smarts-emotion-trust-ai/?lm=testing-ai-methodology&pt=article)
  * [ How AI Succeeds (and Fails) to Help People Find Information Kate Moran  ¬∑ 7 min ](https://www.nngroup.com/articles/ai-information-seeking-keyword-foraging/?lm=testing-ai-methodology&pt=article)


## Subscribe to Our Newsletter
Get weekly UX articles, videos, and upcoming training events straight to your inbox.
Email
## Follow Us
  * [ LinkedIn ](https://www.linkedin.com/company/nielsen-norman-group)
  * [ Instagram ](https://www.instagram.com/nngux)
  * [ Youtube ](https://www.youtube.com/channel/UC2oCugzU6W8-h95W7eBTUEg)
  * [ Podcast ](https://podcasters.spotify.com/pod/show/nngroup )
  * [ X (Twitter) ](https://x.com/nngroup)
  * [ Facebook ](https://www.facebook.com/nngux)


  * Certification
    * [What is UX Certification?](https://www.nngroup.com/ux-certification/)
    * [Specialties](https://www.nngroup.com/ux-certification/specialties/)
    * [Exams](https://www.nngroup.com/ux-certification/exams/)
    * [UX Certified People](https://www.nngroup.com/ux-certification/people/)
  * UX Training
    * [All Live Courses](https://www.nngroup.com/courses/)
    * [Live Online Training Events](https://www.nngroup.com/training/live-courses/)
    * [Private Team Training](https://www.nngroup.com/team-training/)
    * [Course Calendar](https://www.nngroup.com/course-calendar/)
  * Consulting
    * [Expert Review](https://www.nngroup.com/consulting/expert-review/)
    * [User Testing](https://www.nngroup.com/consulting/user-testing/)
    * [Customized Research](https://www.nngroup.com/consulting/user-research/)
    * [Applied Workshops](https://www.nngroup.com/consulting/applied-workshops/)
    * [Keynote Speaking](https://www.nngroup.com/consulting/keynote-speaking/)
  * Free Guidance
    * [Articles & Videos](https://www.nngroup.com/articles/)
    * [The NN/g UX Podcast](https://podcasters.spotify.com/pod/show/nngroup)
  * About
    * [Why NN/g](https://www.nngroup.com/about/why-nng/)
    * [About Us](https://www.nngroup.com/about/)
    * [People](https://www.nngroup.com/people/)
    * [Clients](https://www.nngroup.com/about/about-client-list/)
    * [Contact](https://www.nngroup.com/about/contact/)
    * [Privacy Policy](https://www.nngroup.com/privacy-policy/)


[Copyright](https://www.nngroup.com/copyright-and-reprint-info/) (C) 1998-2025 Nielsen Norman Group, All Rights Reserved. 
  * Cookie Preferences
  * [Cookie Declaration](https://www.nngroup.com/cookie-declaration/)
  * [Privacy Policy](https://www.nngroup.com/privacy-policy/)


  
Top
