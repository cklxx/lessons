# Good from Afar, But Far from Good: AI Prototyping in Real Design Contexts - NN/G

- URL: https://www.nngroup.com/articles/ai-prototyping/
- Retrieved: 2025-12-18T10:40:23.520559+00:00

Skip to content
**NEW RESEARCH COURSES: UX Research Methods, Heatmaps | [Learn More](https://www.nngroup.com/news/item/new-courses/)**
Open main navigation [ Nielsen Norman Group ](https://www.nngroup.com/)
  * Training & UX Certification 
    * [All Live Courses](https://www.nngroup.com/courses/)
    * [Live Online Training Events](https://www.nngroup.com/training/live-courses/)
    * [Private Team Training](https://www.nngroup.com/team-training/)
    * [Bulk Discounts](https://www.nngroup.com/training/bulk-discounts/)
    * [UX Certification](https://www.nngroup.com/ux-certification/)
  * [Articles & Videos](https://www.nngroup.com/articles/)
  * [Consulting](https://www.nngroup.com/consulting/)
  * [Reports & Books](https://www.nngroup.com/reports/)
  * About NN/g 
    * [Overview](https://www.nngroup.com/about/)
    * [People](https://www.nngroup.com/people/)
    * [Clients](https://www.nngroup.com/about/about-client-list/)
    * [News](https://www.nngroup.com/news/)
    * [Contact Us](https://www.nngroup.com/about/contact/)


(https://www.nngroup.com/cart/)
Profile 
Search
Search
Reset Search
8
# Good from Afar, But Far from Good: AI Prototyping in Real Design Contexts
Huei-Hsin Wang, Megan Brown
[ Huei-Hsin Wang](https://www.nngroup.com/articles/author/huei-hsin-wang/) and [ Megan Brown](https://www.nngroup.com/articles/author/megan-brown/)
October 24, 2025 2025-10-24
[ Share ]
  * [ Email article ](mailto:?subject=NN/g Article: Good from Afar, But Far from Good: AI Prototyping in Real Design Contexts&body=https://www.nngroup.com/articles/ai-prototyping/)
  * [ Share on LinkedIn ](http://www.linkedin.com/shareArticle?mini=true&url=http://www.nngroup.com/articles/ai-prototyping/&title=Good from Afar, But Far from Good: AI Prototyping in Real Design Contexts&source=Nielsen%20Norman%20Group)
  * [ Share on Twitter ](https://twitter.com/intent/tweet?url=http://www.nngroup.com/articles/ai-prototyping/&text=Good from Afar, But Far from Good: AI Prototyping in Real Design Contexts&via=nngroup)


Summary:  AI prototyping tools follow general directions but lack the judgment and nuance of an experienced designer. 
Over the past few months, the UX design field has been flooded with AI-powered prototyping tools that generate interfaces instantly from natural-language prompts. Despite the massive marketing hype, our evaluation with real design scenarios revealed that **these tools can follow instructions** **to achieve a general goal** , but they **lack the sophistication** to weigh design tradeoffs and produce thoughtful, high-quality designs without extensive guidance from humans.
##  In This Article: 
(#)
  * About the Evaluation
  * Specific Prompts Lead to Better Outputs
  * AI Reflects Patterns from Its Training Data
  * Using AI Prototyping Tools in Real Workflows
  * Conclusion


## About the Evaluation
To understand whether AI prototyping tools can **craft thoughtful, context-aware designs** comparable to those created by human designers, we conducted an evaluation using an actual project — redesigning the profile page for individuals registered for [NN/G’s live online training](https://www.nngroup.com/training/live-courses/). This evaluation focused on three categories of AI tools:
  * **AI-assisted design** tools that focus on generating static wireframes or design mockups
  * **AI-assisted**(vibe) **coding** tools that generate interactive code-based prototypes
  * **General-purpose AI chatbots** capable of generating prototypes


To mirror different stages of the real-world design process, we wrote prompts providing various levels of context:
  * **Prompt 1 – broad text prompt:** General context and page goals, with minimal detail
  * **Prompt 2 – detailed text prompt:** General context, page goals, and explicit outlining of components, design language, and interaction states
  * **Prompt 3 – text plus design artifacts:** Supporting visuals at varying fidelity levels, including a photo of a hand sketch, the image of the design mockup, and a link to a Figma design frame


We conducted [heuristic evaluations](https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/) to assess the AI-generated designs and compared them with designs produced by designers at NN/G.
For full details on this study, check out our sidebar, including [the study methodology and the prompts we used](https://www.nngroup.com/articles/testing-ai-methodology), as well as the [associated FigJam board containing the AI-generated designs](https://www.figma.com/board/gLi4O1jr7Lo1AWQPZAdKXg/NN-G-AI-Prototyping-Evaluation?node-id=0-1&t=CbbP0fzNSeLIdup5-1).
## Specific Prompts Lead to Better Outputs
The quality of AI-generated outputs strongly depends on the specificity of the prompt. Our evaluation showed that **longer prompts with clear, detailed design requirements consistently yield better results** — particularly with AI tools that generate code-based prototypes, which can produce outputs that resemble the work of a human designer. (This finding reinforces what we already know about AI prompts: [the more specific they are, the better the output.](https://www.nngroup.com/articles/ai-prompt-structure/))
For example, when we input a detailed text prompt (Prompt 2), AI tools generated tailored outputs that were similar to human-produced designs (even though we didn’t upload any visual references in the prompt). In particular, the AI design outputs:
  * Included key design elements such as progress bars and course listings
  * Used NN/g’s brand colors and specialty shape
  * Included the UX-certification progress in the left rail (even though this was not a request in the prompt)

_Designs generated from a detailed text prompt (Prompt 2) closely matched the human-designed version. (__Note: Besides the two examples shown here, other tools also generated high-quality results._[_See the full set of outputs on the FigJam board_](https://www.figma.com/board/gLi4O1jr7Lo1AWQPZAdKXg/NN-G-AI-Prototyping-Evaluation?node-id=0-1&t=f4QxQFSnnAZ6Xky6-1) _.)_
In contrast, when given a high-level prompt (Prompt 1), the AI-generated outputs varied widely across the board. That’s because **general prompts leave room for AI tools to make assumptions about the design requirements and fill in the gaps.**
_Designs generated by AI in response to the same broad text prompt (Prompt 1) varied widely across tools. (_[_See the full set of outputs on the FigJam board_](https://www.figma.com/board/gLi4O1jr7Lo1AWQPZAdKXg/NN-G-AI-Prototyping-Evaluation?node-id=0-1&t=f4QxQFSnnAZ6Xky6-1) _.)_
Depending on your context and stage in the design process, this isn’t always a bad thing. Outputs based on prompts that leave room for interpretation can be valuable in early-stage exploration. When you need to explore different layout approaches or break through creative blocks, vague prompts might surface unexpected directions you might not have considered.
However, if you already have a clear vision for the design, vague prompts may yield less-desirable outputs. Without specific guidance, AI’s assumptions may miss the mark and produce outputs that don’t align with your design requirements or user needs.
### An Image (or a Figma Link) Is Worth a Thousand Words
Most AI prototyping tools can process uploaded images, such as hand-drawn wireframes, design mockups, or moodboards; some can also accept a link to a Figma frame to interpret its design structure. In our testing, AI prompts that included attached design artifacts **resulted in more streamlined outputs**. The higher the fidelity of the attached file, the more accurately the design was translated.
The saying _An image is worth a thousand words_ proves remarkably accurate here. When AI tools can examine existing patterns, spatial relationships, hierarchy, and aesthetic treatments through the artifacts you provide, they can produce more consistent and accurate designs that match your vision. The irony is that by providing these references, **you’ve already completed much of the design work yourself.**
_Prompts including a Figma frame (Prompt 3c)_****_produced the most accurate translation of the original design. (__Note: Besides the two examples shown here, other tools also generated accurate results._[_See the full set of outputs on the FigJam board_](https://www.figma.com/board/gLi4O1jr7Lo1AWQPZAdKXg/NN-G-AI-Prototyping-Evaluation?node-id=0-1&t=f4QxQFSnnAZ6Xky6-1) _.)_
### Close, But Missing the Nuance
Even when AI tools came close to the target with a detailed text prompt like Prompt 2, **they still lacked the human nuance and attention to detail.**
While the general layout and key components aligned with the intended design, a closer look revealed problems in the details:
  * A lack of visual hierarchy or grouping among related elements
  * Overused colors creating visual tension
  * Poor color contrast
  * Inconsistent margin spacing


These subtleties may seem minor, but they make the difference between a design that feels thoughtful and one that feels “almost there.”
Take Bolt’s output for Prompt 2 as an example: the password for course materials and the link to access them were separated by a large gap, even when the user’s exam was still available. Grouping those two elements would improve scannability and help users recognize more easily that the password is specific to the linked materials.
_The AI output in response to a detailed text prompt (Prompt 2) missed subtle but important details related to spacing, grouping, and hierarchy._
**This is what sets human designers apart from AI tools:** the ability to balance nuance, create sophisticated solutions, and back every decision with a clear rationale. AI prototyping tools produce high-fidelity designs fast, but they lack the intuition to tailor them to nuanced contexts, even when provided with detailed instructions. Their pattern-matching tendency drives them toward the most common solutions, not the most contextually meaningful ones. As a result, the output often feels **good from afar, but far from good.**
## AI Reflects Patterns from Its Training Data
To integrate AI tools effectively in design workflows, designers must understand the technology's limitations — **AI tools are only as good as the data they were trained on**.
Most AI prototyping tools are [trained on vast datasets](https://www.nngroup.com/articles/ai-model-training/) comprising millions of existing websites, open-source libraries, and UI patterns. The AI learns to identify and reflect the most common patterns within this data. As a result, the **outputs are biased toward mainstream design conventions**.
That bias could potentially be good for the user experience — we know that it’s easier for people to use interfaces when they’re [consistent with external standards.](https://www.nngroup.com/articles/consistency-and-standards/) But in our evaluation, the AI prototyping tools often took this too far. They tended to produce unpolished, indistinctive visual styles.
### Generic Visual Style
Without detailed specifications on visual design, AI prototyping tools tend to output designs that share **a similar, generic look** using sans-serif typeface and minimalistic styling. This homogeneity is largely because AI systems favor common patterns from their training data and often default to component libraries like Shadcn and front-end frameworks like Tailwind CSS to generate their designs.
Because they lack distinctive visual language, many **AI-generated screens appear flat and interchangeable.** Despite the interactivity and presence of colors, AI-generated prototypes often resemble unpolished wireframes,
**❌** _When visual styles aren’t_ _specified in the prompt, AI-generated designs default to neutral, minimalistic visual aesthetics with bright color accents._ _While the clean, subtle style is a safe default, it lacks visual identity and emotion._
### Wrong Design Pattern
When designing for a nuanced context, following design patterns rigidly can produce designs that technically work but feel off. This issue is tied to prompt specificity, as well as the models’ ability to interpret language nuance and make the right inference for the context.
For example, our prompts used the phrase “ _profile page_.” Depending on the context, that phrase can point to different patterns. In our case, a profile page was meant to be a personal page for a course attendee, not a public-facing profile. But when we used a high-level prompt (prompt 1) without specifying which components to include, several AI prototyping tools interpreted “profile” as a social-media profile and created profile widgets that resembled the ones used for social media (like a LinkedIn profile banner).
**❌** _When given a high-level goal, the tool applied a pattern that emphasized user information (e.g., email, contact, role). This design pattern, while common on social media platforms like LinkedIn, is less effective in our design context as unnecessary visual attention is placed over information that is not essential for the main task._
While this isn’t a severe usability violation, it still makes the page less usable by focusing on secondary information at the expense of the primary one, which is pushed lower on the page.
Unfortunately, UX language is often ambiguous: one phrase may refer to many different things, and the same pattern can have many names. There isn’t always a single, universal way of describing the intended design. When working with AI, **designers need to disambiguate the language of their prompts as much as possible** , so that they can precisely communicate the exact situation they need to design for.
The inappropriate use of a design pattern is most prevalent in tools trained on a small number of components (e.g., Figma’s First Draft feature) or that focus on creating specific page types (e.g., Relume focuses on creating marketing websites). When the design scenario exceeds the training data or the scoped use case, the result is **designs that are force-fit into the prescribed template.**
## Using AI Prototyping Tools in Real Workflows
### When to Use AI Prototyping
AI’s limited grasp of design nuances and inconsistent output make it **best suited for ideation, concept exploration, and early-phase prototype testing,** rather than later stages. While you likely won’t take an AI-generated prototype straight to production, these tools can help you break through creative blocks and explore new directions quickly.
#### Early Ideation and Creative Exploration
Use AI to quickly generate concepts for layouts and potential components. Stay at low or mid fidelity to explore broadly without overinvesting in detail too soon. The goal here isn’t pixel-perfect results, but quick iterations to spark ideas and explore directions.
#### Proof of Concept Demonstrations
When you need to quickly demonstrate an idea to stakeholders, especially for unconventional or complex design concepts, AI tools can generate compelling and realistic outputs in minutes. This speed helps you get stakeholder buy-in early and secure the time and resources for proper planning. These proofs of concept should have just enough fidelity to facilitate meaningful conversations about the direction and feasibility of your ideas.
#### Rapid Usability-Testing Prototypes
Turn static Figma layouts into functional prototypes with minimal setup. Use your design as a reference, prompt for specific interactions and states, and get something testable in front of users quickly. The AI accelerates the feedback loop and helps teams iterate more effectively.
### AI Prototypes Are Still Just Prototypes
Even though AI outputs can look final on the surface, they often lack the underlying structure, logic, and usability considerations needed for real product development. They're effective for short-term testing and stakeholder communication, but still require validation, iteration, and hands-on refinement before anything ships.
Showing polished, high-fidelity AI prototypes that aren’t close to finalized without proper framing may sabotage your stakeholder communication. (For example, it may cause a debate about button color when the visual hierarchy isn’t even close to being done.)
### Strong Design Knowledge Is Necessary
Here’s the irony: **while AI promises to**[**close skill gaps**](https://www.nngroup.com/articles/return-ux-generalist/)**, it works best in the hands of people who understand the craft.** It takes a strong foundation of design and technical knowledge to produce meaningful outcomes.
Designers need to understand layout, typography, component naming, and user flows to know the right vocabulary to use when directing AI. Often, to get a precise outcome from AI prototyping tools, one will need to spell out design specs in detail or attach visual references, which means **much of the design work has already happened before AI enters the picture**.
This reality highlights a paradox: **AI lowers barriers to creation,** yet it also **magnifies the gap between okay results and exceptional ones.**[A sharp eye and a strong sense for design](https://www.nngroup.com/articles/taste-vs-technical-skills-ai/) — the ability to refine purposefully and choose elements that make a design functional for its audience — distinguishes truly great work from superficially polished but less nuanced designs.
## Conclusion
We’ve long advocated working with AI tools [the way you’d work with an intern](https://www.nngroup.com/articles/ai-intern/). AI prototyping tools can draft layouts, assemble components, and echo familiar patterns, but it still takes human judgment to balance tradeoffs and create meaning. The rise of AI prototyping tools is a reminder of what design truly involves: not just arranging pixels or chasing fidelity but interpreting context, establishing priorities, and creating nuance. **The real work of design remains in the judgment, empathy, and intent that only human designers can provide.**
## Related Courses
  * #### [AI for Design Workflows Leverage AI to enhance creativity, efficiency, and impact in everyday design work  Interaction ](https://www.nngroup.com/courses/ai-for-design/?lm=ai-prototyping&pt=article)
  * #### [Accelerating Research with AI The AI-assisted user research workflow  Research ](https://www.nngroup.com/courses/research-with-ai/?lm=ai-prototyping&pt=article)
  * #### [Designing AI Experiences Design innovative, trusted, and useful AI products and features  Interaction ](https://www.nngroup.com/courses/designing-ai-experiences/?lm=ai-prototyping&pt=article)


Artificial Intelligence,Design Process,Interaction Design,wireframes,Prototyping,interfaces
## Related Topics
  * Artificial Intelligence [Artificial Intelligence](https://www.nngroup.com/topic/ai/)
  * [Design Process](https://www.nngroup.com/topic/ux-design-process/)
  * [Interaction Design](https://www.nngroup.com/topic/interaction-design/)
  * [Prototyping](https://www.nngroup.com/topic/prototyping/)


## Learn More:
(https://www.youtube.com/watch?v=XavthHrTjIY "AI-Assisted Prototyping: Promise and Pitfalls on YouTube \(new window\)")
Enable cookies  to watch NN/g videos 
AI-Assisted Prototyping: Promise and Pitfalls 
Megan Brown · 5 min
  * [ Humanizing AI Does Not Help Your Users  Caleb Sponheim  · 4 min ](https://www.nngroup.com/videos/humanizing-ai-does-not-help/?lm=ai-prototyping&pt=article)
  * [ AI Strategy: 3 Key Questions  Caleb Sponheim  · 5 min ](https://www.nngroup.com/videos/ai-strategy-key-questions/?lm=ai-prototyping&pt=article)
  * [ CARE: Structure for Crafting AI Prompts  Kate Moran  · 4 min ](https://www.nngroup.com/videos/care-for-ai-prompts/?lm=ai-prototyping&pt=article)


## Related Articles:
  * [ AI Design Tools Are Marginally Better: Status Update Megan Brown, Caleb Sponheim, and Taylor Dykes  · 7 min ](https://www.nngroup.com/articles/ai-design-tools-update-2/?lm=ai-prototyping&pt=article)
  * [ A Research Agenda for Generative AI in UX Raluca Budiu  · 8 min ](https://www.nngroup.com/articles/genai-ux-research-agenda/?lm=ai-prototyping&pt=article)
  * [ Redefine Your Design Skills to Prepare for AI Pablo Fernández Vallejo  · 6 min ](https://www.nngroup.com/articles/prepare-for-ai/?lm=ai-prototyping&pt=article)
  * [ AI Hallucinations: What Designers Need to Know Page Laubheimer  · 13 min ](https://www.nngroup.com/articles/ai-hallucinations/?lm=ai-prototyping&pt=article)
  * [ How AI Works and How Users Think About It: Study Guide Tanner Kohler  · 4 min ](https://www.nngroup.com/articles/ai-functionality-study-guide/?lm=ai-prototyping&pt=article)
  * [ Designing AI Products and Features: Study Guide Tanner Kohler  · 4 min ](https://www.nngroup.com/articles/designing-ai-study-guide/?lm=ai-prototyping&pt=article)


## Subscribe to Our Newsletter
Get weekly UX articles, videos, and upcoming training events straight to your inbox.
Email
## Follow Us
  * [ LinkedIn ](https://www.linkedin.com/company/nielsen-norman-group)
  * [ Instagram ](https://www.instagram.com/nngux)
  * [ Youtube ](https://www.youtube.com/channel/UC2oCugzU6W8-h95W7eBTUEg)
  * [ Podcast ](https://podcasters.spotify.com/pod/show/nngroup )
  * [ X (Twitter) ](https://x.com/nngroup)
  * [ Facebook ](https://www.facebook.com/nngux)


  * Certification
    * [What is UX Certification?](https://www.nngroup.com/ux-certification/)
    * [Specialties](https://www.nngroup.com/ux-certification/specialties/)
    * [Exams](https://www.nngroup.com/ux-certification/exams/)
    * [UX Certified People](https://www.nngroup.com/ux-certification/people/)
  * UX Training
    * [All Live Courses](https://www.nngroup.com/courses/)
    * [Live Online Training Events](https://www.nngroup.com/training/live-courses/)
    * [Private Team Training](https://www.nngroup.com/team-training/)
    * [Course Calendar](https://www.nngroup.com/course-calendar/)
  * Consulting
    * [Expert Review](https://www.nngroup.com/consulting/expert-review/)
    * [User Testing](https://www.nngroup.com/consulting/user-testing/)
    * [Customized Research](https://www.nngroup.com/consulting/user-research/)
    * [Applied Workshops](https://www.nngroup.com/consulting/applied-workshops/)
    * [Keynote Speaking](https://www.nngroup.com/consulting/keynote-speaking/)
  * Free Guidance
    * [Articles & Videos](https://www.nngroup.com/articles/)
    * [The NN/g UX Podcast](https://podcasters.spotify.com/pod/show/nngroup)
  * About
    * [Why NN/g](https://www.nngroup.com/about/why-nng/)
    * [About Us](https://www.nngroup.com/about/)
    * [People](https://www.nngroup.com/people/)
    * [Clients](https://www.nngroup.com/about/about-client-list/)
    * [Contact](https://www.nngroup.com/about/contact/)
    * [Privacy Policy](https://www.nngroup.com/privacy-policy/)


[Copyright](https://www.nngroup.com/copyright-and-reprint-info/) (C) 1998-2025 Nielsen Norman Group, All Rights Reserved. 
  * Cookie Preferences
  * [Cookie Declaration](https://www.nngroup.com/cookie-declaration/)
  * [Privacy Policy](https://www.nngroup.com/privacy-policy/)


  
Top
