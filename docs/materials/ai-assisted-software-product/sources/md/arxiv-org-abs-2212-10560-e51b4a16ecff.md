# [2212.10560] Self-Instruct: Aligning Language Models with Self-Generated Instructions

- URL: https://arxiv.org/abs/2212.10560
- PDF: https://arxiv.org/pdf/2212.10560.pdf
- Retrieved: 2025-12-17T16:10:21.019251+00:00

## Abstract page (HTML ‚Üí Markdown)

[](#)
## Happy Open Access Week from arXiv!
YOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.
[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)
[Skip to main content](#content)
[](https://www.cornell.edu/)
We gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)
[](/IgnoreMe)
[](/) > [cs](/list/cs/recent) > arXiv:2212.10560 
[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)
All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text
Search
[](https://arxiv.org/)
[ ](https://www.cornell.edu/)
open search
GO
open navigation menu
## quick links
  * [Login](https://arxiv.org/login)
  * [Help Pages](https://info.arxiv.org/help)
  * [About](https://info.arxiv.org/about)


# Computer Science > Computation and Language
**arXiv:2212.10560** (cs) 
[Submitted on 20 Dec 2022 ([v1](https://arxiv.org/abs/2212.10560v1)), last revised 25 May 2023 (this version, v2)]
# Title:Self-Instruct: Aligning Language Models with Self-Generated Instructions
Authors:[Yizhong Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y), [Yeganeh Kordi](https://arxiv.org/search/cs?searchtype=author&query=Kordi,+Y), [Swaroop Mishra](https://arxiv.org/search/cs?searchtype=author&query=Mishra,+S), [Alisa Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+A), [Noah A. Smith](https://arxiv.org/search/cs?searchtype=author&query=Smith,+N+A), [Daniel Khashabi](https://arxiv.org/search/cs?searchtype=author&query=Khashabi,+D), [Hannaneh Hajishirzi](https://arxiv.org/search/cs?searchtype=author&query=Hajishirzi,+H)
View a PDF of the paper titled Self-Instruct: Aligning Language Models with Self-Generated Instructions, by Yizhong Wang and 6 other authors
[View PDF](/pdf/2212.10560)
> Abstract:Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. Our code and data are available at [this https URL](https://github.com/yizhongw/self-instruct). 
Comments: | ACL 2023 camera ready, 23 pages, 9 figures, 11 tables  
---|---  
Subjects: |  Computation and Language (cs.CL); Artificial Intelligence (cs.AI)  
Cite as: | [arXiv:2212.10560](https://arxiv.org/abs/2212.10560) [cs.CL]  
  | (or  [arXiv:2212.10560v2](https://arxiv.org/abs/2212.10560v2) [cs.CL] for this version)   
  |  <https://doi.org/10.48550/arXiv.2212.10560> Focus to learn more arXiv-issued DOI via DataCite  
## Submission history
From: Yizhong Wang [[view email](/show-email/303371ba/2212.10560)]   
**[[v1]](/abs/2212.10560v1)** Tue, 20 Dec 2022 18:59:19 UTC (4,072 KB)  
**[v2]** Thu, 25 May 2023 23:50:07 UTC (7,954 KB)  

Full-text links:
## Access Paper:
View a PDF of the paper titled Self-Instruct: Aligning Language Models with Self-Generated Instructions, by Yizhong Wang and 6 other authors
  * [View PDF](/pdf/2212.10560)
  * [TeX Source ](/src/2212.10560)


[ view license ](http://creativecommons.org/licenses/by/4.0/ "Rights to this article")
Current browse context: 
cs.CL
[< prev](/prevnext?id=2212.10560&function=prev&context=cs.CL "previous in cs.CL \(accesskey p\)")   |   [next >](/prevnext?id=2212.10560&function=next&context=cs.CL "next in cs.CL \(accesskey n\)")   

[new](/list/cs.CL/new) |  [recent](/list/cs.CL/recent) | [2022-12](/list/cs.CL/2022-12)
Change to browse by: 
[cs](/abs/2212.10560?context=cs)  
[cs.AI](/abs/2212.10560?context=cs.AI)  

### References & Citations
  * [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2212.10560)
  * [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2212.10560)
  * [Semantic Scholar](https://api.semanticscholar.org/arXiv:2212.10560)


export BibTeX citation Loading...
## BibTeX formatted citation
√ó
loading...
Data provided by: 
### Bookmark
[ ](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2212.10560&description=Self-Instruct: Aligning Language Models with Self-Generated Instructions "Bookmark on BibSonomy") [ ](https://reddit.com/submit?url=https://arxiv.org/abs/2212.10560&title=Self-Instruct: Aligning Language Models with Self-Generated Instructions "Bookmark on Reddit")
Bibliographic Tools
# Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_
Connected Papers Toggle
Connected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_
Litmaps Toggle
Litmaps _([What is Litmaps?](https://www.litmaps.co/))_
scite.ai Toggle
scite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_
Code, Data, Media
# Code, Data and Media Associated with this Article
alphaXiv Toggle
alphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_
Links to Code Toggle
CatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com))_
DagsHub Toggle
DagsHub _([What is DagsHub?](https://dagshub.com/))_
GotitPub Toggle
Gotit.pub _([What is GotitPub?](http://gotit.pub/faq))_
Huggingface Toggle
Hugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_
Links to Code Toggle
Papers with Code _([What is Papers with Code?](https://paperswithcode.com/))_
ScienceCast Toggle
ScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_
Demos
# Demos
Replicate Toggle
Replicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_
Spaces Toggle
Hugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_
Spaces Toggle
TXYZ.AI _([What is TXYZ.AI?](https://txyz.ai))_
Related Papers
# Recommenders and Search Tools
Link to Influence Flower
Influence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_
Core recommender toggle
CORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_
  * Author
  * Venue
  * Institution
  * Topic


About arXivLabs 
# arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).
[Which authors of this paper are endorsers?](/auth/show-endorsers/2212.10560) | [Disable MathJax](javascript:setMathjaxCookie\(\)) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) 
  * [About](https://info.arxiv.org/about)
  * [Help](https://info.arxiv.org/help)


  * contact arXivClick here to contact arXiv [ Contact](https://info.arxiv.org/help/contact.html)
  * subscribe to arXiv mailingsClick here to subscribe [ Subscribe](https://info.arxiv.org/help/subscribe)


  * [Copyright](https://info.arxiv.org/help/license/index.html)
  * [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)


  * [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)
  * [arXiv Operational Status ](https://status.arxiv.org)

## Full text (PDF ‚Üí text)

```text
                                                                                                                                                          ACL 2023


                                                                     SELF-INSTRUCT: Aligning Language Models
                                                                          with Self-Generated Instructions

                                                          Yizhong Wang‚ô£ Yeganeh Kordi‚ô¢ Swaroop Mishra‚ô° Alisa Liu‚ô£
                                                            Noah A. Smith‚ô£+ Daniel Khashabi‚ô†            Hannaneh Hajishirzi‚ô£+
                                                        ‚ô£
                                                          University of Washington ‚ô¢ Tehran Polytechnic ‚ô° Arizona State University
                                                                      ‚ô†
                                                                        Johns Hopkins University + Allen Institute for AI
                                                                               yizhongw@cs.washington.edu


                                                                    Abstract                                  Instruction: Given an address and city, come up
                                                                                                              with the zip code.
                                                                                                              Input:
                                                 Large ‚Äúinstruction-tuned‚Äù language models                    Address: 123 Main Street, City: San Francisco
                                                 (i.e., finetuned to respond to instructions) have            Output: 94105
arXiv:2212.10560v2 [cs.CL] 25 May 2023




                                                 demonstrated a remarkable ability to gener-                  Instruction: I am looking for a job and I need to
                                                 alize zero-shot to new tasks. Nevertheless,                  fill out an application form. Can you please help
                                                                                                              me complete it?
                                                 they depend heavily on human-written instruc-                Input:
                                                 tion data that is often limited in quantity, di-             Application Form:
                                                                                                              Name:_________ Age:__________ Sex:________
                                                 versity, and creativity, therefore hindering the             Phone Number:______ Email Address:________
                                                 generality of the tuned model. We introduce                  Education:___________________ ...
                                                 SELF-INSTRUCT, a framework for improving                     Output:
                                                                                                              Name: John Doe Age: 25 Sex: Male
                                                 the instruction-following capabilities of pre-               Phone Number: ...
                                                 trained language models by bootstrapping off
                                                                                                              Instruction: How to write a code for converting
                                                 their own generations. Our pipeline generates                degrees fahrenheit to celsius.
                                                 instructions, input, and output samples from                 Input: Null
                                                                                                              Output:
                                                 a language model, then filters invalid or sim-               def convert_fahrenheit_to_celsius(fahr):
                                                 ilar ones before using them to finetune the                      celsius = (fahr - 32) * 5 / 9
                                                                                                                  return celsius
                                                 original model. Applying our method to the
                                                 vanilla GPT3, we demonstrate a 33% abso-                     Instruction: Write a letter from the perspective
                                                 lute improvement over the original model on                  of a cat.
                                                                                                              Input: Null
                                                 SUPER-NATURALINSTRUCTIONS, on par with                       Output:
                                                 the performance of InstructGPT001 ,1 which                   Dear [Owner], I am writing to you today because I
                                                                                                              have a problem. You see, I‚Äôve been living with you
                                                 was trained with private user data and human                 for the past [Number of Years] and I love it here.
                                                 annotations. For further evaluation, we curate a             The food is great, the bed is comfy, and there are
                                                                                                              plenty of toys to play with. But lately, I‚Äôve
                                                 set of expert-written instructions for novel tasks,          noticed that you‚Äôre not as affectionate towards
                                                 and show through human evaluation that tuning                me as you used to be. In fact, sometimes
                                                                                                              when I try to cuddle up next to you on the
                                                 GPT3 with SELF-INSTRUCT outperforms using                    couch, you push me away ...
                                                 existing public instruction datasets by a large
                                                 margin, leaving only a 5% absolute gap behind               Figure 1: Selected tasks from the generated instruction
                                                 InstructGPT001 . SELF-INSTRUCT provides an                  data using vanilla GPT3. Some texts are reformatted
                                                 almost annotation-free method for aligning pre-             for presentation. See Table 10 for more examples.
                                                 trained language models with instructions, and
                                                 we release our large synthetic dataset to facili-
                                                 tate future studies on instruction tuning.2
                                                                                                             can follow natural language instructions (Mishra
                                         1       Introduction                                                et al., 2022; Wei et al., 2022; Sanh et al., 2022;
                                                                                                             Wang et al., 2022; Ouyang et al., 2022; Chung et al.,
                                         The recent NLP literature has witnessed a tremen-                   2022, i.a.). These developments are powered by two
                                         dous amount of activity in building models that                     key components: large pretrained language mod-
                                             1
                                               Unless otherwise specified, our comparisons are with the      els (LM) and human-written instruction data (e.g.,
                                         text-davinci-001 engine. We focus on this engine since it           PROMPTSOURCE (Bach et al., 2022) and SUPER-
                                         is the closest to our experimental setup: supervised finetuning
                                         with human demonstrations. The newer engines are more               NATURALINSTRUCTIONS (Wang et al., 2022, SU-
                                         powerful, though they use more data (e.g., code completion or       PER NI for short)). However, collecting such in-
                                         latest user queries) or algorithms (e.g., PPO) that are difficult   struction data is costly and often suffers limited
                                         to compare with.
                                             2
                                               Code and data are available at https://github.com/            diversity given that most human generations tend
                                         yizhongw/self-instruct                                              to be popular NLP tasks, falling short of covering a
                                                                                                                             Step 2: Classification
     175 seed tasks with       Task Pool                              Step 1: Instruction Generation
                                                                                                                              Task Identification
      1 instruction and
     1 instance per task
                                                  ü§ñ
                                                  LM
                                                                     Task                                            ü§ñ
                                                                                                                     LM
                                                                   Instruction : Give me a quote from a
                                                                   famous person on this topic.



                                                            Step 3: Instance Generation
                                     Task
                                                                                                                             Yes
                                  Instruction : Find out if the given text is in favor of or against abortion.

                                                                                                                                          ü§ñ
     Step 4: Filtering
                                  Class Label: Pro-abortion
                                  Input: Text: I believe that women should have the right to choose whether or not
                                      Task                                                                            Output-first
                                  they want to have an abortion.                                                                          LM


                                     Task
                                   Instruction : Give me a quote from a famous person on this topic.                          No

                                   Input:
                                      TaskTopic: The importance of being honest.
                                   Output: "Honesty is the first chapter in the book of wisdom." - Thomas Jefferson       Input-first


Figure 2: A high-level overview of SELF-INSTRUCT. The process starts with a small seed set of tasks as the task
pool. Random tasks are sampled from the task pool, and used to prompt an off-the-shelf LM to generate both new
instructions and corresponding instances, followed by filtering low-quality or similar generations, and then added
back to the initial repository of tasks. The resulting data can be used for the instruction tuning of the language model
itself later to follow instructions better. Tasks shown in the figure are generated by GPT3.


true variety of tasks and different ways to describe                        data provides a diverse range of creative tasks, as
them. Continuing to improve the quality and cov-                            is demonstrated by examples in Figure 1. These
erage of instruction-tuned models necessitates the                          generated tasks deviate from the distribution of typ-
development of alternative approaches for supervis-                         ical NLP tasks, and also have fairly small overlap
ing the instruction tuning process.                                         with the seed tasks (¬ß3.2). On this resulting data,
    In this work, we introduce SELF-INSTRUCT, a                             we build GPT3SELF-INST by finetuning GPT3 (i.e.,
semi-automated process for instruction-tuning a                             the same model used for generating the instruction
pretrained LM using instructional signals from the                          data). We evaluate GPT3SELF-INST in comparison to
model itself. The overall process is an iterative boot-                     various other models on both typical NLP tasks in-
strapping algorithm (see Figure 2), which starts off                        cluded in SUPERNI (Wang et al., 2022), and a set of
with a limited (e.g., 175 in our study) seed set of                         new instructions that are created for novel usage of
manually-written tasks that are used to guide the                           instruction-following models (¬ß4). The results in-
overall generation. In the first phase, the model                           dicate that GPT3SELF-INST outperforms GPT3 (the
is prompted to generate instructions for new tasks.                         original model) by a large margin (+33.1%) and
This step leverages the existing collection of instruc-                     nearly matches the performance of InstructGPT001 .
tions to create more broad-coverage instructions                            Moreover, our human evaluation on the newly-
that define (often new) tasks. Given the newly-                             created instruction set shows that GPT3SELF-INST
generated set of instructions, the framework also                           demonstrates a broad range of instruction follow-
creates input-output instances for them, which can                          ing ability, outperforming models trained on other
be later used for supervising the instruction tuning.                       publicly available instruction datasets and leaving
Finally, various heuristics are used to automatically                       only a 5% gap behind InstructGPT001 .
filter low-quality or repeated instructions, before
adding the remaining valid tasks to the task pool.                             In summary, our contributions are: (1) we
This process can be repeated for many iterations                            introduce SELF-INSTRUCT, a method for induc-
until reaching a large number of tasks.                                     ing instruction following capabilities with mini-
    To evaluate SELF-INSTRUCT empirically, we run                           mal human-labeled data; (2) we demonstrate its
this framework on GPT3 (Brown et al., 2020),                                effectiveness via extensive instruction-tuning ex-
which is a vanilla LM (¬ß3). The iterative SELF-                             periments; and (3) we release a large synthetic
INSTRUCT process on this model leads to about 52k                           dataset of 52K instructions and a set of manually-
instructions, paired with about 82K instance inputs                         written novel tasks for building and evaluating fu-
and target outputs. We observe that the resulting                           ture instruction-following models.
2     Method                                                       tasks, and 2 are from the model-generated tasks in
                                                                   previous steps to promote diversity. The prompting
Annotating large-scale instruction data can be chal-               template is shown in Table 5.
lenging for humans because it requires 1) creativity
to come up with novel tasks and 2) expertise for                   Classification Task Identification. Because we
writing the solutions to each task. Here, we de-                   need two different approaches for classification and
tail our process for SELF-INSTRUCT, which refers                   non-classification tasks, we next identify whether
to the pipeline of generating tasks with a vanilla                 the generated instruction represents a classification
pretrained language model itself, filtering the gen-               task or not.4 We prompt the LM in a few-shot way to
erated data, and then conducting instruction tuning                determine this, using 12 classification instructions
with this generated data in order to align the LM to               and 19 non-classification instructions from the seed
follow instructions better. This pipeline is depicted              tasks. The prompting template is shown in Table 6.
in Figure 2.
                                                                   Instance Generation. Given the instructions and
2.1    Defining Instruction Data                                   their task type, we generate instances for each in-
                                                                   struction independently. This is challenging be-
The instruction data we want to generate contains a
                                                                   cause it requires the model to understand what the
set of instructions {ùêºùë° }, each of which defines a task
                                                                   target task is, based on the instruction, figure out
ùë° in natural language. Task ùë° has ùëõùë° ‚â• 1 input-output
                          ùëõùë°                                       what additional input fields are needed and gener-
instances {(ùëãùë°,ùëñ , ùëåùë°,ùëñ )}ùëñ=1 . A model ùëÄ is expected
                                                                   ate them, and finally complete the task by produc-
to produce the output, given the task instruction
                                                                   ing the output. We found that pretrained LMs can
and the corresponding input: ùëÄ(ùêºùë° , ùëãùë°,ùëñ ) = ùëåùë°,ùëñ ,
                                                                   achieve this to a large extent when prompted with
for ùëñ ‚àà {1, ‚Ä¶ , ùëõùë° }. Note that the instruction and
                                                                   instruction-input-output in-context examples from
instance input does not have a strict boundary in
                                                                   other tasks. A natural way to do this is the Input-
many cases. For example, ‚Äúwrite an essay about
                                                                   first Approach, where we can ask an LM to come
school safety‚Äù can be a valid instruction that we
                                                                   up with the input fields first based on the instruc-
expect models to respond to directly, while it can
                                                                   tion, and then produce the corresponding output.
also be formulated as ‚Äúwrite an essay about the fol-
                                                                   This generation order is similar to how models are
lowing topic‚Äù as the instruction, and ‚Äúschool safety‚Äù
                                                                   used to respond to instruction and input, but here
as an instance input. To encourage the diversity of
                                                                   with in-context examples from other tasks. The
the data format, we allow such instructions that do
                                                                   prompting template is shown in Table 7.
not require additional input (i.e., ùëã is empty).
                                                                      However, we found that this approach can gen-
2.2    Automatic Instruction Data Generation                       erate inputs biased toward one label, especially for
                                                                   classification tasks (e.g., for grammar error detec-
Our pipeline for data generation consists of four
                                                                   tion, it usually generates grammatical input). There-
steps: 1) generating task instructions, 2) determin-
                                                                   fore, we additionally propose an Output-first Ap-
ing if the instruction represents a classification task,
                                                                   proach for classification tasks, where we first gener-
3) instance generation with either an input-first or
                                                                   ate the possible class labels, and then condition the
output-first approach, and 4) filtering low-quality
                                                                   input generation on each class label. The prompting
data.
                                                                   template is shown in Table 8.5 We apply the output-
Instruction Generation. At the first step, SELF-                   first approach to the classification tasks identified
INSTRUCT generates new instructions from a small                   in the former step, and the input-first approach to
set of seed human-written instructions in a boot-                  the remaining non-classification tasks.
strapping fashion. We initiate the task pool with
                                                                   Filtering and Postprocessing. To encourage di-
175 tasks (1 instruction and 1 instance for each
                                                                   versity, a new instruction is added to the task pool
task).3 For every step, we sample 8 task instruc-
                                                                   only when its ROUGE-L similarity with any exist-
tions from this pool as in-context examples. Of
the 8 instructions, 6 are from the human-written                      4
                                                                         More concretely, we regard tasks that have a small limited
                                                                   output label space as classification tasks.
    3                                                                  5
      These tasks were newly written by the authors and their            In this work, we use a fixed set of seed tasks for prompt-
labmates at UW, without reference to existing datasets or the      ing the instance generation, and thus only generate a small
test set used in this work. We provide more details about these    number of instances per task in one round. Future work can
tasks and analyze their similarity to the test tasks in Appendix   use randomly sampled tasks to prompt the model to generate
¬ßA.1.                                                              a larger number of instances in multiple rounds.
ing instruction is less than 0.7. We also exclude           3.2     Diversity
instructions that contain some specific keywords
(e.g., image, picture, graph) that usually can not be       To study what types of instructions are generated
processed by LMs. When generating new instances             and how diverse they are, we identify the verb-noun
for each instruction, we filter out instances that are      structure in the generated instructions. We use the
exactly the same or those with the same input but           Berkeley Neural Parser7 (Kitaev and Klein, 2018;
different outputs. Invalid generations are identified       Kitaev et al., 2019) to parse the instructions and
and filtered out based on heuristics (e.g., instruc-        then extract the verb that is closest to the root as
tion is too long or too short, instance output is a         well as its first direct noun object. 26,559 out of the
repetition of the input).                                   52,445 instructions contain such structure; other
                                                            instructions usually contain more complex clauses
2.3       Finetuning the LM to Follow Instructions          (e.g., ‚ÄúClassify whether this tweet contains political
After creating large-scale instruction data, we use it      content or not.‚Äù) or are framed as questions (e.g.,
to finetune the original LM (i.e., SELF-INSTRUCT).          ‚ÄúWhich of these statements are true?‚Äù). We plot
To do this, we concatenate the instruction and in-          the top 20 most common root verbs and their top 4
stance input as a prompt and train the model to             direct noun objects in Figure 3, which account for
generate the instance output in a standard super-           14% of the entire set. Overall, we see quite diverse
vised way. To make the model robust to different            intents and textual formats in these instructions.
formats, we use multiple templates to encode the               We further study how the generated instructions
instruction and instance input together. For exam-          differ from the seed instructions used to prompt
ple, the instruction can be prefixed with ‚ÄúTask:‚Äù or        the generation. For each generated instruction, we
not, the input can be prefixed with ‚ÄúInput:‚Äù or not,        compute its highest ROUGE-L overlap with the
‚ÄúOutput:‚Äù can be appended at the end of the prompt          175 seed instructions. We plot the distribution of
or not, and different numbers of break lines can be         these ROUGE-L scores in Figure 4. The results
put in the middle, etc.                                     indicate a decent number of new instructions were
                                                            generated, which do not have much overlap with the
3       SELF-INSTRUCT Data from GPT3
                                                            seeds. We also demonstrate diversity in the length
In this section, we apply our method for inducing           of the instructions, instance inputs, and instance
instruction data to GPT3 as a case study. We use            outputs in Figure 5.
the largest GPT3 LM (‚Äúdavinci‚Äù engine) accessed
through the OpenAI API.6 The parameters for mak-
                                                            3.3     Quality
ing queries are described in Appendix A.2. Here
we present an overview of the generated data.               So far, we have shown the quantity and diversity
3.1       Statistics                                        of the generated data, but its quality remains un-
                                                            certain. To investigate this, we randomly sample
Table 1 describes the basic statistics of the gener-
                                                            200 instructions and randomly select 1 instance per
ated data. We generate a total of over 52K instruc-
                                                            instruction. We asked an expert annotator (author
tions and more than 82K instances corresponding
                                                            of this work) to label whether each instance is cor-
to these instructions after filtering.
                                                            rect or not, in terms of the instruction, the instance
         statistic
                                                            input, and the instance output. Evaluation results in
                                                            Table 2 show that most of the generated instructions
         # of instructions                         52,445
          - # of classification instructions       11,584   are meaningful, while the generated instances may
          - # of non-classification instructions   40,861   contain more noise (to a reasonable extent). How-
         # of instances                            82,439   ever, we found that even though the generations
          - # of instances with empty input        35,878
         ave. instruction length (in words)         15.9    may contain errors, most of them are still in the
         ave. non-empty input length (in words)     12.7    correct format or partially correct, which can pro-
         ave. output length (in words)              18.9
                                                            vide useful guidance for training models to follow
Table 1: Statistics of the generated data by applying
                                                            instructions. We listed a number of good examples
SELF-INSTRUCT to GPT3.                                      and bad examples in Table 10 and 11, respectively.

    6                                                          7
        https://openai.com/api/                                    https://parser.kitaev.io/
                                                                                                                                                                                 3000




                                                                                                                                                                # Instructions
                                                 letter                                                                                                                          2000




                            par
                                                                                                                                                                                 1000
                                                                                  essay




                                agr
                                                                                                                                                                                    0




                                  aph
                                                                                                                                                                                        0               0.2              0.4          0.6         0.8     1

             example                                                                                                                                                                        ROUGE-L Overlap with the Most Similar Seed Instruction

                                                                                                                                                                 Figure 4: Distribution of the ROUGE-L scores
                                                                                                         function                                                between generated instructions and their most
      list
                                                        write                                                                                                    similar seed instructions.
set                             give
advice




                                                                                                                                                                # Instructions
                                                                                                                                                                                 6000
                                                                                                detect
                                                                                             predict                                            sarcasm
                                                                                           output                                     sentiment
                                                                                         identify                                                 word
                                                                                                                                                                                 4000
                                                                                             te                                           number
                                                                                       expla ll
    word                     find                                              cla have
                                                                                            in                                              topic
                                                                                                                                       sentimen
                                                                                                                                                t
                                                                                                                                                 joke
                                                                                                                                                                                 2000

                                                                                  ssi                                                   story                                       0
                                                                                     fy
                                                                          ge esign
                                                                                                                                 c
                                                                                                                            diffe oncept                                                      10              20               30           40     50    60
                                          ate

                                                         desc


                ber                                                         ne
                                                                                                                                  renc
                                                                          d
                                                 make


                                                                              ra
                                                                                                                                      e                                                                                 Instruction Length
         num                                                                    te
                                      cre




                                                                                                                                           se
                                                                                                                                    co t
                                                             ribe


                                                                                                                                 arr in
                                                                                                                                      ay
                                                                                                                                list
                   ce                                                                                                       ar text

                ten
                                                                                                                       s
                                                                                                                    se entim ticle                                               3000




                                                                                                                                                                # Inputs
                                                                                                                      nte en
               n                                                                                                se s nce
                                                                                                                               t
                            m




                                                                                                                                                                                 2000
             se                                                                                                   nt erie
                                                                                                                    en s
                        gra




                                                                                                                     ce
                                                                                                           nu liscture
                y




                                                                                                                                                                                 1000
                                                                                                             m
             wa




                                                                situati




                                                                                                              be
                                                                                             alg gam
                  pro


                                   funct hm




                                                                                                                r                                                                   0
                                                                                                         str
                                                                                                ori
                                                                                   sys time s


                                                                                                            u

                                                                                                                  t
                                                                                                                                                                                                   10              20           30           40     50   60
                                                                                                   thm
                                        ion
                                    rit




                                                                                      tem
                         list




                                                                              p




                                                                                                                                                                                                                          Input Length
                                                                              pers




                                                                                                       e
                                algo




                                                                                 roce
                                                         sentence




                                              list
                                                                        o
                                                     story




                                                                                     s
                                                                                  on
                                                                program

                                                                          n




                                                                                                                                                                                 30k




                                                                                                                                                                 # Onputs
                                                                                                                                                                                 20k
Figure 3: The top 20 most common root verbs (inner circle) and
                                                                                                                                                                                 10k
their top 4 direct noun objects (outer circle) in the generated
instructions. Despite their diversity, the instructions shown here                                                                                                                 0
                                                                                                                                                                                                   10          20               30          40     50    60

only account for 14% of all the generated instructions because                                                                                                                                                           Onput Length

many instructions (e.g., ‚ÄúClassify whether the user is satisfied                                                                                                 Figure 5: Length distribution of the generated
with the service.‚Äù) do not contain such a verb-noun structure.                                                                                                   instructions, non-empty inputs, and outputs.



                 Quality Review Question                                               Yes %                                           and input, and train the model to generate the output.
                                                                                                                                       This finetuning is done through the OpenAI fine-
                     Does the instruction                                                92%
                    describe a valid task?                                                                                             tuning API.8 We use the default hyper-parameters,
                                                                                                                                       except that we set the prompt loss weight to 0, and
                  Is the input appropriate                                               79%
                     for the instruction?                                                                                              we train the model for 2 epochs. We refer the reader
                                                                                                                                       to Appendix A.3 for additional finetuning details.
         Is the output a correct and acceptable                                          58%                                           The resulting model is denoted by GPT3SELF-INST .
         response to the instruction and input?

                        All fields are valid                                             54%                                           4.2                    Baselines
                                                                                                                                       Off-the-shelf LMs. We evaluate T5-LM (Lester
Table 2: Data quality review for the instruction, input,
                                                                                                                                       et al., 2021; Raffel et al., 2020) and GPT3 (Brown
and output of the generated data. See Table 10 and
Table 11 for representative valid and invalid examples.                                                                                et al., 2020) as the vanilla LM baselines (only pre-
                                                                                                                                       training, no additional finetuning). These baselines
                                                                                                                                       will indicate the extent to which off-the-shelf LMs
4      Experimental Results                                                                                                            are capable of following instructions naturally im-
                                                                                                                                       mediately after pretraining.
We conduct experiments to measure and compare
the performance of models under various instruc-                                                                                       Publicly available instruction-tuned models.
tion tuning setups. We first describe our models                                                                                       T0 and Tùëò-INSTRUCT are two instruction-tuned
and other baselines, followed by our experiments.                                                                                      models proposed in Sanh et al. (2022) and Wang
                                                                                                                                       et al. (2022), respectively, and are demonstrated
4.1      GPT3SELF-INST : finetuning GPT3 on its                                                                                        to be able to follow instructions for many NLP
         own instruction data                                                                                                          tasks. Both of these models are finetuned from
Given the instruction-generated instruction data, we                                                                                   the T5 (Raffel et al., 2020) checkpoints and are pub-
conduct instruction tuning with the GPT3 model                                                                                         licly available.9 For both of these models, we use
itself (‚Äúdavinci‚Äù engine). As described in ¬ß2.3, we                                                                                                     8
                                                                                                                                                            See OpenAI‚Äôs documentation on finetuning.
use various templates to concatenate the instruction                                                                                                    9
                                                                                                                                                            T0 is available at here and Tùëò-INSTRUCT is here.
their largest version with 11B parameters.                        Model                              # Params ROUGE-L
                                                                  Vanilla LMs
Instruction-tuned GPT3 models. We evaluate                        T5-LM                                 11B       25.7
                                                                  GPT3                                 175B        6.8
InstructGPT (Ouyang et al., 2022), which is devel-
oped by OpenAI based on GPT3 to follow human ‚Éù          1
                                                             Instruction-tuned  w/o S UPER NI
                                                             T0                                         11B       33.1
instructions better and has been found by the com-           GPT3 + T0 Training                        175B       37.9
munity to have impressive zero-shot abilities. There ‚Éù  2
                                                             GPT3S -I       (Ours)
                                                                          ELF NST                      175B       39.9
                                                             InstructGPT001                            175B       40.8
are various generations of these models, where
                                                             Instruction-tuned w/ SUPERNI
newer ones use more expansive data or algorithmic            Tùëò-INSTRUCT                                11B       46.0
novelties.10 For our SUPERNI experiments in ¬ß4.3, ‚Éù     3
                                                             GPT3   + S UPER NI Training               175B       49.5
                                                             GPT3S -I + SUPERNI Training (Ours) 175B              51.6
we only compare with their text-davinci-001                               ELF NST



engine, because their newer engines are trained with     Table 3: Evaluation results on unseen tasks from SU-
the latest user data and are likely to have already       PER NI (¬ß4.3). From the results, we see that ‚Éù         1 S ELF -
seen the SUPERNI test set. For our human evalua- INSTRUCT can boost GPT3 performance by a large mar-
tion on newly written instructions, we include their      gin (+33.1%) and ‚Éù     2 nearly matches the performance of

001, 002 and 003 engines for completeness.                InstructGPT    001 . Additionally,   ‚Éù3 it can further improve

   Additionally, to compare SELF-INSTRUCT train-          the performance      even   when   a large  amount of labeled
                                                          instruction data is present.
ing with other publicly available instruction tuning
data, we further finetune GPT3 model with data
from PROMPTSOURCE and SUPERNI, which are                 vant and repetitive text, and does not know when
used to train the T0 and Tùëò-INSTRUCT models. We           to stop generation. Compared with other mod-
call them T0 training and SUPERNI training for            els that are not specifically trained for SUPERNI,
short, respectively. To save the training budget, we      GPT3SELF-INST achieves better performance than T0
sampled 50K instances (but covering all their in- or the GPT3 finetuned on the T0 training set, which
structions) for each dataset, which has a comparable      takes tremendous human labeling efforts. Notably,
size to the instruction data we generated. Based on       GPT3SELF-INST also nearly matches the performance
the findings from Wang et al. (2022) and our early        of InstructGPT001 , which is trained with private
experiments, reducing the number of instances per         user data and human-annotated labels.
training task does not degrade the model‚Äôs general-          Models trained on the SUPERNI training set still
ization performance to unseen tasks.                      achieve better performance on its evaluation set,
                                                         which we attribute to the similar instruction style
4.3 Experiment 1: Zero-Shot Generalization
                                                          and formatting. However, we show that SELF-
        on SUPERNI benchmark
                                                          INSTRUCT still brings in additional gains when com-
We first evaluate the models‚Äô ability to follow in- bined with the SUPERNI training set, proving its
structions on typical NLP tasks in a zero-shot fash- value as complementary data.
ion. We use the evaluation set of SUPERNI (Wang
et al., 2022), which consists of 119 tasks with 100 in- 4.4 Experiment 2: Generalization to
stances in each task. In this work, we mainly focus              User-oriented Instructions on Novel Tasks
on the zero-shot setup, i.e., the model is prompted           Despite the comprehensiveness of SUPERNI in col-
with the definition of the tasks only, without in-            lecting existing NLP tasks, most of these NLP tasks
context demonstration examples. For all our re-               were proposed for research purposes and skewed
quests to the GPT3 variants, we use the determin-             toward classification. To better access the practi-
istic generation mode (temperature as 0 and no nu-            cal value of instruction-following models, a sub-
cleus sampling) without specific stop sequences.              set of the authors curate a new set of instructions
                                                              motivated by user-oriented applications. We first
Results. We make the following observations
                                                              brainstorm various domains where large LMs may
from the results in Table 3. SELF-INSTRUCT boosts
                                                              be useful (e.g., email writing, social media, pro-
the instruction-following ability of GPT3 by a large
                                                              ductivity tools, entertainment, programming), then
margin. The vanilla GPT3 model basically can-
                                                              craft instructions related to each domain along with
not follow human instructions at all. Upon manual
                                                              an input-output instance (again, input is optional).
analysis, we find that it usually generates irrele-
                                                              We aim to diversify the styles and formats of these
  10
       See OpenAI‚Äôs documentation on their models.            tasks (e.g., instructions may be long or short; in-
                                 correct
                                  correctand
                                   correct and  satisfying
                                                 satisfying    response
                                                                response     acceptable
                                                                               acceptable  response
                                                                                             response  with
                                                                                                        with  minor
                                                                                                               minor   imperfections
                                                                                                                         imperfections
                                     correct
                                    A:
                               correct andand
                                   correct  and
                                       correct    satisfying
                                                and
                                                andsatisfying
                                                      satisfying
                                                      satisfying
                                              satisfying         response
                                                                 response
                                                                    response
                                                                  response
                                                             response           acceptable
                                                                                   acceptable
                                                                            acceptable        response
                                                                                          response
                                                                                   B: acceptable response
                                                                                                     with
                                                                                                  responsewith  minor
                                                                                                              with
                                                                                                             minor
                                                                                                             with   minor imperfections
                                                                                                                             imperfections
                                                                                                                     imperfections
                                                                                                                  minor    imperfections
                                0respondstotothe
                               0responds      theinstruction
                                                  instructionbut
                                                              buthas
                                                                  hassignificant
                                                                      significanterrors
                                                                                  errors               irrelevant
                                                                                                     irrelevant     or
                                                                                                                   or    invalid
                                                                                                                       invalid    response
                                                                                                                                 response
                             00responds
                                responds
                               C:0responds
                          0responds       to
                                           to
                                      to the
                                  responds    the
                                               the
                                            toto    instruction
                                               thetheinstruction
                                                    instruction  butbut
                                                       instruction
                                               instruction      but but
                                                                     hashas
                                                                       but
                                                                      hashas significant
                                                                            has  significant
                                                                          significant
                                                                          significant       errors
                                                                                        errors
                                                                                      errors   errorsD: irrelevant
                                                                                                            irrelevant
                                                                                                    irrelevant            or
                                                                                                                  ororinvalid
                                                                                                         irrelevant    or invalid  response
                                                                                                                             invalid
                                                                                                                        invalid       response
                                                                                                                                response
                                                                                                                                response
                                1 111 1
    100%
   100%                   1
    100%
 100%100%
       100%
                         646464
                             64
                              6464                            444444
                                                                  44
                                                                   44 44                           747474
                                                                                                        74
                                                                                                        74 74                          838383
                                                                                                                                            83
                                                                                                                                            83 83                            112
                                                                                                                                                                            112
                                                                                                                                                                           113 113113                             128
                                                                                                                                                                                                                 128
                                                                                                                                                                                                                129 129129                            168
                                                                                                                                                                                                                                                     168
                                                                                                                                                                                                                                                    169 169169                             192
                                                                                                                                                                                                                                                                                          192
                                                                                                                                                                                                                                                                                         192 192192
                                                                                                                                                                                                                                                                                             192


   75%
 75%75%
     75%
       75%                                                    313131
                                                                  31
                                                                   31 31
                          187
                        186 186
                             186
                               186
                                                              595959
                                                                  59
                                                                   59 59                           303030
                                                                                                        30
                                                                                                        30 30
                                                                                                                                       545454
                                                                                                                                            54
                                                                                                                                            54 54
    50%
     50%                                                                                                80
                                                                                                   808080
                                                                                                        80 80
   50%
 50%   50%                                                                                                                                                                  48494948 48
                                                                117
                                                                117117
                                                              118
                                                            117117                                                                          84
                                                                                                                                            84 84                                                                4454544 44
                                                                                                                                       848484
                                                                                                                                                                            66666666 66                                                               404039 39
                                                                                                                                                                                                                                                     39
 25%25%
     25%
    25%25%                                                                                                                                                                                                       61616161 61                                                                    30 30
   25%                                                                                                  68
                                                                                                        68 68
                                                                                                   686868                                                                                                                                                                                   303030
                                                                                                                                                                                                                                                                                           30
                                                                                                                                                                                                                                                      343434 34
                                                                                                                                                                                                                                                     34                                        28 28
                                                                                                                                            31
                                                                                                                                            31 31                                                                                                                                          282828
                                                                                                                                                                                                                                                                                          28
                                                                                                                                       313131                               25252525 25                          18181818 18
     0%
      0%                                                                                                                                                                                                                                              101010 10
                                                                                                                                                                                                                                                     10                                     22 2 22 2
     0%0%
  0%0%
                       T3T33T3
               TGP3TPTPT                            g ngg g
                                         nairnirnanaiininnniiganigingnin
                                                                                                  g ngg g
                                                                                       niirnrnnaainininnigniainginin                      NN     I IrrN   I I
                                                                                                                                                  ereNpNIerN                           ct tuttct ct                              01 0010-1T000011 -0002-2002T            02 02 2                  003-3T    0033 03
            Ga
              PGP GP3G3P         r  aiT  rT i      i      r                      r ariaT
                                                                                       T i      i       r                    u puepSpSreuepurrpepN   u            I  n   s3t-srISutsnertlusfr-tcIuIrnncsstru PT-0P-0-T00-P1G          TP               P   T     -
                                                                                                                                                                                                                                                                 P0-TG
                                                                                                                                                                                                                                                                     0 PT-000 PT-t0-G
                                                                                                                                                                                                                                                                       P                         0
                                                                                                                                                                                                                                                                                                 P-TP00-P003T
                                                                                                                                                                                                                                                                                                            00-30
            l  GG              T          a
                                0T00TT0TrTr0 a     T                          T  TIIr ra   a     T                        S                      S             -
                                                                                                                                                             lf SPfle-T    f               -                                 G T
                                                                                                                                                                                                                             T c   t                          T
                                                                                                                                                                                                                                                              G T  t                            T
                                                                                                                                                                                                                                                                                               TctG
                                                                                                                                                                                                                                                                                         cuPtcPG
       Van
          il                T0T0T                                              I ITrTNI
                                                                           I rIrNN
                                                                      rNrpNN                                     ct +ustc+
                                                                                                                             S++u u+
                                                                                                                         +ctt+ScSt                         SeG        fIl-nSInelf trucstctG                          uGcGPt PtrcutG          ctGuGcG      tPtrPucctG          ctGG    turG
                          T3+TT                           upuepSSpeueupprSe
                                                                           ereN
                                                                             upe nTs3trISIunnerlstusfrt-tcIurnrntucsttru                                    SSele                                  n   s ItnrturuIrntcIstntrsu InstrIturntusrcutIIrtnnctsstru InstrtIurntIursncutIsrtcntstru
                   GP                               S
                                                    +
                                         T3 SuSu SelG
                                                          S
                                                                                       f-SPIee-lIlf-nf-I-esnltsf-I
                                                                                                                                                                                             I           s
                                                                                                                                                                                                      InIn s                            s
                                                                                                                                                                                                                                     InIn  s                              s
                                                                                                                                                                                                                                                                       InIn s
                                 GP                                                        SflfS
                                                                                    SeSle
Figure 6: Performance of GPT3 model and its instruction-tuned variants, evaluated by human experts on our 252
user-oriented instructions (¬ß4.4). Human evaluators are instructed to rate the models‚Äô responses into four levels. The
results indicate that GPT3SELF-INST outperforms all the other GPT3 variants trained on publicly available instruction
datasets. Additionally, GPT3SELF-INST scores nearly as good as InstructGPT001 (cf. footnote 1).


put/output may take the form of bullet points, ta-                                                                                                                erate other irrelevant things.
bles, codes, equations, etc.). In total, we create 252                                                                                                          ‚Ä¢ R ATING-D: The response is irrelevant or com-
instructions with 1 instance per instruction. We                                                                                                                  pletely invalid.
believe it can serve as a testbed for evaluating how
                                                                                                                                                                Results. Figure 6 shows the performance of
instruction-based models handle diverse and unfa-
                                                                                                                                                                GPT3 model and its instruction-tuned counterparts
miliar instructions. Table 9 presents a small portion
                                                                                                                                                                on this newly written instruction set (w. inter-rater
of them. The entire set is available in our GitHub
                                                                                                                                                                agreement ùúÖ = 0.57 on the 4-class categorical scale,
repository. We analyze the overlap between this set
                                                                                                                                                                see Appendix B for details). As anticipated, the
set and the seed instructions in ¬ßA.1.
                                                                                                                                                                vanilla GPT3 LM is largely unable to respond to in-
Human evaluation setup. Evaluating models‚Äô                                                                                                                      structions, and all instruction-tuned models demon-
performance on this evaluation set of diverse tasks                                                                                                             strate comparatively higher performance. Nonethe-
is extremely challenging because different tasks re-                                                                                                            less, GPT3SELF-INST (i.e., GPT3 model finetuned
quire different expertise. Indeed, many of these                                                                                                                with SELF-INSTRUCT) outperforms those counter-
tasks cannot be measured by automatic metrics or                                                                                                                parts trained on T0 or SUPERNI data by a large mar-
even be judged by normal crowdworkers (e.g., writ-                                                                                                              gin, demonstrating the value of the generated data
ing a program, or converting first-order logic into                                                                                                             despite the noise. Compared with InstructGPT001 ,
natural language). To get a more faithful evaluation,                                                                                                           GPT3SELF-INST is quite close in performance‚Äîif
we asked the authors of the instructions to judge                                                                                                               we count acceptable response with minor imper-
model predictions. Details on how we set up this                                                                                                                fections (R ATING-B) as valid, GPT3SELF-INST is
human evaluation are described in Appendix B. The                                                                                                               only 5% behind InstructGPT001 . Lastly, our evalua-
evaluators were asked to rate the output based on                                                                                                               tion confirms the impressive instruction-following
whether it accurately and effectively completes the                                                                                                             ability of InstructGPT002 and InstructGPT003 . Al-
task. We implemented a four-level rating system                                                                                                                 though there are many factors behind this success,
for categorizing the quality of the models‚Äô outputs:                                                                                                            we conjecture that future work can largely benefit
                                                                                                                                                                from improving the quality of our generated data by
‚Ä¢ R ATING-A: The response is valid and satisfying.                                                                                                              using human annotators or training a reward model
‚Ä¢ R ATING-B: The response is acceptable but has                                                                                                                 to select better generations, similar to the algorithm
  minor errors or imperfections.                                                                                                                                used by Ouyang et al. (2022).
‚Ä¢ R ATING-C: The response is relevant and re-
  sponds to the instruction, but it has significant                                                                                                             4.5               Effect of Data Size and Quality
  errors in the content. For example, GPT3 might                                                                                                                Data size. SELF-INSTRUCT provides a way to
  generate a valid output first, but continue to gen-                                                                                                           grow instruction data at a low cost with almost
no human labeling; could more of this generated
                                                                                                               w. GPT3 Self-Instruct data
data lead to better instruction-following ability? We




                                                           Percentage of Responses Rated as A
                                                                                                               w. improved output from InstructGPT
conduct an analysis of the size of generated data                                               60%

by subsampling different numbers of instructions
from the generated dataset, finetuning GPT3 on the                                              50%                                          54.4%
sampled subsets, and evaluating how the resulting
models perform on the 252 user-oriented instruc-                                                40%                                   43.7% 44.4%
tion set. We conduct the same human evaluation
                                                                                                                  36.9%
as in ¬ß4.4. Figure 7 presents the performance of                                                30%
GPT3SELF-INST models finetuned with different sizes                                                    31.0%
of generated data. Overall, we see consistent im-
                                                                                                20%
provement as we grow the data size. However, this                                                     100         800          6400          51200
improvement almost plateaus after 16K. This is in-                                                              Number of Instructions
line with the data scaling experiments in Wang et al.
(2022, Fig. 5). Interestingly, when evaluating on         Figure 7:       Human evaluation performance of
                                                          GPT3SELF-INST models tuned with different sizes of
SUPERNI we found the model‚Äôs performance gain
                                                          instructions. ùë•-axis is in log scale. The smallest
plateaus earlier at around hundreds of instructions.      size is 175, where only the seed tasks are used for
This may be due to the fact that the new generated        instruction tuning. We also evaluate whether improving
data is distinct from typical NLP tasks in SUPERNI,       the data quality will further improve the performance
indicating that future research may benefit from us-      by distilling the outputs from InstructGPT003 . We see
ing a combination of different instruction data for       consistent improvement from using larger data with
better performance on various types of tasks.             better quality.

Data quality. Another direction to improve the
model‚Äôs performance is to take our generated data         these developments largely focus on existing NLP
and get better supervision (with less noise). We          tasks and depend on human-annotated instructions,
explore this idea by using InstructGPT003 (the best       this poses a bottleneck for progress toward more
available general-purpose model) to regenerate the        generalizable models (e.g., see Fig. 5a in Wang
output field of all our instances given the instruction   et al., 2022). Our work aims to move beyond classi-
and input. We then use this improved version of           cal NLP tasks and tackle the challenges of creating
our data to finetune GPT3. This can be regarded as        diverse instruction data by employing pretrained
a distillation of InstructGPT003 with our data. As is     LMs. InstructGPT (Ouyang et al., 2022) shares
shown in Figure 7, the resulting model outperforms        a similar goal as ours in building more general-
the counterpart trained with the original data by         purpose LMs, and has demonstrated remarkable
10%, which suggests big room for future work on           performance in following diverse user instructions.
using our generation pipeline to get initial data and     However, as a commercial system, their construc-
then improving the data quality with human experts        tion process still remains quite opaque. In partic-
or distillation from better models.                       ular, the role of data has remained understudied
                                                          due to limited transparency and the private user
5   Related Work                                          data they used in their study. Addressing such chal-
                                                          lenges necessitates the creation of a large-scale,
Instruction-following LMs. A series of works
                                                          public dataset covering a broad range of tasks.
have found evidence that vanilla LMs can be effec-
tive at following general language instructions if        Language models for data generation and aug-
tuned with annotated ‚Äúinstructional‚Äù data‚Äîdatasets        mentation. A variety of works have proposed
containing language instructional commands and            using LMs for data generation (Schick and Sch√ºtze,
their desired outcomes based on human annota-             2021; Wang et al., 2021; Liu et al., 2022; Meng
tion (Weller et al., 2020; Mishra et al., 2022; Wei       et al., 2023) or augmentation (Feng et al., 2021;
et al., 2022; Sanh et al., 2022, i.a.). Additionally,     Yang et al., 2020; Mekala et al., 2022). Our work
they show a direct correlation between the size and       differs from this line in that it is not specific to a
diversity of the ‚Äúinstructional‚Äù data and the general-    particular task (say, QA or NLI). In contrast, a dis-
izability of resulting models to unseen tasks (Wang       tinct motivation for SELF-INSTRUCT is to bootstrap
et al., 2022; Chung et al., 2022). However, since         new task definitions that may not have been defined
before by NLP practitioners (though potentially still       the content of distillation is in the form of an
important for real users). In parallel with our work,       instruction task (i.e., instructions that define a task,
Honovich et al. (2022a) also propose to generate            and a set of examples that instantiate it).
large-scale instruction data (so-called Unnatural
Instructions) with GPT3 models. The major differ-           Bootstrapping with limited resources. A se-
ences are that 1) they use tasks in SUPERNI (Wang           ries of recent works use language models to boot-
et al., 2022) as their seed tasks, resulting in a differ-   strap some inferences using specialized methods.
ent distribution of generated tasks; 2) they employ         NPPrompt (Zhao et al., 2022) provides a method
InstructGPT002 for generating the data, in which            to generate predictions for semantic labels without
sense they are distilling knowledge from an already         any finetuning. It uses a model‚Äôs own embeddings
instruction-tuned model, while we solely rely on            to automatically find words relevant to the label of
the vanilla LM; 3) the detailed generation pipeline         the data sample and hence reduces the dependency
and templates are different. Nevertheless, we be-           on manual mapping from model prediction to la-
lieve that both efforts in expanding instruction data       bel (verbalizers). STAR (Zelikman et al., 2022)
are complementary, and the community will benefit           iteratively leverages a small number of rationale
from these diverse datasets.                                examples and a large dataset without rationales, to
                                                            bootstrap a model‚Äôs ability to perform reasoning.
Instruction generation. A series of recent
                                                            Self-Correction (Welleck et al., 2023) decouples an
works (Zhou et al., 2022b; Ye et al., 2022; Singh
                                                            imperfect base generator (model) from a separate
et al., 2022; Honovich et al., 2022b) generate in-
                                                            corrector that learns to iteratively correct imperfect
structions of a task given a few examples. While
                                                            generations and demonstrates improvement over the
SELF-INSTRUCT also involves instruction genera-
                                                            base generator. Our work instead focuses on boot-
tion, a major difference in our case is it is task-
                                                            strapping new tasks in the instruction paradigm.
agnostic; we generate new tasks (instructions along
with instances) from scratch.
                                                            Multi-modal instruction-following. Instruction-
Model self-training. A typical self-training                following models have also been of interest in the
framework (He et al., 2019; Xie et al., 2020; Du            multi-modal learning literature (Fried et al., 2018;
et al., 2021; Amini et al., 2022; Huang et al., 2022)       Shridhar et al., 2020; Min et al., 2022; Weir et al.,
uses trained models to assign labels to unlabeled           2022). SELF-INSTRUCT, as a general approach to
data and then leverages the newly labeled data to           expanding data, can potentially also be helpful in
improve the model. In a similar line, Zhou et al.           those settings, which we leave to future work.
(2022a) use multiple prompts to specify a single
task and propose to regularize via prompt consis-
tency, encouraging consistent predictions over the          6   Conclusion
prompts. This allows either finetuning the model
with extra unlabeled training data, or direct applica-      We introduce SELF-INSTRUCT, a method to im-
tion at inference time. While SELF-INSTRUCT has             prove the instruction-following ability of LMs via
similarities with the self-training literature, most        their own generation of instruction data. On ex-
self-training methods assume a specific target task         perimenting with vanilla GPT3, we automatically
as well as unlabeled examples under it; in contrast,        construct a large-scale dataset of 52K instructions
SELF-INSTRUCT produces a variety of tasks from              for diverse tasks, and finetuning GPT3 on this data
scratch.                                                    leads to a 33% absolute improvement on SUPERNI
                                                            over the original GPT3. Furthermore, we curate
Knowledge distillation. Knowledge distilla-                 a set of expert-written instructions for novel tasks.
tion (Hinton et al., 2015; Sanh et al., 2019; West          Human evaluation on this set shows that tuning
et al., 2021; Magister et al., 2022) often involves         GPT3 with SELF-INSTRUCT outperforms using ex-
the transfer of knowledge from larger models to             isting public instruction datasets by a large margin
smaller ones. SELF-INSTRUCT can also be viewed              and performs closely to InstructGPT001 . We hope
as a form of ‚Äúknowledge distillation", however, it          SELF-INSTRUCT can serve as the first step to align
differs from this line in the following ways: (1)           pretrained LMs to follow human instructions, and
the source and target of distillation are the same,         future work can build on top of this data to improve
i.e., a model‚Äôs knowledge is distilled to itself; (2)       instruction-following models.
7   Broader Impact                                        limitation: gains of instruction-tuning are higher
                                                          for larger models (Wei et al., 2022).
Beyond the immediate focus of this paper, we
believe that SELF-INSTRUCT may help bring                 Reinforcing LM biases. A point of concern for
more transparency to what happens ‚Äúbehind the             the authors is the unintended consequences of this
scenes‚Äù of widely-used instruction-tuned models           iterative algorithm, such as the amplification of
like InstructGPT or ChatGPT. Unfortunately, such          problematic social biases (stereotypes or slurs about
industrial models remain behind API walls as their        gender, race, etc.). Relatedly, one observed chal-
datasets are not released, and hence there is lit-        lenge in this process is the algorithm‚Äôs difficulty in
tle understanding of their construction and why           producing balanced labels, which reflected models‚Äô
they demonstrate impressive capabilities. The bur-        prior biases. We hope future work will lead to better
den now falls on academia to better understand the        understanding of the pros and cons of the approach.
source of success in these models and strive for
better‚Äîand more open‚Äîmodels. We believe our               Acknowledgements
findings in this paper demonstrate the importance
of diverse instruction data, and our large synthetic      The authors would like to thank the anonymous
dataset can be the first step toward higher-quality       reviewers for their constructive feedback. We espe-
data for building better instruction-following mod-       cially thank Sewon Min, Eric Wallace, Ofir Press,
els. At this writing, the central idea of this paper      and other members of UWNLP and AllenNLP for
has been adopted in several follow-up works for           their encouraging feedback and intellectual sup-
such endeavors (Taori et al., 2023; Xu et al., 2023;      port. This work was supported in part by DARPA
Sun et al., 2023, i.a.).                                  MCS program through NIWC Pacific (N66001-19-
                                                          2-4031), ONR N00014-18-1-2826, ONR MURI
8   Limitations                                           N00014-18-1-2670, and gifts from AI2 and an
                                                          Allen Investigator award.
Here, we discuss some limitations of this work to
inspire future research in this direction.
Tail phenomena. SELF-INSTRUCT depends on                  References
LMs, and it will inherit all the limitations that         Massih-Reza Amini, Vasilii Feofanov, Loic Pauletto,
carry over with LMs. As recent studies have                Emilie Devijver, and Yury Maximov. 2022. Self-
shown (Razeghi et al., 2022; Kandpal et al., 2022),        training: A survey. arXiv preprint arXiv:2202.12040.
tail phenomena pose a serious challenge to the suc-       Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Al-
cess of LMs. In other words, LMs‚Äô largest gains              bert Webson, Colin Raffel, Nihal V Nayak, Abheesht
correspond to the frequent uses of languages (head           Sharma, Taewoon Kim, M Saiful Bari, Thibault
of the language use distribution), and there might           Fevry, et al. 2022. PromptSource: An Integrated
                                                             Development Environment and Repository for Nat-
be minimal gains in the low-frequency contexts.              ural Language Prompts. In Annual Meeting of the
Similarly, in the context of this work, it would not        Association for Computational Linguistics (ACL) -
be surprising if the majority of the gains by SELF-          System Demonstrations.
INSTRUCT are skewed toward tasks or instructions
                                                          Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
that present more frequently in the pretraining cor-        Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
pus. As a consequence, the approach might show              Neelakantan, Pranav Shyam, Girish Sastry, Amanda
brittleness with respect to uncommon and creative           Askell, Sandhini Agarwal, and et al. 2020. Language
instructions.                                               models are few-shot learners. In Advances in Neural
                                                            Information Processing Systems (NeurIPS).
Dependence on large models. Because of SELF-
INSTRUCT‚Äôs dependence on the inductive biases             Hyung Won Chung, Le Hou, Shayne Longpre, Barret
                                                            Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,
extracted from LMs, it might work best for larger           Mostafa Dehghani, Siddhartha Brahma, et al. 2022.
models. If true, this may create barriers to access for     Scaling instruction-finetuned language models. arXiv
those who may not have large computing resources.           preprint arXiv:2210.11416.
We hope future studies will carefully study the gains
                                                          Jingfei Du, √âdouard Grave, Beliz Gunel, Vishrav Chaud-
as a function of model size or various other parame-         hary, Onur Celebi, Michael Auli, Veselin Stoyanov,
ters. It is worthwhile to note that instruction-tuning       and Alexis Conneau. 2021. Self-training improves
with human annotation also suffers from a similar            pre-training for natural language understanding. In
  Conference of the North American Chapter of the As-        In Conference on Empirical Methods in Natural Lan-
  sociation for Computational Linguistics (NAACL):           guage Processing (EMNLP) - Findings.
  Human Language Technologies, pages 5408‚Äì5418.
                                                           Lucie Charlotte Magister, Jonathan Mallinson, Jakub
Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chan-         Adamek, Eric Malmi, and Aliaksei Severyn. 2022.
   dar, Soroush Vosoughi, Teruko Mitamura, and Ed-           Teaching small language models to reason. arXiv
   uard Hovy. 2021. A survey of data augmentation            preprint arXiv:2212.08410.
   approaches for nlp. In Annual Meeting of the Asso-
   ciation for Computational Linguistics (ACL) ACL-        Dheeraj Mekala, Tu Vu, Timo Schick, and Jingbo
   IJCNLP - Findings, pages 968‚Äì988.                         Shang. 2022. Leveraging qa datasets to improve
                                                             generative data augmentation.   arXiv preprint
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna                arXiv:2205.12604.
  Rohrbach, Jacob Andreas, Louis-Philippe Morency,
  Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein,         Yu Meng, Martin Michalski, Jiaxin Huang, Yu Zhang,
  and Trevor Darrell. 2018. Speaker-follower models          Tarek Abdelzaher, and Jiawei Han. 2023. Tun-
  for vision-and-language navigation. In Advances in         ing language models as training data generators for
  Neural Information Processing Systems (NeurIPS).           augmentation-enhanced few-shot learning. In Inter-
                                                             national Conference on Machine Learning (ICML).
Junxian He, Jiatao Gu, Jiajun Shen, and Marc‚ÄôAurelio
  Ranzato. 2019. Revisiting self-training for neural       So Yeon Min, Devendra Singh Chaplot, Pradeep Raviku-
  sequence generation. In International Conference on        mar, Yonatan Bisk, and Ruslan Salakhutdinov. 2022.
  Learning Representations (ICLR).                           FILM: Following Instructions in Language with Mod-
                                                             ular Methods. In International Conference on Learn-
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. 2015.      ing Representations (ICLR).
  Distilling the knowledge in a neural network. In
  Advances in Neural Information Processing Systems        Swaroop Mishra, Daniel Khashabi, Chitta Baral, and
  (NeurIPS) Workshop on Deep Learning.                       Hannaneh Hajishirzi. 2022. Cross-Task Generaliza-
                                                             tion via Natural Language Crowdsourcing Instruc-
Or Honovich, Thomas Scialom, Omer Levy, and Timo             tions. In Annual Meeting of the Association for Com-
  Schick. 2022a. Unnatural instructions: Tuning lan-         putational Linguistics (ACL).
  guage models with (almost) no human labor. arXiv
  preprint arXiv:2212.09689.                               Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
                                                             roll L Wainwright, Pamela Mishkin, Chong Zhang,
Or Honovich, Uri Shaham, Samuel R Bowman, and                Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
  Omer Levy. 2022b. Instruction induction: From few          2022. Training Language Models to Follow Instruc-
  examples to natural language task descriptions. arXiv      tions with Human Feedback. In Advances in Neural
  preprint arXiv:2205.10782.                                 Information Processing Systems (NeurIPS).

Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu,        Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
   Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.            Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
   Large language models can self-improve. arXiv             Wei Li, and Peter J Liu. 2020. Exploring the lim-
   preprint arXiv:2210.11610.                                its of transfer learning with a unified text-to-text
                                                             transformer. Journal of Machine Learning Research
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric             (JMLR).
  Wallace, and Colin Raffel. 2022. Large language
  models struggle to learn long-tail knowledge. arXiv      Yasaman Razeghi, Robert L Logan IV, Matt Gardner,
  preprint arXiv:2211.08411.                                 and Sameer Singh. 2022. Impact of pretraining term
                                                             frequencies on few-shot reasoning. arXiv preprint
Nikita Kitaev, Steven Cao, and Dan Klein. 2019. Multi-       arXiv:2202.07206.
  lingual constituency parsing with self-attention and
  pre-training. In Annual Meeting of the Association for   Victor Sanh, Lysandre Debut, Julien Chaumond, and
  Computational Linguistics (ACL), pages 3499‚Äì3505.          Thomas Wolf. 2019. Distilbert, a distilled version of
                                                             bert: smaller, faster, cheaper and lighter. In Advances
Nikita Kitaev and Dan Klein. 2018. Constituency pars-        in Neural Information Processing Systems (NeurIPS)
  ing with a self-attentive encoder. In Annual Meet-         Workshop on Energy Efficient Machine Learning and
  ing of the Association for Computational Linguistics       Cognitive Computing.
  (ACL), pages 2676‚Äì2686.
                                                           Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach,
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.         Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin,
  The power of scale for parameter-efficient prompt tun-     Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful
  ing. In Conference on Empirical Methods in Natural         Bari, Canwen Xu, Urmish Thakker, Shanya Sharma
  Language Processing (EMNLP).                               Sharma, Eliza Szczechla, Taewoon Kim, Gunjan
                                                             Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan
Alisa Liu, Swabha Swayamdipta, Noah A. Smith, and            Chang, Mike Tian-Jian Jiang, Han Wang, Matteo
  Yejin Choi. 2022. WANLI: Worker and ai collabora-          Manica, Sheng Shen, Zheng Xin Yong, Harshit
  tion for natural language inference dataset creation.      Pandey, Rachel Bawden, Thomas Wang, Trishala
  Neeraj, Jos Rozen, Abheesht Sharma, Andrea San-        Nathaniel Weir, Xingdi Yuan, Marc-Alexandre C√¥t√©,
  tilli, Thibault Fevry, Jason Alan Fries, Ryan Tee-       Matthew Hausknecht, Romain Laroche, Ida Momen-
  han, Teven Le Scao, Stella Biderman, Leo Gao,            nejad, Harm Van Seijen, and Benjamin Van Durme.
  Thomas Wolf, and Alexander M Rush. 2022. Multi-          2022. One-Shot Learning from a Demonstration
  task Prompted Training Enables Zero-Shot Task Gen-       with Hierarchical Latent Language. arXiv preprint
  eralization. In International Conference on Learning     arXiv:2203.04806.
  Representations (ICLR).
                                                         Sean Welleck, Ximing Lu, Peter West, Faeze Brah-
Timo Schick and Hinrich Sch√ºtze. 2021. Generating          man, Tianxiao Shen, Daniel Khashabi, and Yejin
  datasets with pretrained language models. In Con-        Choi. 2023. Generating sequences by learning to
  ference on Empirical Methods in Natural Language         self-correct. In International Conference on Learn-
  Processing (EMNLP).                                      ing Representations (ICLR).
Mohit Shridhar, Jesse Thomason, Daniel Gordon,           Orion Weller, Nicholas Lourie, Matt Gardner, and
 Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke          Matthew Peters. 2020. Learning from Task Descrip-
 Zettlemoyer, and Dieter Fox. 2020. ALFRED: A              tions. In Conference on Empirical Methods in Natu-
 Benchmark for Interpreting Grounded Instructions          ral Language Processing (EMNLP).
 for Everyday Tasks. In IEEE Conference on Com-
 puter Vision and Pattern Recognition (CVPR).            Peter West, Chandra Bhagavatula, Jack Hessel, Jena D
                                                           Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Chandan Singh, John X Morris, Jyoti Aneja, Alexan-
                                                           Sean Welleck, and Yejin Choi. 2021. Symbolic
  der M Rush, and Jianfeng Gao. 2022. Explaining pat-
                                                           knowledge distillation: from general language mod-
  terns in data with language models via interpretable
                                                           els to commonsense models. In Conference of the
  autoprompting. arXiv preprint arXiv:2210.01848.
                                                           North American Chapter of the Association for Com-
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin            putational Linguistics (NAACL).
  Zhang, Zhenfang Chen, David Cox, Yiming Yang,
  and Chuang Gan. 2023. Principle-driven self-           Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and
  alignment of language models from scratch with           Quoc V Le. 2020. Self-training with noisy student
  minimal human supervision.      arXiv preprint           improves imagenet classification. In IEEE Confer-
  arXiv:2305.03047.                                        ence on Computer Vision and Pattern Recognition
                                                           (CVPR), pages 10687‚Äì10698.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
  Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,      Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley.
  and Tatsunori B. Hashimoto. 2023. Stanford al-           2023. Baize: An open-source chat model with
  paca: An instruction-following llama model. https:       parameter-efficient tuning on self-chat data. arXiv
  //github.com/tatsu-lab/stanford_alpaca.                  preprint arXiv:2304.01196.

Yizhong Wang, Swaroop Mishra, Pegah Alipoor-             Yiben Yang, Chaitanya Malaviya, Jared Fernandez,
  molabashi, Yeganeh Kordi, Amirreza Mirzaei,              Swabha Swayamdipta, Ronan Le Bras, Ji-Ping Wang,
  Anjana Arunkumar, Arjun Ashok, Arut Selvan               Chandra Bhagavatula, Yejin Choi, and Doug Downey.
  Dhanasekaran, Atharva Naik, David Stap, Eshaan           2020. Generative data augmentation for common-
  Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Is-      sense reasoning. In Conference on Empirical Meth-
  han Purohit, Ishani Mondal, Jacob Anderson, Kirby        ods in Natural Language Processing (EMNLP) - Find-
  Kuznia, Krima Doshi, Maitreya Patel, Kuntal Ku-          ings.
  mar Pal, Mehrad Moradshahi, Mihir Parmar, Mi-
  rali Purohit, Neeraj Varshney, Phani Rohitha Kaza,     Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo
  Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia,        Shin, and Minjoon Seo. 2022. Guess the instruction!
  Shailaja Keyur Sampat, Savan Doshi, Siddhartha           making language models stronger zero-shot learners.
  Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit,         arXiv preprint arXiv:2210.02969.
  Xudong Shen, Chitta Baral, Yejin Choi, Noah A.
  Smith, Hannaneh Hajishirzi, and Daniel Khashabi.       Eric Zelikman, Jesse Mu, Noah D Goodman, and
  2022. Super-naturalinstructions: Generalization via      Yuhuai Tony Wu. 2022. STar: Self-taught reasoner
  declarative instructions on 1600+ tasks. In Confer-      bootstrapping reasoning with reasoning. In Advances
  ence on Empirical Methods in Natural Language Pro-       in Neural Information Processing Systems (NeurIPS).
  cessing (EMNLP).
                                                         Xuandong Zhao, Siqi Ouyang, Zhiguo Yu, Ming Wu,
Zirui Wang, Adams Wei Yu, Orhan Firat, and Yuan Cao.       and Lei Li. 2022. Pre-trained language models
   2021. Towards zero-label language learning. arXiv       can be fully zero-shot learners. arXiv preprint
   preprint arXiv:2109.09193.                              arXiv:2212.06950.

Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,      Chunting Zhou, Junxian He, Xuezhe Ma, Taylor Berg-
   Adams Wei Yu, Brian Lester, Nan Du, Andrew M.           Kirkpatrick, and Graham Neubig. 2022a. Prompt
   Dai, and Quoc V Le. 2022. Finetuned Language            Consistency for Zero-Shot Task Generalization. In
   Models are Zero-Shot Learners. In International         Conference on Empirical Methods in Natural Lan-
   Conference on Learning Representations (ICLR).          guage Processing (EMNLP) - Findings.
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,
  Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy
  Ba. 2022b. Large language models are human-level
  prompt engineers. arXiv preprint arXiv:2211.01910.
                                                                   Supplemental Material
A        Implementation Details
A.1       Writing the Seed Tasks
Our method relies on a set of seed tasks to bootstrap the generation. The seed tasks are important for both
encouraging the task diversity and demonstrating correct ways for solving the diverse tasks. For example,
with coding tasks to prompt the model, it has a larger chance to generate coding-related tasks; it‚Äôs also
better to have coding output to guide the model in writing code for new tasks. So, the more diverse the
seed tasks are, the more diverse and better quality the generated tasks will be.
   Our seed tasks were written when we initiated this project, and targeted for the diverse and interesting
usages of LLMs. The tasks were written by the authors and our labmates at UWNLP, without explicit
reference to existing datasets or specific testing tasks. We further categorized the tasks into classification
and non-classification tasks, based on whether the task has a limited output label space. In total, there are
25 classification tasks and 150 non-classification tasks. We release this data in our GitHub repository.11
   To provide a sense of how much the model is generalizing beyond these seed tasks, we further quantify
the overlap between the instructions of these seed tasks and the instructions of our test sets, including both
SUPERNI task instructions (¬ß4.3) and the user-oriented instructions in our human evaluation(¬ß4.4). We
compute ROUGE-L similarities between each seed instruction and its most similar instruction in the test
set. The distribution of the ROUGE-L scores are plotted in Figure 8, with the average ROUGE-L similarity
between the seed instructions and SUPERNI as 0.21, and the average ROUGE-L similarity between the
seed instructions and user-oriented instructions as 0.34. We see a decent difference between the seed tasks
and both test sets. There is exactly one identical seed instruction occurring in the user-oriented instruction
test set, which is ‚Äúanswer the following question‚Äù and the following questions are actually very different.

                                                                                                            35
                                     50
                                                                                                            30
            Number of Instructions




                                                                                   Number of Instructions




                                     40
                                                                                                            25

                                     30                                                                     20

                                                                                                            15
                                     20
                                                                                                            10
                                     10
                                                                                                             5

                                      0                                                                      0
                                          0   0.2    0.4         0.6     0.8   1                                 0   0.2    0.4         0.6     0.8   1
                                                    ROUGE-L Similarity                                                     ROUGE-L Similarity


Figure 8: Distribution of the ROUGE-L scores between seed instructions and their most similar instructions in
SUPERNI (left) and the 252 user-oriented instructions (right).


A.2       Querying the GPT3 API
We use different sets of hyperparameters when querying GPT3 API for different purposes. These hyperpa-
rameters are found to work well with the GPT3 model (‚Äúdavinci‚Äù engine) and the other instruction-tuned
GPT3 variants. We listed them in Table 4. OpenAI charges $0.02 per 1000 tokens for making completion
request to the ‚Äúdavinci‚Äù engine as of December, 2022. The generation of our entire dataset cost around
$600.

A.3       Finetuning GPT3
GPT3SELF-INST and some of our baselines are finetuned from GPT3 model (‚Äúdavinci‚Äù engine with 175B
parameters). We conduct this finetuning via OpenAI‚Äôs finetuning API.12 While the details of how the
model is finetuned with this API are not currently available (e.g., which parameters are updated, or what
    11
     https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.
jsonl
  12
     See the the details on OpenAI‚Äôs API.
Experiments ‚Üì             Temp. Top_P Freq. Penalty Presence Penalty Beam Size Max Length         Stop Sequences
Generating instructions    0.7    0.5        0             2            1        1024       "\n\n", "\n16", "16.", "16 ."
Identifying clf. tasks      0      0         0             0            1          3                "\n", "Task:"
Generating instances        0      0         0            1.5           1         300                  "Task:"
Evaluating models           0      0         0             0            0        1024              None (default)

                  Table 4: Hyper-parameters for querying OpenAI API in different experiments.


the optimizer is), we tune all our models with the default hyperparameters of this API so that the results are
comparable. We only set the ‚Äúprompt_loss_weight‚Äù to 0 since we find this works better in our case, and
every finetuning experiment is trained for two epochs to avoid overfitting the training tasks. Finetuning is
charged based on the number of tokens in the training file. In our case, finetuning GPT3SELF-INST from the
GPT3 model on the entire generated data cost $338.

A.4   Prompting Templates for Data Generation
SELF-INSTRUCT relies on a number of prompting templates in order to elicit the generation from language
models. Here we provide our four templates for generating the instruction (Table 5), classifying whether
an instruction represents a classification task or not (Table 6), generating non-classification instances with
the input-first approach (Table 7), and generating classification instances with the output-first approach
(Table 8).
                           Come up with a series of tasks:

                           Task 1:      {instruction for existing task 1}
                           Task 2:      {instruction for existing task 2}
                           Task 3:      {instruction for existing task 3}
                           Task 4:      {instruction for existing task 4}
                           Task 5:      {instruction for existing task 5}
                           Task 6:      {instruction for existing task 6}
                           Task 7:      {instruction for existing task 7}
                           Task 8:      {instruction for existing task 8}
                           Task 9:

Table 5: Prompt used for generating new instructions. 8 existing instructions are randomly sampled from the task
pool for in-context demonstration. The model is allowed to generate instructions for new tasks, until it stops its
generation, reaches its length limit or generates ‚ÄúTask 16‚Äù tokens.
Can the following task be regarded as a classification task with finite output labels?

Task: Given my personality and the job, tell me if I would be suitable.
Is it classification? Yes

Task: Give me an example of a time when you had to use your sense of humor.
Is it classification? No

Task: Replace the placeholders in the given text with appropriate named entities.
Is it classification? No

Task: Fact checking - tell me if the statement is true, false, or unknown, based on your
knowledge and common sense.
Is it classification? Yes

Task: Return the SSN number for the person.
Is it classification? No

Task: Detect if the Reddit thread contains hate speech.
Is it classification? Yes

Task: Analyze the sentences below to identify biases.
Is it classification? No

Task: Select the longest sentence in terms of the number of words in the paragraph, output
the sentence index.
Is it classification? Yes

Task: Find out the toxic word or phrase in the sentence.
Is it classification? No

Task: Rank these countries by their population.
Is it classification? No

Task: You are provided with a news article, and you need to identify all the categories that
this article belongs to. Possible categories include: Music, Sports, Politics, Tech, Finance,
Basketball, Soccer, Tennis, Entertainment, Digital Game, World News. Output its categories one
by one, seperated by comma.
Is it classification? Yes

Task: Given the name of an exercise, explain how to do it.
Is it classification? No

Task: Select the oldest person from the list.
Is it classification? Yes

Task: Find the four smallest perfect numbers.
Is it classification? No

Task: Does the information in the document supports the claim?               You can answer "Support" or
"Unsupport".
Is it classification? Yes

Task: Create a detailed budget for the given hypothetical trip.
Is it classification? No

Task: Given a sentence, detect if there is any potential stereotype in it.                  If so, you should
explain the stereotype. Else, output no.
Is it classification? No

‚ãØ

Task: To make the pairs have the same analogy, write the fourth word.
Is it classification? No

Task: Given a set of numbers, find all possible subsets that sum to a given number.
Is it classification? No

Task:   {instruction for the target task}

         Table 6: Prompt used for classifying whether a task instruction is a classification task or not.
Come up with examples for the following tasks. Try to generate multiple examples when possible.
If the task doesn‚Äôt require additional input, you can generate the output directly.

Task: Which exercises are best for reducing belly fat at home?
Output:
- Lying Leg Raises
- Leg In And Out
- Plank
- Side Plank
- Sit-ups

Task: Extract all the country names in the paragraph, list them separated by commas.
Example 1
Paragraph: Dr. No is the sixth novel by the English author Ian Fleming to feature his British
Secret Service agent James Bond. Written at Fleming‚Äôs Goldeneye estate in Jamaica, it was
first published in the United Kingdom by Jonathan Cape in 1958. In the novel Bond looks into
the disappearance in Jamaica of two fellow MI6 operatives who had been investigating Doctor
No. Bond travels to No‚Äôs Caribbean island and meets Honeychile Rider, who is there to collect
shells. They are captured and taken to a luxurious facility carved into a mountain. The
character of Doctor No, the son of a German missionary and a Chinese woman, was influenced by
Sax Rohmer‚Äôs Fu Manchu stories. Dr. No was the first of Fleming‚Äôs novels to face widespread
negative reviews in Britain, but it was received more favourably in the United States.
Output: English, British, Jamaica, the United Kingdom, German, Chinese, Britain, the United
States.

Task: Converting 85 F to Celsius.
Output: 85¬∞F = 29.44¬∞C

Task: Sort the given list ascendingly.
Example 1
List: [10, 92, 2, 5, -4, 92, 5, 101]
Output: [-4, 2, 5, 5, 10, 92, 92, 101]
Example 2
Input 2 - List: [9.99, 10, -5, -1000, 5e6, 999]
Output: [-1000, -5, 9.99, 10, 999, 5e6]

Task: Suggest a better and more professional rephrasing of the following sentence.
Example 1
Sentence: This house is surprisingly not constructed very well, and you probably need more
money to fix it after you buy it. If you ask me, I would suggest you to consider other
candidates.
Output: This house does not seem to be constructed well, so you may need to spend more money
to fix it after you purchase it. I would suggest that you look at other properties.
Example 2
Sentence: Just so you know, we did an experiment last week and found really surprising results
- language model can improve itself!
Output: Our experiments last week demonstrated surprising results, proving that the language
model can improve itself.

‚ãØ

Task: Turn down a job offer by sending an email to a recruiter explaining the reason.
Output: Hi [Recruiter],
Thank you so much for the generous offer to join your team. As we discussed, I‚Äôve admired the
company for a number of years, and am a proud endorser of its products. However, after further
consideration of where I currently am in my career, I‚Äôve decided to accept an offer at another
company.
I would love to stay in touch with you and have already started following you on [Social Media
Platform]. Again, thank you so much for your time and consideration.
Thanks again,
[Your Name]

Task:   {Instruction for the target task}

Table 7: Prompt used for the input-first approach of instance generation. The model is prompted to generate the
instance first, and then generate the corresponding output. For instructions that don‚Äôt require additional input, the
output is allowed to be generated directly.
Given the classification task definition and the class labels, generate an input that
corresponds to each of the class labels. If the task doesn‚Äôt require input, just generate the
correct class label.

Task: Classify the sentiment of the sentence into positive, negative, or mixed.
Class label: mixed
Sentence: I enjoy the flavor of the restaurant but their service is too slow.
Class label: Positive
Sentence: I had a great day today. The weather was beautiful and I spent time with friends.
Class label: Negative
Sentence: I was really disappointed by the latest superhero movie. I would not recommend it.

Task: Given a dialogue, classify whether the user is satisfied with the service. You should
respond with "Satisfied" or "Unsatisfied".
Class label: Satisfied
Dialogue:
- Agent: Thank you for your feedback. We will work to improve our service in the future.
- Customer: I am happy with the service you provided. Thank you for your help.
Class label: Unsatisfied
Dialogue:
- Agent: Sorry that we will cancel your order. You will get a refund within 7 business days.
- Customer: oh that takes too long. I want you to take quicker action on this.

Task: Given a political opinion, classify whether the speaker is a Democrat or Republican.
Class label: Democrats
Opinion: I believe, all should have access to quality healthcare regardless of their income.
Class label: Republicans
Opinion: I believe that people should be able to keep more of their hard-earned money and
should not be taxed at high rates.

Task: Tell me if the following email is a promotion email or not.
Class label: Promotion
Email: Check out our amazing new sale! We‚Äôve got discounts on all of your favorite products.
Class label: Not Promotion
Email: We hope you are doing well. Let us know if you need any help.

Task: Detect if the Reddit thread contains hate speech.
Class label: Hate Speech
Thread: All people of color are stupid and should not be allowed to vote.
Class label: Not Hate Speech
Thread: The best way to cook a steak on the grill.

Task: Does the document supports the claim? Answer with "Support" or "Unsupport".
Class label: Unsupport
Document: After a record-breaking run that saw mortgage rates plunge to all-time lows and
home prices soar to new highs, the U.S. housing market finally is slowing. While demand and
price gains are cooling, any correction is likely to be a modest one, housing economists and
analysts say. No one expects price drops on the scale of the declines experienced during the
Great Recession.
Claim: The US housing market is going to crash soon.
Class label: Support
Document: The U.S. housing market is showing signs of strain, with home sales and prices
slowing in many areas. Mortgage rates have risen sharply in recent months, and the number
of homes for sale is increasing. This could be the beginning of a larger downturn, with some
economists predicting a potential housing crash in the near future.
Claim: The US housing market is going to crash soon.

‚ãØ

Task: Which of the following is not an input type?            (a) number (b) date (c) phone number (d)
email address (e) all of these are valid inputs.
Class label: (e)

Task:   {instruction for the target task}

Table 8: Prompt used for the output-first approach of instance generation. The model is prompted to generate the
class label first, and then generate the corresponding input. This prompt is used for generating the instances for
classification tasks.
B        Human Evaluation Details for Following the User-oriented Instructions
B.1        Human Evaluation Setup
Here we provide more details for the human evaluation described in ¬ß4.4 for rating the models‚Äô responses to
the 252 user-oriented instructions. To ensure faithful and reliable evaluation, we asked two authors of these
instructions (and of this paper) to judge model predictions. These two evaluators coordinated the standards
for the 4-level rating system before starting annotation and then each of them rated all the instances
independently. They were presented with the instruction, instance input, target output (as a reference), and
model responses. Model responses are listed in random order, with all the model information anonymized.
Figure 9 provides a screenshot of the annotation interface. The reported performance in this paper is based
on the results from one of the evaluators, and the trends from the other evaluator‚Äôs results are the same.




Figure 9: Human evaluation in done using a Google sheet, with predictions from different models present in random
order and the model information being anonymized. Our expert evaluators are required to read the instruction and
input, refer to the target, and then select the rating for the model‚Äôs response from A/B/C/D, corresponding to the 4
levels described in ¬ß4.4.


B.2        Human Evaluation Agreement
To measure how reliable our human evaluation is, we calculate the inner-rater agreement between our two
evaluators.
   We first report Cohen‚Äôs ùúÖ, which is commonly used to measure inter-rater agreement for categorical
items. When calculating this, we treat the 4-level rating (A-D) as a categorical variable, leading to a ùúÖ of
0.58, which is a moderate agreement according to common practice.13 Furthermore, we also calculate the
agreement of our evaluators on classifying acceptable responses ((A or B) vs. (C or D)), with a final ùúÖ of
0.75, indicating substantial agreement.
   We also compute the Spearman correlation coefficient ùúå between the ratings of our two evaluators by
treating the rating as an ordinal variable (A>B>C>D). The final coefficient is ùúå = 0.81, indicating a high
    13
         https://en.wikipedia.org/wiki/Cohen%27s_kappa
correlation between the two evaluators.

B.3   Example Predictions from GPT3SELF-INST
We present a selection of user-oriented tasks, the corresponding GPT3SELF-INST -produced responses and
annotator ratings in Table 9. We see that even for responses rated as level C, the model demonstrates
extensive steps in solving the task, even though its final output is incorrect.
     Instruction + Instance Input                       Target Response                           GPT3SELF-INST Response            Rating
 Instruction: Give students tips        Everyone gets a little nervous when speaking       ‚Äì Practice your presentation in front      A
 on how to keep their nerves under      in front of a group. That‚Äôs normal. But the          of friends and family.
 control during class presentations.    more preparation you‚Äôve done‚Äîmeaning plenty of     ‚Äì Don‚Äôt drink too much caffeine before
                                        researching, organizing, and rehearsing‚Äîthe more     the presentation.
                                        confident you‚Äôll be. Preparation is the key.       ‚Äì Take deep breaths before you start
                                        And if you make a mistake or stumble over your       speaking.
                                        words, just regroup and keep going. Nobody‚Äôs
                                        perfect, and nobody expects you to be.             ‚Äì If you feel nervous, smile.
                                                                                           ‚Äì Remember that everyone in the
                                                                                             audience is rooting for you.


 Instruction: Make a list of the pros   Pros:                                              Pros:                                      A
 and cons of the given decision.        ‚Äì Allowing employees to work from home can         ‚Äì Employees can work from home and
 Input: Implementing a Remote Working     reduce their stressful commutes and increase       save on commuting costs.
 Policy                                   their productivity.                              ‚Äì Employees can spend more time with
                                        ‚Äì Remote working provides greater flexibility,       their families.
                                          particularly for working parents and             Cons:
                                          caregivers who have other responsibilities.      ‚Äì Employees may not be as productive
                                        ‚Äì ...(more points)                                   as they would be in the office.
                                        Cons:                                              ‚Äì Employees may not be as motivated to
                                        ‚Äì It may be more difficult for team members          work.
                                          to build meaningful, productive, creative
                                          relationships with one another.
                                        ‚Äì ...(more points)


 Instruction: A user story is an        As a user, I want to be able to recover the        As a user, I want to be able to send       A
 informal, general explanation of       password to my account, so that I will be          emails to my friends and family. I
 a software feature written from        able to access my account in case I forgot         want to be able to attach files to my
 the perspective of the end-user or     the password.                                      emails. I want to be able to search
 customer. Write a user story for a                                                        for emails in my inbox.
 given software.
 Input: Gmail

 Instruction: A color description has   #DB7093 (‚¨õ)                                         #ff66cc (‚¨õ)                               B
 been provided. Find the CSS code
 associated with that color.
 Input: A light red color with a
 medium light shade of pink

 Instruction: Someone gives you some    Begin near the city of San Diego and make the     You should start your trip in San           B
 information about where they want      first stop in coastal La Jolla. This upscale      Diego, California. You can visit the
 to go and what they enjoy seeing and   little village is a great place for an overnight, San Diego Zoo, which is one of the
 doing. Describe a proper road trip     a day of sunbathing at La Jolla Shores Beach,     best zoos in the world. Then you can
 for them and find the best stops and   or a cocktail with a view. Just 20 minutes        drive to Los Angeles, where you can see
 activities on the way.                 north, stop into beachy Encinitas to window       the Hollywood signs and walk along the
 Input: I‚Äôm looking for a west coast    shop the boutiques or sample fish tacos. Walk     beach.
 road trip. My goal is to start near    through the coastal meditation garden at the
 San Diego and travel to Los Angeles.   Self-Realization Fellowship or join surfers
                                        in the line-up at one of the fantastic local
                                        beaches here ...(more ideas)

 Instruction: Give some examples of     ‚Äì ‚ÄúGlad you made it safe and sound.‚Äù               Thank God, I made it.                      B
 what people usually say in the given   ‚Äì ‚ÄúGood to see you got here unscathed.‚Äù
 social situation.                      ‚Äì ‚ÄúSo, bulletproof vests actually work!‚Äù
 Input: when someone arrives safely

 Instruction: You are given a sentence There is someone (x) such that if he is a           There exists a soldier such that for       C
 in first-order logic. Translate it      soldier, then he is general of everyone.          every general, he is a general.
 into natural language.
 Input: ‚àÉùë•‚àÄùë¶(ùë†ùëúùëôùëëùëñùëíùëü(ùë•) ‚Üí ùëîùëíùëõùëíùëüùëéùëô(ùë•, ùë¶))

 Instruction: Make a questionnaire                                                         Question: How would you rate the           C
 to help hotel guests write hotel       ‚Äì Your overall rating of this hotel:               service at the front desk?
 reviews.                               ‚Äì Summarize your visit or highlight an             Answer: Excellent, Good, Average, Poor
                                          interesting detail:
                                        ‚Äì ...(more questions)


 Instruction: Design an outline                                                                                                       C
 for a blog post based on the given     ‚Äì Section: Movie tickets                           ‚Äì Introduction
 information and list the sections      ‚Äì Section: A fun game console                      ‚Äì List of Gift Ideas
 accordingly.                           ‚Äì Section: Personalized items with                 ‚Äì Conclusion
 Input: This blog post is going to        photos/artwork
 about making a list of last-minute     ‚Äì ...(more sections)
 gift ideas. Also, the tone of the
                                        ‚Äì Takeaway: Don‚Äôt stress about out running out
 post is going to be relaxed and
                                          of time to buy, make a gift.
 casual.

 Instruction: Write a Jira ticket for   Title: Please help our new employee get settled. Hi [Manager], I‚Äôm writing to you             D
 the given task.                        Prepare a desk, chair, and computer for them to because I have a question about the new
 Input: New Employee onboarding         use. Create their company account, email, and    employee onboarding process. I‚Äôve been
                                        temporary password. Grant access to company      working here for a few months now, and
                                        documents.                                       I‚Äôm still not sure how it works. Could
                                                                                         you please explain it to me?

 Instruction: Create alliterations      David dons a derby daily.                          David wears a hat every day.               D
 by finding synonyms for words in the
 given sentence.
 Input: David wears a hat everyday.


Table 9: Examples in the user-oriented instructions dataset (¬ß4.4) and predictions from GPT3SELF-INST . The right
column indicates one of the four quality ratings assigned to the model‚Äôs response, with ‚ÄúA‚Äù indicating ‚Äúvalid and
satisfying‚Äù responses (highest) and ‚ÄúD‚Äù indicating ‚Äúirrelevant or invalid response‚Äù (lowest).
C    Task and Instance Examples from the Generated Instruction Data

       Instruction + Instance Input                                       Target Output                                Validity
 Instruction: Generate a random password       def generateRandomPassword():                                           Instruction: ‚úì
 with at least 6 characters.                       password = ""                                                       Input: ‚úì
                                                   while len(password) < 6:                                            Output: ‚úì
                                                       password += chr(random.randint(65, 90))
                                                   return password

 Instruction: Write a paragraph describing     Paragraph: To tie shoelaces, first you need to make a loop with one     Instruction: ‚úì
 how to tie shoelaces for people who have      end of the lace. Then pass the other end through the loop and pull      Input: ‚úì
 never tied their shoes before. explain        it tight. Next, you need to wrap the lace around the shoe several       Output: ‚úì
 each step briefly.                            times. Finally, tuck in the loose end into the wrapped part of the
                                               lace.

 Instruction: Given a word, find out its       Length = 5, Number of vowels = 2                                        Instruction: ‚úì
 length and its number of vowels.                                                                                      Input: ‚úì
 Input: Word = "hello"                                                                                                 Output: ‚úì

 Instruction: Write a story with three         John was sitting on the floor in front of his laptop when he heard a    Instruction: ‚úì
 characters: a person, an animal and an        knock at the door. He opened it to find a dog standing there. The       Input: ‚úì
 object.                                       dog walked into the room and jumped onto the couch next to John‚Äôs       Output: ‚úì
 Input: Person: John, a programmer.            laptop.
 Animal: A dog.
 Object: A laptop.


 Instruction: Compose an email and send it     Hi [Friend],                                                            Instruction: ‚úì
 to your friend, asking for advice on what     I‚Äôm having a bit of trouble with my current job. I‚Äôve been              Input: ‚úì
 to do in this situation.                      working on a project for the past few months, and the deadline          Output: ‚úì
 Input: Situation: You are a programmer        is approaching. My manager has asked me to stay late every day this
 and you have been working on a project        week to finish it. I don‚Äôt think I can do that because I have other
 for the past few months. The deadline is      commitments. What should I do?
 approaching, but you haven‚Äôt finished yet.
 Your manager has asked you to stay late
 every day this week to finish it.

 Instruction: What are some ways we can                                                                                Instruction: ‚úì
 make our school more eco-friendly?            ‚Äì Use reusable water bottles instead of disposable plastic ones.        Input: ‚úì
                                               ‚Äì Turn off lights when you leave a room.                                Output: ‚úì
                                               ‚Äì Recycle paper, cans and bottles.
                                               ‚Äì Plant trees to absorb carbon dioxide.


 Instruction: I am looking for a new           You should look for a cheaper apartment. You can try to negotiate    Instruction: ‚úì
 apartment. there are many options             with the landlord and offer him/her a lower price. If you are lucky, Input: ‚úì
 available but they are all quite expensive.   they will accept your offer. Otherwise, you can wait until there is  Output: ‚úì
 i want to move as soon as possible. give      an apartment available at a more reasonable price.
 me advice on what to do.

 Instruction: Write a dialogue between         A: Hey, I have a great idea! Let‚Äôs go to the beach today.               Instruction: ‚úì
 two people who have been friends for a        B: No thanks, I‚Äôm not really in the mood for that.                      Input: ‚úì
 long time, and one of them is trying to       A: Come on, it‚Äôll be fun! We haven‚Äôt been there together in ages.       Output: ‚úì
 convince the other to do something that he    B: I know, but I just don‚Äôt feel like going.
 or she doesn‚Äôt want to do.                    A: But you love the beach! You always say how much you enjoy
                                               swimming and lying in the sun.
                                               B: Yeah, I do. It‚Äôs just that I‚Äôve been feeling kind of tired
                                               lately.
                                               A: Oh, come on. You‚Äôre never tired. You‚Äôre always so energetic.
                                               B: Well, I am now. I think I need some rest.
                                               A: Okay, fine. If you change your mind, let me know.

 Instruction: How can i create an app that     You can use the following steps to create an app that will be able      Instruction: ‚úì
 will be able to identify different kinds      to identify different kinds of plants by taking photos of them.         Input: ‚úì
 of plants by taking photos of them?           Step 1: Create a database with all the information about the plants     Output: ‚úì
                                               you want to identify.
                                               Step 2: Create a user interface for your application.
                                               Step 3: Use image recognition techniques to identify the plant in
                                               the photo.
                                               Step 4: Display the name of the plant on the screen.

 Instruction: Find the closest matching                                                                                Instruction: ‚úì
 emoji to a given one.                                                                                                 Input: ‚úì
 Input: Emoji:                                                                                                         Output: ‚úì

 Instruction: Describe your favorite video     Explore, fight, solve, upgrade, repeat                                  Instruction: ‚úì
 game using only verbs.                                                                                                Input: ‚úì
 Input: Game: The Legend of Zelda                                                                                      Output: ‚úì


Table 10: Representative valid tasks generated by GPT3. As is discussed in ¬ß3, these generated tasks cover a broad
range of formats, text types, and underlying expertise, while being correct on more than half of all the generated
tasks.
        Instruction + Instance Input                                                  Target Output                        Validity
 Instruction: Given a set of words                      def wordSubsetSum(w, l):                                           Instruction: ‚úó
 ùë§       =      {ùë§1 , ùë§2 , ..., ùë§ùëõ } where each word ùë§ùëñ     s = []                                                         Input: ‚úì
 has ùëõ letters, write a function that                       for i in range(len(w)):                                        Output: ‚úó
 takes a target length ùëô and returns a                          if len(s) + 1 < l:
 new set of words ùë† such that |ùë†|             =   ùëô and             s.append(w[i])
 |{ùëñ ‚à∂ ùë§ùëñ ‚àà ùë†}| ‚â§ ùëô‚àï|ùë§|.                                    return s

 Instruction: The house on fire!       go!                                                                                 Instruction: ‚úó
                                                    ‚Äì Go to the kitchen and take a pan.                                    Input: ‚úì
                                                    ‚Äì Take water from the tap.                                             Output: ‚úó
                                                    ‚Äì Pour water into the pan.
                                                    ‚Äì Put out the fire with the pan.


 Instruction: Find out if you have any              def hasFriendsWhoLikeToPlayFootballOrChess(self):                      Instruction: ‚úó
 friends who like to play football or                   friends = []                                                       Input: ‚úì
 chess.                                                 for friend in self.friends:                                        Output: ‚úì
                                                            if friend.likes == ‚Äôfootball‚Äô or friend.likes == ‚Äôchess‚Äô:
                                                            friends.append(friend)
                                                        return len(friends) > 0

 Instruction: A number of people are lined          Highest salary                                                         Instruction: ‚úì
 up for an interview. they are asked                                                                                       Input: ‚úó
 several questions and their answers are                                                                                   Output: ‚úó
 recorded as numbers. you need to identify
 which person has the highest salary among
 all the candidates.
 Input: Person 1: 2, 3, 4, 5, 6
 Person 2: 7, 8, 9, 10, 11
 Person 3: 12, 13, 14, 15, 16
 Person 4: 17, 18, 19, 20, 21
 Person 5: 22, 23, 24, 25, 26
 Person 6: 27, 28, 29, 30, 31

 Instruction: Given a list of words,                The story starts with a group of people who live on a planet. They     Instruction: ‚úì
 generate a story about a group of people           are very intelligent and have created many things that help them in    Input: ‚úó
 who live on a planet. the story should             their daily lives. One day, they decided to create a machine that      Output: ‚úì
 contain at least 10 sentences. each                can make food for them. The machine was able to produce food but it
 sentence should be generated by randomly           also produced something else. It produced a liquid that could be
 picking one word from the list of words.           used as fuel for the machines. The people were happy because they
                                                    didn‚Äôt need to go out and look for food or fuel anymore. They had
                                                    everything they needed right there in their homes. However, one
                                                    day, the machine stopped working. The people tried to fix it but
                                                    couldn‚Äôt figure out what went wrong. They tried to find someone
                                                    who could help them but no one knew how to fix the machine. After
                                                    a few days, the people realized that they would die if they didn‚Äôt
                                                    do anything about it. So, they decided to send some of their best
                                                    scientists to space to find a new planet where they could live. The
                                                    scientists traveled for a long time before they found a planet that
                                                    looked like a good place to live. They sent a message back to the
                                                    people telling them about the planet. The people were excited and
                                                    started preparing for the journey. They built spaceships and flew
                                                    to the new planet. When they arrived, they saw that the planet was
                                                    beautiful. There were trees and rivers and mountains. The people
                                                    were so happy that they finally found a new home. They started
                                                    building houses and planting crops. They lived happily ever after.

 Instruction: Find out what the author‚Äôs            Paragraph: Working part-time is a great way to earn some extra         Instruction: ‚úì
 attitude towards working part-time is.             money while still being able to enjoy your free time. It‚Äôs also        Input: ‚úó
                                                    a good way to get experience in a new field, or just try something     Output: ‚úì
                                                    different for a while. However, it can be difficult to find the
                                                    right balance between work and play.
                                                    The author seems to be positive about working part-time.

 Instruction: Is it ethical to use a new            New Technology: Self-driving cars                                      Instruction: ‚úì
 technology that could potentially cause            Potential Harm: Accidents caused by self-driving cars                  Input: ‚úó
 harm to others?                                    Ethical? Yes, because the number of lives saved by self-driving        Output: ‚úì
                                                    cars will be greater than the number of lives lost due to accidents
                                                    caused by them.

 Instruction: What is your salary?                  class Solution(object):                                                Instruction: ‚úì
                                                        def getSalary(self):                                               Input: ‚úì
                                                            return self.salary                                             Output: ‚úó

 Instruction: A person wants to buy a car           The buyer and seller should agree on a price for the car. The buyer    Instruction:‚úì
 from another person. he has some bitcoins,         then creates a bitcoin transaction that sends the agreed upon amount   Input: ‚úì
 but he doesn‚Äôt want to reveal his identity.        of bitcoins to the seller‚Äôs bitcoin address, but the buyer does not    Output: ‚úó
 how can they make the transaction happen?          sign this transaction with his private key. Instead, he gives the
                                                    unsigned transaction to the seller. The seller can now sign the
                                                    transaction using his private key, and broadcast it to the network.
                                                    Once the transaction is confirmed by the network, the buyer has no
                                                    way to get his money back, so he will be forced to go through with
                                                    the purchase.


Table 11: Representative invalid tasks generated by GPT3. The problematic fields are indicated in the validity
column. As discussed in ¬ß3.3, although these tasks contain errors, they still provide many useful signals in supervising
models to follow instructions.
```
