# Deep Research: [54] axe-core：可访问性自动化检查的最低成本方案

- Source: https://github.com/dequelabs/axe-core
- Note: ../notes/ref-054-axe-core.md
- Snapshot: ../sources/md/github-com-dequelabs-axe-core-ffda5b0730f2.md
## TL;DR
axe-core 是目前业界事实上的可访问性（Accessibility/a11y）自动化测试标准，它通过将无障碍检查“左移”至开发和 CI 阶段，以极低的集成成本帮助团队建立“防止体验退化”的底线，虽然仅能覆盖约 57% 的 WCAG 问题，但其“零误报”设计理念极大地建立了开发者对工具的信任。

## 核心观点
1.  **自动化不仅仅是省力，更是底线守护**：axe-core 的核心价值不在于发现所有问题，而在于作为一个无情的守门员，防止已修复的低级错误（如丢失 alt 文本、对比度不足）在后续迭代中再次出现。
2.  **“零误报”原则（Zero False Positives）**：这是 axe-core 最重要的宣言。如果工具报错，那几乎肯定是一个 Bug。这极大地降低了开发者的抵触心理，避免了狼来了的故事。
3.  **覆盖率局限性（~57%）**：自动化只能检测程序化的错误（如 HTML 结构）。语义类问题（如“图片的 alt 描述是否准确”）仍需人工或 AI 辅助判断。因此，axe-core 结果通过 $\neq$ 完全合规。
4.  **技术栈无关性**：它是一个纯 JavaScript 库，不依赖特定框架。无论是 React、Vue、Angular，还是通过 Selenium、Cypress、Jest 进行测试，都可以无缝集成。
5.  **规则可配置**：支持 WCAG 2.0, 2.1, 2.2 的 A, AA, AAA 各个等级。团队可以根据实际合规需求（通常是 WCAG 2.1 AA）定制规则集。
6.  **影子 DOM 支持**：对 Shadow DOM 的良好支持使其适应现代 Web Components 架构，不会因为组件封装而失效。
7.  **“不完整（Incomplete）”状态**：除了 Pass/Fail，它会返回“需要人工确认”的项目，引导测试人员关注机器无法判断的模糊地带。
8.  **开源与商业的双轮驱动**：由 Deque Systems 维护，保证了更新频率（紧跟浏览器和标准变化）和长期支持，同时开源协议（MPL 2.0）允许广泛商用。

## 可落地做法

### 1. 工程化集成（面向开发/DevOps）
*   **单元测试层**：使用 `jest-axe` 或 `vitest-axe`。在组件单元测试中增加断言，确保每个 UI 原子组件在渲染时符合基础标准。
*   **端到端测试层**：集成 `cypress-axe` 或 `playwright-axe`。在页面加载完成或交互发生后注入 `axe.run()`，捕获动态渲染产生的问题。
*   **CI 门禁**：在 GitHub Actions 或 GitLab CI 中配置流程。如果引入了新的 a11y 违规（Severity 为 critical/serious），则阻断 Merge Request。

### 2. 流程规范（面向产品/设计）
*   **定义 DoD（Definition of Done）**：产品验收标准中明确“axe-core 扫描无 Critical 级别错误”。
*   **基线管理**：对于历史遗留严重的旧项目，不要追求一次清零。建立“基线文件”，只对**新增代码**产生的错误进行报错，后续逐步偿还技术债。

### 3. 开发辅助
*   **IDE 插件**：安装 VS Code 的 axe Linter 插件，在写 HTML/JSX 时实时提示可访问性错误，将反馈循环缩短到秒级。
*   **浏览器扩展**：开发调试时使用 axe DevTools 浏览器插件进行快速自测。

## 检查清单：可访问性自动化门禁

此清单用于确认项目是否有效利用了 axe-core 建立了基础防护网：

- [ ] **依赖安装**：已在 `devDependencies` 中安装 `axe-core` 或其对应的测试框架适配器（如 `jest-axe`）。
- [ ] **本地运行**：运行测试命令（如 `npm run test`）能成功触发 a11y 检查并输出报告。
- [ ] **规则配置**：已在配置文件中明确目标标准（例如：`runOnly: { type: 'tag', values: ['wcag21aa'] }`）。
- [ ] **CI 阻断**：CI 流水线在发现新的严重违规时会标记为失败（Fail）。
- [ ] **基线机制**：如果是旧项目，已配置忽略列表或快照，确保旧账不影响新功能的合并。
- [ ] **错误可视**：测试报告能指明具体的 DOM 节点和违规原因（不仅是说“出错了”）。
- [ ] **文档同步**：README 中包含如何运行可访问性测试的说明。

## 常见坑与对策

1.  **坑：迷信“全绿”**
    *   **现象**：axe-core 扫描通过，团队就认为产品无障碍了，忽略了键盘导航逻辑、焦点管理和屏幕阅读器实际体验。
    *   **对策**：教育团队“自动化只是第一步”。必须保留人工抽查（Manual Audit）或使用 AI 模拟用户操作进行补充验证。

2.  **坑：性能拖慢测试**
    *   **现象**：在大规模 E2E 测试的每一步都运行 `axe.run()`，导致测试耗时成倍增加。
    *   **对策**：只在关键状态变化（如弹窗打开、路由切换）后运行扫描，或在专门的 nightly build 中运行全量扫描，而非每次提交都跑全量。

3.  **坑：对比度误报**
    *   **现象**：对于背景复杂的图片或渐变色，自动化工具常无法准确计算对比度。
    *   **对策**：对于此类误报，在代码中显式标记忽略（`axe-skip` 或配置规则忽略特定 ID），并添加人工确认的注释。

4.  **坑：动态内容漏测**
    *   **现象**：只测了静态 HTML，忽略了用户交互后动态加载的内容（如表单验证错误提示）。
    *   **对策**：确保测试脚本模拟了用户交互（点击、输入），并在交互完成后再次触发扫描。

## 可用于丰富《AI 辅助软件产品》的写作点

*   **第 3 章（UI/UX - 设计即代码）**：
    *   在介绍“从设计稿生成代码”的流程时，强调生成的代码必须**自带** axe-core 测试用例。AI 生成的组件如果不符合 a11y 标准，就是不合格的生成。可以将“通过 axe 检查”作为 AI 生成代码质量评估的一个硬性指标（Reward Model 的一部分）。
*   **第 4 章（质量门禁 - 自动化测试）**：
    *   作为“低成本高收益”的典型案例。对比人工测试的高昂成本，axe-core 展示了如何用极低的机器成本守住 50%+ 的体验底线。可以引用其“零误报”哲学来论述为什么某些静态分析工具能成功推广，而有些则因为噪音太大被弃用。
*   **第 8 章（前端工程化）**：
    *   在 Pipeline 设计图中，将 axe-core 作为一个独立的 Lint 环节。
    *   **AI Agent 场景**：描述一个“无障碍修复 Agent”。它读取 axe-core 的 JSON 报错报告（包含节点选择器和修复建议），自动定位代码并生成修复 PR（例如自动添加缺失的 `aria-label` 或调整 tailwind 颜色类名）。这是 AI 辅助编码极其具体的落地场景。
