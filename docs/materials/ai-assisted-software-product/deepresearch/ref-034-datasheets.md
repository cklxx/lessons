# Deep Research: [34] Datasheets for Datasets：数据集要像产品说明书一样可追溯

- Source: https://arxiv.org/abs/1803.09010
- Note: ../notes/ref-034-datasheets.md
- Snapshot: ../sources/md/arxiv-org-abs-1803-09010-641a177ce167.md
## TL;DR
机器学习数据集不应是缺乏上下文的静态文件，而应被视为具有规格、限制和适用范围的工业组件；必须为其配备类似电子元器件规格书（Datasheet）的标准化文档，详细记录从动机、采集到维护的全生命周期信息，以在源头遏制模型偏差与合规风险。

## 核心观点

1.  **类比电子工业标准**：就像电阻或芯片有规格书说明其工作电压、误差范围和测试结果一样，作为 AI 系统核心原材料的数据集，也必须明确其运行特征和推荐用法。
2.  **透明度促进问责**：通过强制记录谁创建、谁资助、为解决什么问题创建，可以揭示潜在的利益冲突（如烟草公司资助的健康数据）和隐性偏差。
3.  **反思优于文档**：Datasheet 的核心价值不仅在于最终的文档，更在于迫使数据创建者在采集前和采集过程中进行**伦理反思**（Reflection），例如思考采集这个数据是否会伤害特定群体。
4.  **反自动化原则**：虽然元数据提取可自动化，但关于动机、伦理风险和推荐用途的描述**不能完全自动化**，必须由人进行主观判断和责任背书。
5.  **生命周期全覆盖**：文档结构应对应数据生命周期（动机 -> 组成 -> 采集 -> 预处理 -> 使用 -> 分发 -> 维护），而不是杂乱的信息堆砌。
6.  **明确非推荐用途**：不仅要写能干什么，更要明确**不能干什么**（例如：此人脸数据集不涵盖深色肤色，严禁用于执法场景）。
7.  **动态维护机制**：数据集是活的，Datasheet 必须包含更新计划、错误勘误（Erratum）机制以及长期维护承诺，防止僵尸数据污染模型。
8.  **降低沟通成本**：标准化的文档让数据消费者（算法工程师/产品经理）能快速判断数据适用性，无需反复询问创建者或在训练失败后才发现数据不匹配。

## 可落地做法

### 1. 产品经理 (PM)
*   **需求阶段定义**：在 PRD 中定义 AI 功能时，同步起草 Datasheet 的动机（Motivation）和用途（Uses）章节。
*   **风险边界设定**：明确列出Negative Use Cases（负面用例），例如本客服对话数据仅覆盖标准普通话，不应用于方言地区。

### 2. 数据/算法工程师 (Engineering)
*   **流水线强制卡点**：在数据入库（Data Ingestion）环节建立硬性约束，未附带基础 Datasheet（如 JSON/YAML 格式元数据）的数据包**禁止进入**训练管道。
*   **版本化管理**：将 Datasheet 与数据版本（如 DVC）绑定，数据清洗逻辑（Preprocessing）的变更必须同步更新文档。

### 3. 评测与合规 (QA/Governance)
*   **偏差审计**：根据 Datasheet 中的组成（Composition）章节，核对测试集是否覆盖了文档声明的所有子群体（Subpopulations）。
*   **合规验收**：检查分发（Distribution）章节的版权和许可条款，确保无商用风险。

## 检查清单：数据规格书（精简版）

可直接整合进项目的 `README.md` 或数据管理系统的表单中：

### 第一部分：动机与背景
- [ ] **创建目的**：是为了解决特定任务（如情感分析）还是通用研究？
- [ ] **资助/创建方**：哪个团队创建的？谁出钱？（排查利益相关性）

### 第二部分：数据组成 (Composition)
- [ ] **实例描述**：数据是什么？（行、图、文本、关系？）
- [ ] **规模与完备性**：有多少条？是全集还是采样？采样的偏差是什么？
- [ ] **敏感信息**：是否包含 PII（个人身份信息）？是否包含攻击性/色情内容？
- [ ] **人群分布**：是否识别了子群体（性别、年龄、地域）？分布是否平衡？

### 第三部分：采集过程 (Collection)
- [ ] **数据来源**：是直接观测（传感器）、用户上报（问卷）还是爬虫抓取？
- [ ] **知情同意**：被采集者是否知情？是否签署了 Consent Form？
- [ ] **采集时间窗**：数据反映的是哪个时间段的世界？（防止时效性偏差）

### 第四部分：预处理 (Preprocessing)
- [ ] **清洗逻辑**：做了什么过滤？（如剔除了短文本、模糊图片）
- [ ] **原始数据**：Raw Data 是否保留？去哪里找？

### 第五部分：使用与限制 (Uses)
- [ ] **推荐用途**：在哪些场景下表现最好？
- [ ] **禁止用途**：绝对不应该用在什么地方？（如高风险决策）
- [ ] **风险提示**：使用者应注意哪些潜在的公平性或法律风险？

## 常见坑与对策

| 常见坑 | 后果 | 对策 |
| :--- | :--- | :--- |
| **只写技术参数** | 文档变成单纯的 `schema` 定义，无法评估业务风险。 | 强制填写动机和限制字段，不仅是包含什么，更要写为什么。 |
| **事后补作业** | 模型上线前突击补文档，信息遗忘，流于形式。 | **Shift Left**：在数据采集脚本编写阶段就要求填写 Datasheet 草稿。 |
| **过度自动化** | 用脚本自动统计行数和空值填入文档，缺乏对内容的定性描述。 | 区分自动生成的统计信息与人工填写的描述信息，后者必须有人签字。 |
| **一稿定终身** | 数据清洗规则变了，Datasheet 还是旧的。 | 将 Datasheet 作为代码仓库的一部分（Check-in code），纳入 Code Review 流程。 |

## 可用于丰富《AI 辅助软件产品》的写作点

*   **第 1 章（需求验证）**：在问题-证据矩阵中，强调**证据的可信度**依赖于 Datasheet。如果没有 Datasheet 证明数据的来源和代表性，所谓的数据驱动决策可能只是Garbage In, Garbage Out。
*   **第 8 章（数据工程）**：
    *   **架构设计**：在设计数据管线（Data Pipeline）时，将Datasheet 生成器作为一个标准微服务或构建步骤。
    *   **Artifacts**：展示一个具体的 JSON Schema 示例，说明如何用代码化的方式管理 Datasheet。
*   **第 12 章（治理与合规）**：
    *   **审计凭证**：将 Datasheet 定义为算法备案和合规审计的核心凭证。
    *   **供应链安全**：讨论使用开源数据集（HuggingFace 等）时的风险，强调必须阅读 Datasheet 才能引入第三方数据。
*   **第 10 章（Agent 与 RAG）**：
    *   **知识库治理**：RAG 系统的知识库切片（Chunking）前，需为原始文档库建立 Datasheet，明确知识的截止时间（Cut-off date）和权威性等级，防止 Agent 产生幻觉时无据可查。
