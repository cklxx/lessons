# Deep Research: [89] Constitutional AI：用规则与 AI 反馈降低人工标注压力

- Source: https://arxiv.org/abs/2212.08073
- Note: ../notes/ref-089-constitutional-ai.md

## TL;DR
Constitutional AI 的出发点是把对齐标准写成一套规则，再让模型基于规则自我批评与改写，用 AI 反馈替代一部分人工反馈。但规则写不清时，成本并不会消失，只会以更隐蔽的方式回到线上事故里。

## 核心观点
1. 规则是关键资产。它既是训练信号来源，也是评测与发布门禁的依据。
2. 用 AI 反馈降低人工成本的前提是规则可执行、可验收，否则只是把噪声换成另一种噪声。
3. 规则体系需要处理冲突与优先级，否则模型在不同场景会表现出不一致，且很难靠调参修复。
4. 对产品团队来说，这类方法更像是把安全与价值观写成工程合同，而不是只做一次训练。[77]

## 可落地做法
1. 把规则写成条款，不写口号。条款要能落到具体回答优劣的判定上，例如何时拒答、何时追问、何时提示风险。[77]
2. 让规则直接服务评测。每条规则至少对应一组评测用例与一个回归阈值，规则更新必须触发评测集更新。[18]
3. 先用人工做基准，再引入 AI 反馈。先用少量人工标注建立基准，验证规则是否足以指导判断，再逐步把低风险部分交给 AI。

## 检查清单
- 规则体系
  - 规则有优先级与冲突处理原则。
  - 规则覆盖边界与高风险任务，并明确人工确认流程。[77]
- 评测与发布
  - 每条规则都有对应评测用例与阈值。
  - 规则变更与模型变更都走同一套发布门禁与回滚机制。[18]

## 常见坑与对策
- 坑：规则大而空，无法指导判断。
  - 对策：把规则改写成可执行条款，并用反例说明什么是不合格。
- 坑：规则之间相互打架，模型表现反复。
  - 对策：引入优先级与仲裁原则，把冲突场景写进评测集。

## 可用于丰富《AI 辅助软件产品》的写作点
- 第 20 章可以把规则体系写成治理框架的一部分：规则不是文档装饰，而是训练、评测、发布的共同事实源。[77][89]
- 第 15 章可以补充一个低成本路径：先用规则约束与评测门禁解决大部分问题，再考虑把反馈自动化。
