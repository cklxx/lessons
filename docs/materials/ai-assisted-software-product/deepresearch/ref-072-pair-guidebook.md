# Deep Research: [72] People + AI Guidebook（Google PAIR）：把以人为本写成可执行的工作流

- Source: https://pair.withgoogle.com/guidebook/
- Note: ../notes/ref-072-pair-guidebook.md
- Snapshot: ../sources/md/pair-withgoogle-com-guidebook-9f0318b11693.md
- Category: UX / UI & Design Systems (ux_ui)
- Chapters: 04-prototype, 06-ui
## TL;DR (1-2 sentences)
Google PAIR Guidebook 提供了一套完整的以人为本AI 产品设计框架，核心在于打破模型即产品的迷思，强调**用户信任、心智模型引导、反馈回路设计**与**故障降级策略**。它将 AI 视为需要与人协作的动态系统，而非单纯的自动化工具。

## 核心观点（5-8 条）
- **AI 的价值在于增强而非仅是自动化**：只有当 AI 能显著提升效率或提供独特能力（如个性化推荐）时才应使用，避免为了 AI 而 AI。
- **建立正确的心智模型**：用户往往高估或低估 AI 能力。产品必须通过引导（Onboarding）和解释（Explainability）让用户理解 AI 的能力边界。
- **信任需要校准**：信任不是越多越好，而是要与系统能力匹配。高风险场景（如医疗）需要高可解释性，低风险场景（如推荐歌曲）可以黑盒。
- **拥抱不确定性与错误**：AI 必然会出错。设计重心应从追求完美转向优雅降级（Graceful Failure），让用户在 AI 失败时也能完成任务。
- **反馈即数据**：每一次用户纠错、拒绝建议或显式点赞，都是优化模型的宝贵数据。反馈回路（Feedback Loop）的设计是产品护城河。
- **数据是产品的核心组件**：数据的采集、清洗和评测不再只是工程师的事，而是产品经理定义成功的关键环节。

## 可落地做法（面向产品/工程/评测，给出步骤）

### 1. 需求与定义阶段（产品经理）
- **任务拆解**：使用增强 vs 自动化矩阵分析用户任务。对于高创造性或高责任任务，选择AI 辅助；对于重复性低风险任务，选择自动化。
- **成功定义**：不要只看准确率（Accuracy）。定义用户成功指标，例如用户采纳建议的比例或完成任务缩短的时间。

### 2. 交互与反馈设计（UI/UX + 前端）
- **显式/隐式反馈埋点**：
    - **显式**：点赞/点踩、修改建议、填写理由。
    - **隐式**：停留时长、采纳建议后的后续行为、忽略建议。
- **可解释性设计**：在关键决策点提供 "Why did I see this?" 的提示，展示 AI 的决策依据（如因为你通过了 X 课程）。

### 3. 工程与评测（研发 + 测试）
- **构建回归集**：将用户反馈中的坏案例自动通过 Webhook 推送至待标注队列，转为回归测试集（Golden Set）。
- **冷启动策略**：在没有足够数据时，设计基于规则（Heuristics）的兜底逻辑，确保基线体验。

## 检查清单（产品设计自查表）

**阶段一：决定是否使用 AI**
- [ ] 这是一个概率性问题吗？（如果是确定性规则，不要用 AI）
- [ ] 错误的代价用户能承受吗？
- [ ] 我们有数据来训练或微调模型吗？

**阶段二：心智与信任**
- [ ] 用户能一眼看出这是 AI 生成的内容吗？
- [ ] 用户知道如果不满意该怎么办吗（修改/重试/人工介入）？
- [ ] 系统是否解释了它为什么这样做（在必要时）？

**阶段三：反馈与控制**
- [ ] 用户能方便地撤销（Undo）AI 的操作吗？
- [ ] 用户能否关闭或调整 AI 的干预程度？
- [ ] 用户的纠错行为是否会被系统记录并用于学习？

**阶段四：错误处理**
- [ ] 当 AI 生成乱码或离谱内容时，UI 是否会崩溃？
- [ ] 是否有备用的非 AI 流程让用户完成任务？

## 常见坑与对策
| 常见坑 | 对策 |
| :--- | :--- |
| **过度承诺**：让用户以为 AI 全知全能，导致预期落差。 | **坦诚边界**：在 Onboarding 明确告知我是处于学习阶段的助手，可能会犯错。 |
| **幽灵模式**：AI 默默做事，用户不知道发生了什么，感到失控。 | **透明化**：使用动效或状态栏展示 AI 的状态（思考中、处理中、已完成）。 |
| **死胡同**：AI 给出的结果不可编辑，用户只能全部删除重写。 | **人机协作**：提供编辑而非重生成；提供 Copilot 模式而非 Autopilot。 |
| **反馈黑洞**：收集了反馈但模型从未改进，用户失去耐心。 | **闭环运营**：定期发布因为你们的反馈，我们学会了 X的更新日志。 |

## 可用于丰富《AI 辅助软件产品》的写作点
- **第 2 章（需求挖掘）**：引入AI 适用性检查清单，帮助读者判断何时**不**该用 AI。
- **第 4 章（原型设计）**：引用Wizard of Oz（野路子原型法）测试用户对 AI 的真实预期，验证反馈回路。
- **第 6 章（Generative UI）**：结合心智模型一节，探讨如何通过 UI 动态适应用户的信任程度（信任低时多解释，信任高时多自动化）。
- **第 18 章（评测）**：强化以用户为中心的评测，将 Guidebook 中的Reward Function概念转化为具体的业务指标设计。
- **第 20 章（治理）**：增加可解释性说明作为产品发布的强制门禁。
